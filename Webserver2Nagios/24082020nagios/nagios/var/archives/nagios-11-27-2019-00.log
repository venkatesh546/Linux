[1574706600] LOG ROTATION: DAILY
[1574706600] LOG VERSION: 2.0
[1574706600] CURRENT HOST STATE: db1-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.46 ms
[1574706600] CURRENT HOST STATE: db2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.41 ms
[1574706600] CURRENT HOST STATE: primary-server;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.40 ms
[1574706600] CURRENT HOST STATE: pservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.38 ms
[1574706600] CURRENT HOST STATE: pservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.32 ms
[1574706600] CURRENT HOST STATE: qservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.27 ms
[1574706600] CURRENT HOST STATE: qservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.29 ms
[1574706600] CURRENT HOST STATE: redis-1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.30 ms
[1574706600] CURRENT HOST STATE: redis-2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.36 ms
[1574706600] CURRENT HOST STATE: rq-1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.28 ms
[1574706600] CURRENT HOST STATE: rq-2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.28 ms
[1574706600] CURRENT HOST STATE: secondary-server;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.38 ms
[1574706600] CURRENT HOST STATE: sig1-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.53 ms
[1574706600] CURRENT HOST STATE: sig2-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.37 ms
[1574706600] CURRENT HOST STATE: sig3-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.30 ms
[1574706600] CURRENT HOST STATE: sig4-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.51 ms
[1574706600] CURRENT HOST STATE: sig5-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.33 ms
[1574706600] CURRENT HOST STATE: sig6-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.46 ms
[1574706600] CURRENT HOST STATE: sigqscluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.41 ms
[1574706600] CURRENT HOST STATE: sigqscluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.27 ms
[1574706600] CURRENT HOST STATE: smscapp1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.26 ms
[1574706600] CURRENT HOST STATE: smscapp2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.28 ms
[1574706600] CURRENT HOST STATE: sservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.28 ms
[1574706600] CURRENT HOST STATE: sservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.33 ms
[1574706600] CURRENT HOST STATE: webserver1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.43 ms
[1574706600] CURRENT HOST STATE: webserver2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.05 ms
[1574706600] CURRENT HOST STATE: webservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.42 ms
[1574706600] CURRENT HOST STATE: webservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.28 ms
[1574706600] CURRENT SERVICE STATE: db1-vm2;CPU Load;OK;HARD;1;OK - load average: 3.45, 3.26, 2.51
[1574706600] CURRENT SERVICE STATE: db1-vm2;CPU_Procs;OK;HARD;1;CPU OK: 461 processes
[1574706600] CURRENT SERVICE STATE: db1-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1574706600] CURRENT SERVICE STATE: db1-vm2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 26771 MB (67% inode=99%):
[1574706600] CURRENT SERVICE STATE: db1-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 42401 MB (82% inode=99%):
[1574706600] CURRENT SERVICE STATE: db1-vm2;Memory;OK;HARD;1;OK - 88.3% (21797956 kB) free.
[1574706600] CURRENT SERVICE STATE: db1-vm2;OutOfMemory-killer--oom-killer;OK;HARD;1;Log check ok - 0 pattern matches found
[1574706600] CURRENT SERVICE STATE: db1-vm2;PING;OK;HARD;1;PING OK - Packet loss = 0%, RTA = 0.05 ms
[1574706600] CURRENT SERVICE STATE: db1-vm2;Total Processes;OK;HARD;1;PROCS OK: 461 processes
[1574706600] CURRENT SERVICE STATE: db2;CPU Load;OK;HARD;1;OK - load average: 0.78, 0.54, 0.26
[1574706600] CURRENT SERVICE STATE: db2;CPU_Procs;OK;HARD;1;CPU OK: 325 processes
[1574706600] CURRENT SERVICE STATE: db2;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1574706600] CURRENT SERVICE STATE: db2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 90228 MB (40% inode=99%):
[1574706600] CURRENT SERVICE STATE: db2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44500 MB (86% inode=99%):
[1574706600] CURRENT SERVICE STATE: db2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: db2;Mariadb status;OK;HARD;1;PROCS OK: 1 process with command name 'mysqld'
[1574706600] CURRENT SERVICE STATE: db2;Memory;OK;HARD;1;OK - 45.3% (22344820 kB) free.
[1574706600] CURRENT SERVICE STATE: db2;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: db2;Total Processes;OK;HARD;1;PROCS OK: 325 processes
[1574706600] CURRENT SERVICE STATE: primary-server;CPU Load;OK;HARD;1;OK - load average: 0.79, 0.61, 0.34
[1574706600] CURRENT SERVICE STATE: primary-server;CPU_Procs;OK;HARD;1;CPU OK: 342 processes
[1574706600] CURRENT SERVICE STATE: primary-server;Current Users;OK;HARD;1;USERS OK - 3 users currently logged in
[1574706600] CURRENT SERVICE STATE: primary-server;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 148464 MB (66% inode=99%):
[1574706600] CURRENT SERVICE STATE: primary-server;HDD_Root status;OK;HARD;1;DISK OK - free space: / 30086 MB (58% inode=99%):
[1574706600] CURRENT SERVICE STATE: primary-server;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: primary-server;Memory;OK;HARD;1;OK - 87.3% (21400884 kB) free.
[1574706600] CURRENT SERVICE STATE: primary-server;Nginx Access Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574706600] CURRENT SERVICE STATE: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574706600] CURRENT SERVICE STATE: primary-server;Nginx Status;OK;HARD;1;NGINX OK -  0.093 sec. response time, Active: 0 (Writing: 0 Reading: 0 Waiting: 0) ReqPerSec: 0.000 ConnPerSec: 0.000 ReqPerConn: 0.000
[1574706600] CURRENT SERVICE STATE: primary-server;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: primary-server;Total Processes;OK;HARD;1;PROCS OK: 342 processes
[1574706600] CURRENT SERVICE STATE: pservercluster1;CPU Load;OK;HARD;1;OK - load average: 0.47, 0.65, 1.28
[1574706600] CURRENT SERVICE STATE: pservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 362 processes
[1574706600] CURRENT SERVICE STATE: pservercluster1;Current Users;OK;HARD;1;USERS OK - 7 users currently logged in
[1574706600] CURRENT SERVICE STATE: pservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 192189 MB (87% inode=99%):
[1574706600] CURRENT SERVICE STATE: pservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40238 MB (78% inode=99%):
[1574706600] CURRENT SERVICE STATE: pservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: pservercluster1;Memory;OK;HARD;1;OK - 23.4% (5775364 kB) free.
[1574706600] CURRENT SERVICE STATE: pservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: pservercluster1;Total Processes;OK;HARD;1;PROCS OK: 365 processes
[1574706600] CURRENT SERVICE STATE: pservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.61, 0.79, 1.18
[1574706600] CURRENT SERVICE STATE: pservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 357 processes
[1574706600] CURRENT SERVICE STATE: pservercluster2;Current Users;OK;HARD;1;USERS OK - 3 users currently logged in
[1574706600] CURRENT SERVICE STATE: pservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 155622 MB (69% inode=99%):
[1574706600] CURRENT SERVICE STATE: pservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 38733 MB (75% inode=98%):
[1574706600] CURRENT SERVICE STATE: pservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: pservercluster2;Memory;OK;HARD;1;OK - 37.9% (9297208 kB) free.
[1574706600] CURRENT SERVICE STATE: pservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: pservercluster2;Total Processes;OK;HARD;1;PROCS OK: 358 processes
[1574706600] CURRENT SERVICE STATE: qservercluster1;CPU Load;OK;HARD;1;OK - load average: 8.44, 6.12, 5.52
[1574706600] CURRENT SERVICE STATE: qservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 329 processes
[1574706600] CURRENT SERVICE STATE: qservercluster1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1574706600] CURRENT SERVICE STATE: qservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 224641 MB (99% inode=99%):
[1574706600] CURRENT SERVICE STATE: qservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44471 MB (86% inode=99%):
[1574706600] CURRENT SERVICE STATE: qservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: qservercluster1;Memory;OK;HARD;1;OK - 88.2% (43439520 kB) free.
[1574706600] CURRENT SERVICE STATE: qservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: qservercluster1;Total Processes;OK;HARD;1;PROCS OK: 330 processes
[1574706600] CURRENT SERVICE STATE: qservercluster2;CPU Load;OK;HARD;1;OK - load average: 1.61, 1.48, 1.50
[1574706600] CURRENT SERVICE STATE: qservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 546 processes
[1574706600] CURRENT SERVICE STATE: qservercluster2;Current Users;OK;HARD;1;USERS OK - 5 users currently logged in
[1574706600] CURRENT SERVICE STATE: qservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 141061 MB (62% inode=99%):
[1574706600] CURRENT SERVICE STATE: qservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 27078 MB (52% inode=98%):
[1574706600] CURRENT SERVICE STATE: qservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: qservercluster2;Memory;OK;HARD;1;OK - 71.3% (35160412 kB) free.
[1574706600] CURRENT SERVICE STATE: qservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: qservercluster2;Total Processes;OK;HARD;1;PROCS OK: 548 processes
[1574706600] CURRENT SERVICE STATE: redis-1;CPU Load;OK;HARD;1;OK - load average: 1.02, 1.05, 0.90
[1574706600] CURRENT SERVICE STATE: redis-1;CPU_Procs;OK;HARD;1;CPU OK: 399 processes
[1574706600] CURRENT SERVICE STATE: redis-1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1574706600] CURRENT SERVICE STATE: redis-1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 367262 MB (98% inode=99%):
[1574706600] CURRENT SERVICE STATE: redis-1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44413 MB (86% inode=99%):
[1574706600] CURRENT SERVICE STATE: redis-1;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /vns1 307825 MB (28% inode=99%):
[1574706600] CURRENT SERVICE STATE: redis-1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: redis-1;Memory;OK;HARD;1;OK - 49.9% (65736128 kB) free.
[1574706600] CURRENT SERVICE STATE: redis-1;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: redis-1;Total Processes;OK;HARD;1;PROCS OK: 400 processes
[1574706600] CURRENT SERVICE STATE: redis-2;CPU Load;OK;HARD;1;OK - load average: 1.01, 1.04, 1.11
[1574706600] CURRENT SERVICE STATE: redis-2;CPU_Procs;OK;HARD;1;CPU OK: 384 processes
[1574706600] CURRENT SERVICE STATE: redis-2;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1574706600] CURRENT SERVICE STATE: redis-2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 319219 MB (85% inode=99%):
[1574706600] CURRENT SERVICE STATE: redis-2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44454 MB (86% inode=99%):
[1574706600] CURRENT SERVICE STATE: redis-2;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /vns1 1069171 MB (99% inode=99%):
[1574706600] CURRENT SERVICE STATE: redis-2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: redis-2;Memory;OK;HARD;1;OK - 22.4% (29477208 kB) free.
[1574706600] CURRENT SERVICE STATE: redis-2;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: redis-2;Total Processes;OK;HARD;1;PROCS OK: 381 processes
[1574706600] CURRENT SERVICE STATE: rq-1;CPU Load;OK;HARD;1;OK - load average: 16.10, 15.76, 15.76
[1574706600] CURRENT SERVICE STATE: rq-1;CPU_Procs;OK;HARD;1;CPU OK: 356 processes
[1574706600] CURRENT SERVICE STATE: rq-1;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1574706600] CURRENT SERVICE STATE: rq-1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 400998 MB (99% inode=99%):
[1574706600] CURRENT SERVICE STATE: rq-1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 42605 MB (83% inode=99%):
[1574706600] CURRENT SERVICE STATE: rq-1;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /rq1vns1 1068147 MB (99% inode=99%):
[1574706600] CURRENT SERVICE STATE: rq-1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: rq-1;Memory;OK;HARD;1;OK - 83.0% (109397332 kB) free.
[1574706600] CURRENT SERVICE STATE: rq-1;Total Processes;OK;HARD;1;PROCS OK: 358 processes
[1574706600] CURRENT SERVICE STATE: rq-1;rq1-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1574706600] CURRENT SERVICE STATE: rq-2;CPU Load;OK;HARD;1;OK - load average: 15.23, 15.45, 15.35
[1574706600] CURRENT SERVICE STATE: rq-2;CPU_Procs;OK;HARD;1;CPU OK: 384 processes
[1574706600] CURRENT SERVICE STATE: rq-2;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1574706600] CURRENT SERVICE STATE: rq-2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 401206 MB (99% inode=99%):
[1574706600] CURRENT SERVICE STATE: rq-2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 45597 MB (89% inode=99%):
[1574706600] CURRENT SERVICE STATE: rq-2;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /dev 64349 MB (100% inode=99%):
[1574706600] CURRENT SERVICE STATE: rq-2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 2 processes with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: rq-2;Memory;OK;HARD;1;OK - 93.6% (123383116 kB) free.
[1574706600] CURRENT SERVICE STATE: rq-2;Total Processes;OK;HARD;1;PROCS OK: 382 processes
[1574706600] CURRENT SERVICE STATE: rq-2;rq2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1574706600] CURRENT SERVICE STATE: secondary-server;CPU Load;OK;HARD;1;OK - load average: 0.16, 0.52, 0.50
[1574706600] CURRENT SERVICE STATE: secondary-server;CPU_Procs;OK;HARD;1;CPU OK: 341 processes
[1574706600] CURRENT SERVICE STATE: secondary-server;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1574706600] CURRENT SERVICE STATE: secondary-server;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 172973 MB (76% inode=99%):
[1574706600] CURRENT SERVICE STATE: secondary-server;HDD_Root status;OK;HARD;1;DISK OK - free space: / 37306 MB (72% inode=99%):
[1574706600] CURRENT SERVICE STATE: secondary-server;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: secondary-server;Memory Status;OK;HARD;1;OK - 69.9% (17139540 kB) free.
[1574706600] CURRENT SERVICE STATE: secondary-server;Nginx Access Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574706600] CURRENT SERVICE STATE: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574706600] CURRENT SERVICE STATE: secondary-server;Nginx Status;OK;HARD;1;NGINX OK -  0.087 sec. response time, Active: 0 (Writing: 0 Reading: 0 Waiting: 0) ReqPerSec: 0.000 ConnPerSec: 0.000 ReqPerConn: 0.000
[1574706600] CURRENT SERVICE STATE: secondary-server;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: secondary-server;Total Processes;OK;HARD;1;PROCS OK: 340 processes
[1574706600] CURRENT SERVICE STATE: sig1-vm2;CPU Load;OK;HARD;1;OK - load average: 0.02, 0.01, 0.00
[1574706600] CURRENT SERVICE STATE: sig1-vm2;CPU_Procs;OK;HARD;1;CPU OK: 266 processes
[1574706600] CURRENT SERVICE STATE: sig1-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1574706600] CURRENT SERVICE STATE: sig1-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 2 processes with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: sig1-vm2;Memory;OK;HARD;1;OK - 71.9% (11750156 kB) free.
[1574706600] CURRENT SERVICE STATE: sig1-vm2;Root status;OK;HARD;1;DISK OK - free space: / 125257 MB (93% inode=97%):
[1574706600] CURRENT SERVICE STATE: sig1-vm2;Total Processes;OK;HARD;1;PROCS OK: 263 processes
[1574706600] CURRENT SERVICE STATE: sig2-vm2;CPU Load;OK;HARD;1;OK - load average: 1.43, 2.69, 2.53
[1574706600] CURRENT SERVICE STATE: sig2-vm2;CPU_Procs;OK;HARD;1;CPU OK: 456 processes
[1574706600] CURRENT SERVICE STATE: sig2-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1574706600] CURRENT SERVICE STATE: sig2-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 122947 MB (88% inode=99%):
[1574706600] CURRENT SERVICE STATE: sig2-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: sig2-vm2;Memory;OK;HARD;1;OK - 88.9% (30976900 kB) free.
[1574706600] CURRENT SERVICE STATE: sig2-vm2;Total Processes;OK;HARD;1;PROCS OK: 460 processes
[1574706600] CURRENT SERVICE STATE: sig3-vm2;CPU Load;OK;HARD;1;OK - load average: 0.14, 0.23, 0.10
[1574706600] CURRENT SERVICE STATE: sig3-vm2;CPU_Procs;OK;HARD;1;CPU OK: 549 processes
[1574706600] CURRENT SERVICE STATE: sig3-vm2;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1574706600] CURRENT SERVICE STATE: sig3-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 90163 MB (75% inode=96%):
[1574706600] CURRENT SERVICE STATE: sig3-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 2 processes with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: sig3-vm2;Memory;OK;HARD;1;OK - 95.6% (22522712 kB) free.
[1574706600] CURRENT SERVICE STATE: sig3-vm2;Total Processes;OK;HARD;1;PROCS OK: 550 processes
[1574706600] CURRENT SERVICE STATE: sig4-vm2;CPU Load;OK;HARD;1;OK - load average: 0.19, 0.07, 0.09
[1574706600] CURRENT SERVICE STATE: sig4-vm2;CPU_Procs;OK;HARD;1;CPU OK: 239 processes
[1574706600] CURRENT SERVICE STATE: sig4-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1574706600] CURRENT SERVICE STATE: sig4-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 97426 MB (75% inode=99%):
[1574706600] CURRENT SERVICE STATE: sig4-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: sig4-vm2;Memory;OK;HARD;1;OK - 87.3% (30411672 kB) free.
[1574706600] CURRENT SERVICE STATE: sig4-vm2;Total Processes;OK;HARD;1;PROCS OK: 239 processes
[1574706600] CURRENT SERVICE STATE: sig5-vm2;CPU Load;OK;HARD;1;OK - load average: 2.57, 3.35, 2.84
[1574706600] CURRENT SERVICE STATE: sig5-vm2;CPU_Procs;OK;HARD;1;CPU OK: 461 processes
[1574706600] CURRENT SERVICE STATE: sig5-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1574706600] CURRENT SERVICE STATE: sig5-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 230627 MB (91% inode=99%):
[1574706600] CURRENT SERVICE STATE: sig5-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: sig5-vm2;Memory;OK;HARD;1;OK - 87.1% (30488868 kB) free.
[1574706600] CURRENT SERVICE STATE: sig5-vm2;Total Processes;OK;HARD;1;PROCS OK: 464 processes
[1574706600] CURRENT SERVICE STATE: sig6-vm2;CPU Load;OK;HARD;1;OK - load average: 2.53, 2.80, 2.50
[1574706600] CURRENT SERVICE STATE: sig6-vm2;CPU_Procs;OK;HARD;1;CPU OK: 498 processes
[1574706600] CURRENT SERVICE STATE: sig6-vm2;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1574706600] CURRENT SERVICE STATE: sig6-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 178634 MB (91% inode=99%):
[1574706600] CURRENT SERVICE STATE: sig6-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: sig6-vm2;Memory;OK;HARD;1;OK - 78.2% (17551476 kB) free.
[1574706600] CURRENT SERVICE STATE: sig6-vm2;OutOfMemory-killer--oom-killer;OK;HARD;1;Log check ok - 0 pattern matches found
[1574706600] CURRENT SERVICE STATE: sig6-vm2;Total Processes;OK;HARD;1;PROCS OK: 497 processes
[1574706600] CURRENT SERVICE STATE: sigqscluster1;CPU Load;OK;HARD;1;OK - load average: 0.05, 0.04, 0.21
[1574706600] CURRENT SERVICE STATE: sigqscluster1;CPU_Procs;OK;HARD;1;CPU OK: 354 processes
[1574706600] CURRENT SERVICE STATE: sigqscluster1;Current Users;OK;HARD;1;USERS OK - 7 users currently logged in
[1574706600] CURRENT SERVICE STATE: sigqscluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 224102 MB (99% inode=99%):
[1574706600] CURRENT SERVICE STATE: sigqscluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 41020 MB (80% inode=99%):
[1574706600] CURRENT SERVICE STATE: sigqscluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: sigqscluster1;Memory;OK;HARD;1;OK - 47.9% (23630088 kB) free.
[1574706600] CURRENT SERVICE STATE: sigqscluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: sigqscluster1;Total Processes;OK;HARD;1;PROCS OK: 352 processes
[1574706600] CURRENT SERVICE STATE: sigqscluster2;CPU Load;OK;HARD;1;OK - load average: 12.70, 11.53, 11.32
[1574706600] CURRENT SERVICE STATE: sigqscluster2;CPU_Procs;OK;HARD;1;CPU OK: 300 processes
[1574706600] CURRENT SERVICE STATE: sigqscluster2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1574706600] CURRENT SERVICE STATE: sigqscluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 208589 MB (99% inode=99%):
[1574706600] CURRENT SERVICE STATE: sigqscluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 45497 MB (88% inode=99%):
[1574706600] CURRENT SERVICE STATE: sigqscluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: sigqscluster2;Memory;OK;HARD;1;OK - 84.6% (41716284 kB) free.
[1574706600] CURRENT SERVICE STATE: sigqscluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: sigqscluster2;Total Processes;OK;HARD;1;PROCS OK: 300 processes
[1574706600] CURRENT SERVICE STATE: sigqscluster2;sigqscluster2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1574706600] CURRENT SERVICE STATE: smscapp1;CPU Load;OK;HARD;1;OK - load average: 1.96, 1.60, 1.67
[1574706600] CURRENT SERVICE STATE: smscapp1;CPU_Procs;OK;HARD;1;CPU OK: 649 processes
[1574706600] CURRENT SERVICE STATE: smscapp1;Current Users;OK;HARD;1;USERS OK - 3 users currently logged in
[1574706600] CURRENT SERVICE STATE: smscapp1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 116551 MB (51% inode=99%):
[1574706600] CURRENT SERVICE STATE: smscapp1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39127 MB (76% inode=98%):
[1574706600] CURRENT SERVICE STATE: smscapp1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: smscapp1;Memory;OK;HARD;1;OK - 46.8% (23065636 kB) free.
[1574706600] CURRENT SERVICE STATE: smscapp1;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: smscapp1;Total Processes;OK;HARD;1;PROCS OK: 650 processes
[1574706600] CURRENT SERVICE STATE: smscapp2;CPU Load;OK;HARD;1;OK - load average: 2.24, 1.96, 2.47
[1574706600] CURRENT SERVICE STATE: smscapp2;CPU_Procs;OK;HARD;1;CPU OK: 555 processes
[1574706600] CURRENT SERVICE STATE: smscapp2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1574706600] CURRENT SERVICE STATE: smscapp2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 208914 MB (92% inode=99%):
[1574706600] CURRENT SERVICE STATE: smscapp2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 38725 MB (75% inode=98%):
[1574706600] CURRENT SERVICE STATE: smscapp2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: smscapp2;Memory;OK;HARD;1;OK - 91.7% (45204816 kB) free.
[1574706600] CURRENT SERVICE STATE: smscapp2;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: smscapp2;Total Processes;OK;HARD;1;PROCS OK: 1144 processes
[1574706600] CURRENT SERVICE STATE: sservercluster1;CPU Load;OK;HARD;1;OK - load average: 1.85, 5.64, 5.18
[1574706600] CURRENT SERVICE STATE: sservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 343 processes
[1574706600] CURRENT SERVICE STATE: sservercluster1;Current Users;OK;HARD;1;USERS OK - 4 users currently logged in
[1574706600] CURRENT SERVICE STATE: sservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 159982 MB (72% inode=99%):
[1574706600] CURRENT SERVICE STATE: sservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 41321 MB (80% inode=99%):
[1574706600] CURRENT SERVICE STATE: sservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: sservercluster1;Memory;WARNING;HARD;3;WARNING - 11.4% (2797516 kB) free!
[1574706600] CURRENT SERVICE STATE: sservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: sservercluster1;Total Processes;OK;HARD;1;PROCS OK: 343 processes
[1574706600] CURRENT SERVICE STATE: sservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.92, 0.79, 1.38
[1574706600] CURRENT SERVICE STATE: sservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 346 processes
[1574706600] CURRENT SERVICE STATE: sservercluster2;Current Users;OK;HARD;1;USERS OK - 3 users currently logged in
[1574706600] CURRENT SERVICE STATE: sservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 181325 MB (82% inode=99%):
[1574706600] CURRENT SERVICE STATE: sservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 35617 MB (69% inode=98%):
[1574706600] CURRENT SERVICE STATE: sservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: sservercluster2;Memory;OK;HARD;1;OK - 63.7% (15615940 kB) free.
[1574706600] CURRENT SERVICE STATE: sservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: sservercluster2;Total Processes;OK;HARD;1;PROCS OK: 347 processes
[1574706600] CURRENT SERVICE STATE: webserver1;CPU Load;OK;HARD;1;OK - load average: 0.80, 0.78, 0.56
[1574706600] CURRENT SERVICE STATE: webserver1;CPU_Procs;OK;HARD;1;CPU OK: 361 processes
[1574706600] CURRENT SERVICE STATE: webserver1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1574706600] CURRENT SERVICE STATE: webserver1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 224832 MB (99% inode=99%):
[1574706600] CURRENT SERVICE STATE: webserver1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40274 MB (78% inode=99%):
[1574706600] CURRENT SERVICE STATE: webserver1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: webserver1;Memory;OK;HARD;1;OK - 88.9% (21747776 kB) free.
[1574706600] CURRENT SERVICE STATE: webserver1;Nginx_status;OK;HARD;1;NGINX OK -  0.088 sec. response time, Active: 1 (Writing: 1 Reading: 0 Waiting: 0) ReqPerSec: 0.002 ConnPerSec: 0.002 ReqPerConn: 1.019
[1574706600] CURRENT SERVICE STATE: webserver1;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: webserver1;Total Processes;OK;HARD;1;PROCS OK: 361 processes
[1574706600] CURRENT SERVICE STATE: webserver2;CPU_Procs;OK;HARD;1;CPU OK: 452 processes
[1574706600] CURRENT SERVICE STATE: webserver2;Current Load;OK;HARD;1;OK - load average: 0.10, 0.07, 0.05
[1574706600] CURRENT SERVICE STATE: webserver2;Current Users;OK;HARD;1;USERS OK - 29 users currently logged in
[1574706600] CURRENT SERVICE STATE: webserver2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 66185 MB (29.44% inode=100%):
[1574706600] CURRENT SERVICE STATE: webserver2;HTTP;OK;HARD;1;HTTP OK: HTTP/1.1 200 OK - 355 bytes in 0.001 second response time
[1574706600] CURRENT SERVICE STATE: webserver2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: webserver2;Memory;OK;HARD;1;OK - 52.3% (12823668 kB) free.
[1574706600] CURRENT SERVICE STATE: webserver2;PING;OK;HARD;1;PING OK - Packet loss = 0%, RTA = 0.06 ms
[1574706600] CURRENT SERVICE STATE: webserver2;Root Partition;OK;HARD;1;DISK OK - free space: / 18703 MB (36.54% inode=99%):
[1574706600] CURRENT SERVICE STATE: webserver2;SSH;OK;HARD;1;SSH OK - OpenSSH_7.4 (protocol 2.0)
[1574706600] CURRENT SERVICE STATE: webserver2;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: webserver2;Total Processes;OK;HARD;1;PROCS OK: 161 processes with STATE = RSZDT
[1574706600] CURRENT SERVICE STATE: webservercluster1;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.01, 0.05
[1574706600] CURRENT SERVICE STATE: webservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 382 processes
[1574706600] CURRENT SERVICE STATE: webservercluster1;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1574706600] CURRENT SERVICE STATE: webservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: / 22460 MB (43% inode=99%):
[1574706600] CURRENT SERVICE STATE: webservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: /home 123743 MB (55% inode=99%):
[1574706600] CURRENT SERVICE STATE: webservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: webservercluster1;Memory;OK;HARD;1;OK - 88.8% (14437704 kB) free.
[1574706600] CURRENT SERVICE STATE: webservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: webservercluster1;Total Processes;OK;HARD;1;PROCS OK: 376 processes
[1574706600] CURRENT SERVICE STATE: webservercluster2;CPU Load;OK;HARD;1;OK - load average: 1.53, 1.46, 1.48
[1574706600] CURRENT SERVICE STATE: webservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 326 processes
[1574706600] CURRENT SERVICE STATE: webservercluster2;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1574706600] CURRENT SERVICE STATE: webservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 222948 MB (99% inode=99%):
[1574706600] CURRENT SERVICE STATE: webservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40280 MB (78% inode=99%):
[1574706600] CURRENT SERVICE STATE: webservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1574706600] CURRENT SERVICE STATE: webservercluster2;Memory;OK;HARD;1;OK - 51.5% (8376172 kB) free.
[1574706600] CURRENT SERVICE STATE: webservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1574706600] CURRENT SERVICE STATE: webservercluster2;Total Processes;OK;HARD;1;PROCS OK: 327 processes
[1574706945] SERVICE ALERT: pservercluster2;Memory;WARNING;SOFT;1;WARNING - 19.7% (4817892 kB) free!
[1574706972] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(38) < 2019/11/26 00:01:52 [error] 24130#0: *9478235 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574706998] SERVICE ALERT: sservercluster2;Memory;WARNING;SOFT;1;WARNING - 10.8% (2658216 kB) free!
[1574707073] SERVICE ALERT: pservercluster2;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (188408 kB) free!
[1574707093] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574707118] SERVICE ALERT: sservercluster2;Memory;CRITICAL;SOFT;2;CRITICAL - 0.7% (163924 kB) free!
[1574707154] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.8% (187204 kB) free!
[1574707178] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1574707194] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (204652 kB) free!
[1574707194] SERVICE ALERT: pservercluster2;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (204652 kB) free!
[1574707238] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (204316 kB) free!
[1574707238] SERVICE ALERT: sservercluster2;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (204316 kB) free!
[1574707266] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (175296 kB) free!
[1574707266] SERVICE ALERT: sservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.7% (175296 kB) free!
[1574707274] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.7% (184304 kB) free!
[1574707300] SERVICE ALERT: pservercluster2;CPU Load;OK;HARD;1;OK - load average: 1.97, 3.20, 3.63
[1574707394] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (194116 kB) free!
[1574707394] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (194116 kB) free!
[1574707692] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(25) < 2019/11/26 00:08:34 [error] 24131#0: *9479473 recv() failed (104: Connection reset by peer) while proxying connection, client: 94.237.68.73, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:39/0, bytes from/to upstream:0/39
[1574707812] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574708294] Auto-save of retention data completed successfully.
[1574708412] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(23) < 2019/11/26 00:23:34 [error] 24130#0: *9482245 recv() failed (104: Connection reset by peer) while proxying connection, client: 169.38.76.212, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:43/0, bytes from/to upstream:0/43
[1574708532] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574709132] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(50) < 2019/11/26 00:37:50 [error] 24130#0: *9484915 recv() failed (104: Connection reset by peer) while proxying connection, client: 94.237.68.73, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:39/0, bytes from/to upstream:0/39
[1574709194] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;OK;notify-service-by-email;OK - 58.5% (14428952 kB) free.
[1574709194] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 58.5% (14428952 kB) free.
[1574709252] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574709281] SERVICE ALERT: redis-1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 400 processes
[1574709401] SERVICE ALERT: redis-1;CPU_Procs;OK;HARD;1;CPU OK: 400 processes
[1574709727] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(140) < 2019/11/26 00:48:25 [error] 26850#0: *9889765 upstream timed out (110: Connection timed out) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574709847] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574709852] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(20) < 2019/11/26 00:44:40 [error] 24130#0: *9486279 connect() failed (111: Connection refused) while connecting to upstream, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574709906] SERVICE ALERT: secondary-server;Nginx Access Log Status;CRITICAL;SOFT;1;(16) < 103.16.101.72 [26/Nov/2019:00:47:18 +0530] TCP 502 0 0 0.000 "backend3" "0" "0" "0.000"
[1574709973] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574710027] SERVICE ALERT: secondary-server;Nginx Access Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574710572] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(20) < 2019/11/26 00:58:19 [error] 24130#0: *9488836 recv() failed (104: Connection reset by peer) while proxying connection, client: 94.237.68.73, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:39/0, bytes from/to upstream:0/39
[1574710692] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574710794] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.4% (340568 kB) free!
[1574710838] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.3% (328232 kB) free!
[1574710866] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.2% (282404 kB) free!
[1574710994] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.8% (196104 kB) free!
[1574711114] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (198276 kB) free!
[1574711234] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (187524 kB) free!
[1574711234] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (187524 kB) free!
[1574711292] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(33) < 2019/11/26 01:13:40 [error] 24130#0: *9491728 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574711412] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(19) < 2019/11/26 01:19:19 [error] 24130#0: *9492833 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.218.150, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:38/0, bytes from/to upstream:0/38
[1574711532] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574711894] Auto-save of retention data completed successfully.
[1574712132] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(2) < 2019/11/26 01:30:43 [error] 24130#0: *9495023 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.143:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574712253] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(24) < 2019/11/26 01:34:05 [error] 24130#0: *9495560 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574712373] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574713573] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(69) < 2019/11/26 01:54:48 [error] 24130#0: *9499490 recv() failed (104: Connection reset by peer) while proxying connection, client: 169.38.76.212, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:43/0, bytes from/to upstream:0/43
[1574713634] SERVICE FLAPPING ALERT: pservercluster1;Memory;STARTED; Service appears to have started flapping (22.2% change >= 20.0% threshold)
[1574713634] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 49.5% (12203804 kB) free.
[1574713693] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574714394] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 2.9% (712672 kB) free!
[1574714438] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.4% (334628 kB) free!
[1574714466] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.4% (334524 kB) free!
[1574714834] SERVICE ALERT: pservercluster1;Memory;WARNING;SOFT;1;WARNING - 19.7% (4866404 kB) free!
[1574714893] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(24) < 2019/11/26 02:08:57 [error] 24130#0: *9502142 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574714954] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (192220 kB) free!
[1574715014] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574715074] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (196064 kB) free!
[1574715384] SERVICE ALERT: smscapp1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.5% (233452 kB) free!
[1574715494] Auto-save of retention data completed successfully.
[1574715504] SERVICE ALERT: smscapp1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.5% (233772 kB) free!
[1574715613] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(38) < 2019/11/26 02:27:00 [error] 24130#0: *9505575 connect() failed (111: Connection refused) while connecting to upstream, client: 185.255.8.58, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574715624] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (237568 kB) free!
[1574715624] SERVICE ALERT: smscapp1;Memory;CRITICAL;HARD;3;CRITICAL - 0.5% (237568 kB) free!
[1574715733] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(20) < 2019/11/26 02:31:50 [error] 24130#0: *9506507 connect() failed (111: Connection refused) while connecting to upstream, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574715853] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574716001] SERVICE ALERT: redis-1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 401 processes
[1574716121] SERVICE ALERT: redis-1;CPU_Procs;OK;HARD;1;CPU OK: 400 processes
[1574716224] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;OK;notify-service-by-email;OK - 80.3% (39568056 kB) free.
[1574716224] SERVICE ALERT: smscapp1;Memory;OK;HARD;1;OK - 80.3% (39568056 kB) free.
[1574717053] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(23) < 2019/11/26 02:44:39 [error] 24131#0: *9508819 recv() failed (104: Connection reset by peer) while proxying connection, client: 94.237.68.73, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:39/0, bytes from/to upstream:0/39
[1574717173] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574717608] SERVICE ALERT: pservercluster2;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 369 processes
[1574717728] SERVICE ALERT: pservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 385 processes
[1574717774] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(41) < 2019/11/26 03:03:47 [error] 24130#0: *9512486 recv() failed (104: Connection reset by peer) while proxying connection, client: 94.237.68.73, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:39/0, bytes from/to upstream:0/39
[1574717894] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574717994] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 2.5% (605108 kB) free!
[1574718038] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.5% (364736 kB) free!
[1574718066] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.0% (253172 kB) free!
[1574718120] SERVICE ALERT: redis-2;Memory;WARNING;SOFT;1;WARNING - 18.4% (24207320 kB) free!
[1574718240] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 31.3% (41290540 kB) free.
[1574718494] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(19) < 2019/11/26 03:10:03 [error] 24130#0: *9513673 connect() failed (111: Connection refused) while connecting to upstream, client: 169.38.76.212, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574718614] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574719094] Auto-save of retention data completed successfully.
[1574719814] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(47) < 2019/11/26 03:39:50 [error] 24130#0: *9519245 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574719934] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574720535] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(15) < 2019/11/26 03:46:44 [error] 24130#0: *9520552 recv() failed (104: Connection reset by peer) while proxying connection, client: 94.237.68.73, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:39/0, bytes from/to upstream:0/39
[1574720655] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(29) < 2019/11/26 03:53:08 [error] 24130#0: *9521751 recv() failed (104: Connection reset by peer) while proxying connection, client: 94.237.65.17, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:39/0, bytes from/to upstream:0/39
[1574720775] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574721594] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.2% (285384 kB) free!
[1574721638] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.5% (362408 kB) free!
[1574721666] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.1% (270900 kB) free!
[1574721975] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(50) < 2019/11/26 04:15:05 [error] 24130#0: *9525874 recv() failed (104: Connection reset by peer) while proxying connection, client: 94.237.65.17, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:39/0, bytes from/to upstream:0/39
[1574722095] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574722694] Auto-save of retention data completed successfully.
[1574722695] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(20) < 2019/11/26 04:22:49 [error] 24125#0: *9527346 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574722816] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(26) < 2019/11/26 04:28:36 [error] 24130#0: *9528413 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574722936] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574724136] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(42) < 2019/11/26 04:51:15 [error] 24130#0: *9532695 recv() failed (104: Connection reset by peer) while proxying connection, client: 94.237.65.17, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:39/0, bytes from/to upstream:0/39
[1574724256] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574724521] SERVICE ALERT: redis-1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 402 processes
[1574724641] SERVICE ALERT: redis-1;CPU_Procs;OK;HARD;1;CPU OK: 401 processes
[1574724856] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(51) < 2019/11/26 05:02:25 [error] 24130#0: *9534788 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574724976] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574725194] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.1% (263708 kB) free!
[1574725238] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.2% (299172 kB) free!
[1574725266] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.4% (347536 kB) free!
[1574725874] SERVICE FLAPPING ALERT: pservercluster1;Memory;STOPPED; Service appears to have stopped flapping (3.9% change < 5.0% threshold)
[1574725874] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.2% (286484 kB) free!
[1574726177] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(20) < 2019/11/26 05:23:46 [error] 24130#0: *9538795 recv() failed (104: Connection reset by peer) while proxying connection, client: 103.209.99.7, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:43/0, bytes from/to upstream:0/43
[1574726294] Auto-save of retention data completed successfully.
[1574726297] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(22) < 2019/11/26 05:26:42 [error] 24133#0: *9539334 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574726417] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574727017] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(42) < 2019/11/26 05:39:10 [error] 24130#0: *9541688 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574727137] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574728337] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(23) < 2019/11/26 05:58:04 [error] 24130#0: *9545251 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574728458] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(22) < 2019/11/26 06:03:15 [error] 24130#0: *9546208 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574728578] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574728794] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (192580 kB) free!
[1574728813] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1574728811
[1574728813] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;OK;notify-service-by-email;OK - 79.7% (19660824 kB) free.
[1574728813] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 79.7% (19660824 kB) free.
[1574728817] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1574728816
[1574728838] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (171196 kB) free!
[1574728855] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Memory;1574728854
[1574728856] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;OK;notify-service-by-email;OK - 92.9% (22777988 kB) free.
[1574728856] SERVICE ALERT: pservercluster2;Memory;OK;HARD;1;OK - 92.9% (22777988 kB) free.
[1574728861] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Memory;1574728860
[1574728866] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Memory;1574728864
[1574728866] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (174668 kB) free!
[1574728916] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster1;Memory;1574728909
[1574728916] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;OK;notify-service-by-email;OK - 70.3% (17229680 kB) free.
[1574728916] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 70.3% (17229680 kB) free.
[1574728921] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster1;Memory;1574728919
[1574728926] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster1;Memory;1574728924
[1574728958] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster2;Memory;1574728957
[1574728958] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;OK;notify-service-by-email;OK - 94.4% (23128024 kB) free.
[1574728958] SERVICE ALERT: sservercluster2;Memory;OK;HARD;1;OK - 94.4% (23128024 kB) free.
[1574728962] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster2;Memory;1574728961
[1574728968] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster2;Memory;1574728966
[1574729178] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(50) < 2019/11/26 06:14:41 [error] 24130#0: *9548356 connect() failed (111: Connection refused) while connecting to upstream, client: 94.237.68.73, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574729298] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574729417] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.8% (194000 kB) free!
[1574729537] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (188772 kB) free!
[1574729647] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(3) < 2019/11/26 06:20:28 [error] 26844#0: *9991625 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:14001, upstream: "10.147.212.49:5001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574729657] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (194628 kB) free!
[1574729657] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (194628 kB) free!
[1574729767] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574729827] SERVICE ALERT: secondary-server;Nginx Access Log Status;CRITICAL;SOFT;1;(1) < 103.255.146.164 [26/Nov/2019:06:20:28 +0530] TCP 502 0 0 0.001 "10.147.212.38:5001, 10.147.212.37:5001, 10.147.212.49:5001" "0, 0, 0" "0, 0, 0" "0.000, 0.001, 0.000"
[1574729894] Auto-save of retention data completed successfully.
[1574729947] SERVICE ALERT: secondary-server;Nginx Access Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574730498] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(14) < 2019/11/26 06:37:02 [error] 24130#0: *9552571 connect() failed (111: Connection refused) while connecting to upstream, client: 103.209.99.7, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574730618] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(24) < 2019/11/26 06:39:24 [error] 24130#0: *9552977 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574730739] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574731338] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(51) < 2019/11/26 06:50:22 [error] 24130#0: *9555056 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574731458] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574731993] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1574731991
[1574731993] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;OK;notify-service-by-email;OK - 92.7% (22863940 kB) free.
[1574731993] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 92.7% (22863940 kB) free.
[1574731997] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1574731995
[1574732662] SERVICE ALERT: sservercluster2;CPU_Procs;CRITICAL;SOFT;1;CPU CRITICAL: 1 crit, 0 warn out of 347 processes
[1574732782] SERVICE ALERT: sservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 359 processes
[1574733258] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(53) < 2019/11/26 07:20:56 [error] 24130#0: *9560821 recv() failed (104: Connection reset by peer) while proxying connection, client: 103.209.99.7, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:43/0, bytes from/to upstream:0/43
[1574733378] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574733494] Auto-save of retention data completed successfully.
[1574733978] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(25) < 2019/11/26 07:26:35 [error] 24130#0: *9561875 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574734099] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574735298] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(43) < 2019/11/26 07:58:01 [error] 24130#0: *9567825 connect() failed (111: Connection refused) while connecting to upstream, client: 180.179.218.150, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574735418] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574736018] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(25) < 2019/11/26 08:01:28 [error] 24130#0: *9568460 recv() failed (104: Connection reset by peer) while proxying connection, client: 94.237.68.73, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:39/0, bytes from/to upstream:0/39
[1574736138] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574737094] Auto-save of retention data completed successfully.
[1574737339] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(46) < 2019/11/26 08:27:15 [error] 24130#0: *9573262 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574737459] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574738059] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(49) < 2019/11/26 08:36:53 [error] 24130#0: *9575068 recv() failed (104: Connection reset by peer) while proxying connection, client: 103.209.99.7, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:43/0, bytes from/to upstream:0/43
[1574738179] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574739379] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(46) < 2019/11/26 09:03:22 [error] 24130#0: *9580078 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574739499] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574739635] SERVICE ALERT: sigqscluster1;Memory;WARNING;SOFT;1;WARNING - 19.3% (9524836 kB) free!
[1574739755] SERVICE ALERT: sigqscluster1;Memory;WARNING;SOFT;2;WARNING - 19.6% (9637536 kB) free!
[1574739875] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;WARNING;notify-service-by-email;WARNING - 19.6% (9638256 kB) free!
[1574739875] SERVICE ALERT: sigqscluster1;Memory;WARNING;HARD;3;WARNING - 19.6% (9638256 kB) free!
[1574740099] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(41) < 2019/11/26 09:11:58 [error] 24132#0: *9581679 recv() failed (104: Connection reset by peer) while proxying connection, client: 169.38.76.212, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:43/0, bytes from/to upstream:0/43
[1574740220] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574740241] SERVICE ALERT: redis-1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 402 processes
[1574740361] SERVICE ALERT: redis-1;CPU_Procs;OK;HARD;1;CPU OK: 402 processes
[1574740694] Auto-save of retention data completed successfully.
[1574741419] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(40) < 2019/11/26 09:39:24 [error] 24130#0: *9586875 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574741539] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574742139] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(51) < 2019/11/26 09:46:31 [error] 24130#0: *9588212 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574742259] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574743460] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(19) < 2019/11/26 10:14:19 [error] 24130#0: *9593399 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574743475] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;WARNING;notify-service-by-email;WARNING - 16.5% (8153552 kB) free!
[1574743580] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(25) < 2019/11/26 10:15:36 [error] 24130#0: *9593676 connect() failed (111: Connection refused) while connecting to upstream, client: 169.38.76.212, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574743700] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574744294] Auto-save of retention data completed successfully.
[1574744300] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(57) < 2019/11/26 10:20:59 [error] 24130#0: *9594635 recv() failed (104: Connection reset by peer) while proxying connection, client: 169.38.76.212, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:43/0, bytes from/to upstream:0/43
[1574744420] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574745251] SERVICE ALERT: webservercluster1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 376 processes
[1574745371] SERVICE ALERT: webservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 376 processes
[1574745620] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(22) < 2019/11/26 10:50:19 [error] 24130#0: *9600203 connect() failed (111: Connection refused) while connecting to upstream, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574745741] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(32) < 2019/11/26 10:51:17 [error] 24130#0: *9600319 recv() failed (104: Connection reset by peer) while proxying connection, client: 103.209.99.7, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:43/0, bytes from/to upstream:0/43
[1574745797] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.8% (198052 kB) free!
[1574745861] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574745875] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (213400 kB) free!
[1574745875] SERVICE ALERT: sigqscluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.4% (213400 kB) free!
[1574745917] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (195436 kB) free!
[1574745968] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(4) < 2019/11/26 10:55:18 [error] 26849#0: *10092441 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:14001, upstream: "10.147.212.37:5001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574746037] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (193608 kB) free!
[1574746037] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (193608 kB) free!
[1574746088] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574746148] SERVICE ALERT: secondary-server;Nginx Access Log Status;CRITICAL;SOFT;1;(2) < 103.255.146.164 [26/Nov/2019:10:55:18 +0530] TCP 502 0 0 0.004 "10.147.212.38:5001, 10.147.212.49:5001, 10.147.212.37:5001" "0, 0, 0" "0, 0, 0" "0.001, 0.000, 0.003"
[1574746268] SERVICE ALERT: secondary-server;Nginx Access Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574746461] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(46) < 2019/11/26 10:56:41 [error] 24130#0: *9601350 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574746581] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574746688] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(4) < 2019/11/26 11:05:17 [error] 26848#0: *10097123 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:14001, upstream: "10.147.212.37:5001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574746808] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(1) < 2019/11/26 11:09:27 [error] 26847#0: *10099284 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574746869] SERVICE ALERT: secondary-server;Nginx Access Log Status;CRITICAL;SOFT;1;(4) < 103.255.146.164 [26/Nov/2019:11:10:17 +0530] TCP 502 0 0 0.001 "10.147.212.38:5001, 10.147.212.49:5001, 10.147.212.37:5001" "0, 0, 0" "0, 0, 0" "0.000, 0.001, 0.000"
[1574746928] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3) < 2019/11/26 11:10:17 [error] 26847#0: *10099718 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:14001, upstream: "10.147.212.37:5001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574746928] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;HARD;3;(3) < 2019/11/26 11:10:17 [error] 26847#0: *10099718 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:14001, upstream: "10.147.212.37:5001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574746989] SERVICE ALERT: secondary-server;Nginx Access Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574747181] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(2) < 2019/11/26 11:16:07 [error] 24131#0: *9605155 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 59.91.63.147, request: "GET / HTTP/1.1", upstream: "http://10.147.212.143:80/", host: "59.91.63.147"
[1574747301] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(4) < 2019/11/26 11:17:47 [error] 24130#0: *9605478 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 59.91.63.147, request: "GET / HTTP/1.1", upstream: "http://10.147.212.143:80/", host: "59.91.63.147"
[1574747421] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574747589] SERVICE ALERT: secondary-server;Nginx Access Log Status;CRITICAL;SOFT;1;(4) < 103.255.146.164 [26/Nov/2019:11:20:17 +0530] TCP 502 0 0 0.001 "10.147.212.38:5001, 10.147.212.49:5001, 10.147.212.37:5001" "0, 0, 0" "0, 0, 0" "0.001, 0.000, 0.000"
[1574747710] SERVICE ALERT: secondary-server;Nginx Access Log Status;CRITICAL;SOFT;2;(1) < 103.255.146.164 [26/Nov/2019:11:24:27 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1574747830] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1) < 103.255.146.164 [26/Nov/2019:11:25:17 +0530] TCP 502 0 0 0.001 "10.147.212.38:5001, 10.147.212.49:5001, 10.147.212.37:5001" "0, 0, 0" "0, 0, 0" "0.001, 0.000, 0.000"
[1574747830] SERVICE ALERT: secondary-server;Nginx Access Log Status;CRITICAL;HARD;3;(1) < 103.255.146.164 [26/Nov/2019:11:25:17 +0530] TCP 502 0 0 0.001 "10.147.212.38:5001, 10.147.212.49:5001, 10.147.212.37:5001" "0, 0, 0" "0, 0, 0" "0.001, 0.000, 0.000"
[1574747894] Auto-save of retention data completed successfully.
[1574748022] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(61) < 2019/11/26 11:28:44 [error] 24135#0: *9607609 connect() failed (111: Connection refused) while connecting to upstream, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574748142] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(28) < 2019/11/26 11:31:43 [error] 24134#0: *9608161 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574748262] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574748800] SERVICE ALERT: sig6-vm2;Memory;WARNING;SOFT;1;WARNING - 19.1% (4291192 kB) free!
[1574748920] SERVICE ALERT: sig6-vm2;Memory;WARNING;SOFT;2;WARNING - 17.6% (3962004 kB) free!
[1574749039] SERVICE ALERT: webservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 1.1% (182248 kB) free!
[1574749040] SERVICE NOTIFICATION: nagiosadmin;sig6-vm2;Memory;WARNING;notify-service-by-email;WARNING - 16.2% (3644632 kB) free!
[1574749040] SERVICE ALERT: sig6-vm2;Memory;WARNING;HARD;3;WARNING - 16.2% (3644632 kB) free!
[1574749159] SERVICE ALERT: webservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 1.0% (168164 kB) free!
[1574749246] SERVICE ALERT: rq-1;rq1-rabbitmqerror;CRITICAL;SOFT;1;(5) < {writer,send_failed,{error,timeout}}
[1574749279] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.0% (156192 kB) free!
[1574749279] SERVICE ALERT: webservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 1.0% (156192 kB) free!
[1574749367] SERVICE ALERT: rq-1;rq1-rabbitmqerror;CRITICAL;SOFT;2;(3) < {writer,send_failed,{error,timeout}}
[1574749475] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (233320 kB) free!
[1574749488] SERVICE ALERT: rq-1;rq1-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1574749637] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (172024 kB) free!
[1574749640] SERVICE NOTIFICATION: nagiosadmin;sig6-vm2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 10.0% (2254052 kB) free!
[1574749640] SERVICE ALERT: sig6-vm2;Memory;CRITICAL;HARD;3;CRITICAL - 10.0% (2254052 kB) free!
[1574750062] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(49) < 2019/11/26 12:02:49 [error] 24130#0: *9614171 connect() failed (111: Connection refused) while connecting to upstream, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574750182] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(20) < 2019/11/26 12:05:38 [error] 24129#0: *9614667 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574750189] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1574750187
[1574750189] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;OK;notify-service-by-email;OK - 92.5% (22827956 kB) free.
[1574750189] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 92.5% (22827956 kB) free.
[1574750194] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1574750193
[1574750236] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sig6-vm2;Memory;1574750234
[1574750236] SERVICE NOTIFICATION: nagiosadmin;sig6-vm2;Memory;OK;notify-service-by-email;OK - 84.7% (19022280 kB) free.
[1574750236] SERVICE ALERT: sig6-vm2;Memory;OK;HARD;1;OK - 84.7% (19022280 kB) free.
[1574750241] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sig6-vm2;Memory;1574750239
[1574750246] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sig6-vm2;Memory;1574750244
[1574750291] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sigqscluster1;Memory;1574750289
[1574750291] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;OK;notify-service-by-email;OK - 80.6% (39730136 kB) free.
[1574750291] SERVICE ALERT: sigqscluster1;Memory;OK;HARD;1;OK - 80.6% (39730136 kB) free.
[1574750296] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sigqscluster1;Memory;1574750294
[1574750303] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(25) < 2019/11/26 12:06:45 [error] 24130#0: *9614874 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574750303] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;HARD;3;(25) < 2019/11/26 12:06:45 [error] 24130#0: *9614874 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574750347] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;webservercluster1;Memory;1574750344
[1574750347] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Memory;OK;notify-service-by-email;OK - 89.2% (14501076 kB) free.
[1574750347] SERVICE ALERT: webservercluster1;Memory;OK;HARD;1;OK - 89.2% (14501076 kB) free.
[1574750352] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;webservercluster1;Memory;1574750351
[1574750466] SERVICE ALERT: pservercluster2;Memory;WARNING;SOFT;1;WARNING - 17.0% (4162104 kB) free!
[1574750528] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(8) < 2019/11/26 12:10:17 [error] 26844#0: *10135749 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:14001, upstream: "10.147.212.37:5001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574750586] SERVICE ALERT: pservercluster2;Memory;WARNING;SOFT;2;WARNING - 16.3% (3995452 kB) free!
[1574750706] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 15.5% (3810892 kB) free!
[1574750706] SERVICE ALERT: pservercluster2;Memory;WARNING;HARD;3;WARNING - 15.5% (3810892 kB) free!
[1574750902] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1574750902] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574751126] SERVICE ALERT: sservercluster1;Memory;WARNING;SOFT;1;WARNING - 20.0% (4890404 kB) free!
[1574751246] SERVICE ALERT: sservercluster1;Memory;WARNING;SOFT;2;WARNING - 19.6% (4792504 kB) free!
[1574751306] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (197376 kB) free!
[1574751306] SERVICE ALERT: pservercluster2;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (197376 kB) free!
[1574751366] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;WARNING;notify-service-by-email;WARNING - 19.1% (4670244 kB) free!
[1574751366] SERVICE ALERT: sservercluster1;Memory;WARNING;HARD;3;WARNING - 19.1% (4670244 kB) free!
[1574751430] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1) < 103.255.146.164 [26/Nov/2019:12:26:31 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1574751494] Auto-save of retention data completed successfully.
[1574751995] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 8.6% (2129476 kB) free!
[1574752102] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(25) < 2019/11/26 12:38:12 [error] 24132#0: *9620837 connect() failed (111: Connection refused) while connecting to upstream, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574752115] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 8.2% (2017504 kB) free!
[1574752222] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(54) < 2019/11/26 12:40:22 [error] 24131#0: *9621222 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574752235] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 7.9% (1949116 kB) free!
[1574752235] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 7.9% (1949116 kB) free!
[1574752328] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1574752328] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574752342] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(27) < 2019/11/26 12:42:09 [error] 24132#0: *9621556 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574752342] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;HARD;3;(27) < 2019/11/26 12:42:09 [error] 24132#0: *9621556 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574752630] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1574752630] SERVICE ALERT: secondary-server;Nginx Access Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574752942] SERVICE FLAPPING ALERT: primary-server;Nginx Error Log Status;STARTED; Service appears to have started flapping (23.9% change >= 20.0% threshold)
[1574752942] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574753166] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 9.4% (2303248 kB) free!
[1574753166] SERVICE ALERT: sservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 9.4% (2303248 kB) free!
[1574753231] SERVICE ALERT: secondary-server;Nginx Access Log Status;CRITICAL;SOFT;1;(1) < 103.255.146.164 [26/Nov/2019:12:56:37 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1574753351] SERVICE ALERT: secondary-server;Nginx Access Log Status;CRITICAL;SOFT;2;(1) < 103.255.146.164 [26/Nov/2019:12:57:30 +0530] TCP 502 0 0 0.001 "10.147.212.38:5001, 10.147.212.37:5001, 10.147.212.49:5001" "0, 0, 0" "0, 0, 0" "0.000, 0.001, 0.000"
[1574753424] SERVICE ALERT: smscapp1;Memory;WARNING;SOFT;1;WARNING - 18.8% (9244468 kB) free!
[1574753472] SERVICE ALERT: secondary-server;Nginx Access Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574753529] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(5) < 2019/11/26 13:01:37 [error] 26846#0: *10168625 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574753544] SERVICE ALERT: smscapp1;Memory;WARNING;SOFT;2;WARNING - 18.2% (8972988 kB) free!
[1574753649] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(3) < 2019/11/26 13:02:31 [error] 26844#0: *10169218 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:14001, upstream: "10.147.212.49:5001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574753665] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;WARNING;notify-service-by-email;WARNING - 17.7% (8709384 kB) free!
[1574753665] SERVICE ALERT: smscapp1;Memory;WARNING;HARD;3;WARNING - 17.7% (8709384 kB) free!
[1574753763] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1574753762
[1574753763] SERVICE FLAPPING ALERT: pservercluster1;Memory;STARTED; Service appears to have started flapping (21.8% change >= 20.0% threshold)
[1574753763] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 92.3% (22788896 kB) free.
[1574753769] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574753806] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Memory;1574753804
[1574753806] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;OK;notify-service-by-email;OK - 92.9% (22773384 kB) free.
[1574753806] SERVICE ALERT: pservercluster2;Memory;OK;HARD;1;OK - 92.9% (22773384 kB) free.
[1574753811] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Memory;1574753809
[1574753862] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster1;Memory;1574753859
[1574753862] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;OK;notify-service-by-email;OK - 73.2% (17939660 kB) free.
[1574753862] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 73.2% (17939660 kB) free.
[1574753867] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster1;Memory;1574753865
[1574754071] SERVICE ALERT: secondary-server;Nginx Access Log Status;CRITICAL;SOFT;1;(4) < 103.255.146.164 [26/Nov/2019:13:07:30 +0530] TCP 502 0 0 0.001 "10.147.212.38:5001, 10.147.212.49:5001, 10.147.212.37:5001" "0, 0, 0" "0, 0, 0" "0.000, 0.000, 0.001"
[1574754192] SERVICE ALERT: secondary-server;Nginx Access Log Status;CRITICAL;SOFT;2;(2) < 103.255.146.164 [26/Nov/2019:13:12:30 +0530] TCP 502 0 0 0.001 "10.147.212.38:5001, 10.147.212.49:5001, 10.147.212.37:5001" "0, 0, 0" "0, 0, 0" "0.000, 0.001, 0.000"
[1574754312] SERVICE ALERT: secondary-server;Nginx Access Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574754369] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(8) < 2019/11/26 13:12:30 [error] 26848#0: *10176079 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:14001, upstream: "10.147.212.37:5001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574754489] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(4) < 2019/11/26 13:17:30 [error] 26841#0: *10179521 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:14001, upstream: "10.147.212.37:5001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574754609] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574754742] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(95) < 2019/11/26 13:18:09 [error] 24133#0: *9628287 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574754862] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(1) < 2019/11/26 13:24:00 [error] 24134#0: *9629734 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.64.122, server: 0.0.0.0:3001, upstream: "10.147.212.155:3001", bytes from/to client:107/17, bytes from/to upstream:17/107
[1574754913] SERVICE ALERT: secondary-server;Nginx Access Log Status;CRITICAL;SOFT;1;(4) < 103.255.146.164 [26/Nov/2019:13:22:30 +0530] TCP 502 0 0 0.002 "10.147.212.38:5001, 10.147.212.49:5001, 10.147.212.37:5001" "0, 0, 0" "0, 0, 0" "0.001, 0.000, 0.001"
[1574754982] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;HARD;3;(2) < 2019/11/26 13:25:20 [error] 24125#0: *9630031 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.64.122, server: 0.0.0.0:3001, upstream: "10.147.212.143:3001", bytes from/to client:1487/17, bytes from/to upstream:17/1487
[1574755033] SERVICE ALERT: secondary-server;Nginx Access Log Status;CRITICAL;SOFT;2;(1) < 103.255.146.164 [26/Nov/2019:13:26:37 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1574755094] Auto-save of retention data completed successfully.
[1574755154] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1) < 103.255.146.164 [26/Nov/2019:13:27:30 +0530] TCP 502 0 0 0.001 "10.147.212.38:5001, 10.147.212.49:5001, 10.147.212.37:5001" "0, 0, 0" "0, 0, 0" "0.000, 0.001, 0.000"
[1574755154] SERVICE ALERT: secondary-server;Nginx Access Log Status;CRITICAL;HARD;3;(1) < 103.255.146.164 [26/Nov/2019:13:27:30 +0530] TCP 502 0 0 0.001 "10.147.212.38:5001, 10.147.212.49:5001, 10.147.212.37:5001" "0, 0, 0" "0, 0, 0" "0.000, 0.001, 0.000"
[1574755209] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(120) < 2019/11/26 13:27:30 [error] 26847#0: *10187547 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:14001, upstream: "10.147.212.37:5001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574755330] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(1) < 2019/11/26 13:31:37 [error] 26838#0: *10190577 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574755450] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(65) < 2019/11/26 13:34:06 [error] 26845#0: *10192768 connect() failed (111: Connection refused) while connecting to upstream, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574755450] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;HARD;3;(65) < 2019/11/26 13:34:06 [error] 26845#0: *10192768 connect() failed (111: Connection refused) while connecting to upstream, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574756065] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 9.9% (4892500 kB) free!
[1574756065] SERVICE ALERT: smscapp1;Memory;CRITICAL;HARD;3;CRITICAL - 9.9% (4892500 kB) free!
[1574756182] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574756561] SERVICE ALERT: redis-1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 401 processes
[1574756681] SERVICE ALERT: redis-1;CPU_Procs;OK;HARD;1;CPU OK: 401 processes
[1574756782] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(104) < 2019/11/26 13:55:31 [error] 24133#0: *9637314 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574756903] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574757431] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;smscapp1;Memory;1574757430
[1574757432] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;OK;notify-service-by-email;OK - 39.5% (19482812 kB) free.
[1574757432] SERVICE ALERT: smscapp1;Memory;OK;HARD;1;OK - 39.5% (19482812 kB) free.
[1574757439] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;smscapp1;Memory;1574757437
[1574757474] SERVICE ALERT: webservercluster2;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 329 processes
[1574757502] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/11/26 14:00:12 [error] 24131#0: *9638280 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.142:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574757594] SERVICE ALERT: webservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 325 processes
[1574757622] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574757963] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.7% (168540 kB) free!
[1574758083] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (197352 kB) free!
[1574758096] SERVICE ALERT: sigqscluster1;Memory;WARNING;SOFT;1;WARNING - 19.0% (9343428 kB) free!
[1574758203] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.7% (175340 kB) free!
[1574758216] SERVICE ALERT: sigqscluster1;Memory;WARNING;SOFT;2;WARNING - 18.8% (9249796 kB) free!
[1574758336] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;WARNING;notify-service-by-email;WARNING - 18.6% (9158084 kB) free!
[1574758336] SERVICE ALERT: sigqscluster1;Memory;WARNING;HARD;3;WARNING - 18.6% (9158084 kB) free!
[1574758694] Auto-save of retention data completed successfully.
[1574758755] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 103.255.146.164 [26/Nov/2019:14:27:30 +0530] TCP 502 0 0 0.001 "10.147.212.38:5001, 10.147.212.37:5001, 10.147.212.49:5001" "0, 0, 0" "0, 0, 0" "0.000, 0.001, 0.000"
[1574758822] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(77) < 2019/11/26 14:28:26 [error] 24127#0: *9643655 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574758942] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(30) < 2019/11/26 14:30:43 [error] 24130#0: *9644164 recv() failed (104: Connection reset by peer) while proxying connection, client: 103.209.99.7, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:43/0, bytes from/to upstream:0/43
[1574759050] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(8) < 2019/11/26 14:32:30 [error] 26852#0: *10233489 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:14001, upstream: "10.147.212.49:5001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574759062] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574760411] SERVICE ALERT: pservercluster2;Memory;CRITICAL;SOFT;1;CRITICAL - 0.8% (186820 kB) free!
[1574760467] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.8% (195140 kB) free!
[1574760531] SERVICE ALERT: pservercluster2;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (188864 kB) free!
[1574760587] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (188860 kB) free!
[1574760605] SERVICE ALERT: qservercluster2;Memory;WARNING;SOFT;1;WARNING - 19.9% (9795020 kB) free!
[1574760651] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (167688 kB) free!
[1574760651] SERVICE ALERT: pservercluster2;Memory;CRITICAL;HARD;3;CRITICAL - 0.7% (167688 kB) free!
[1574760707] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 2.3% (562524 kB) free!
[1574760707] SERVICE ALERT: sservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 2.3% (562524 kB) free!
[1574760725] SERVICE ALERT: qservercluster2;Memory;WARNING;SOFT;2;WARNING - 19.6% (9638692 kB) free!
[1574760845] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 19.2% (9471540 kB) free!
[1574760845] SERVICE ALERT: qservercluster2;Memory;WARNING;HARD;3;WARNING - 19.2% (9471540 kB) free!
[1574760862] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(52) < 2019/11/26 15:03:47 [error] 24131#0: *9650526 connect() failed (111: Connection refused) while connecting to upstream, client: 169.38.76.212, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574760982] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574761336] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.3% (3105380 kB) free!
[1574761336] SERVICE ALERT: sigqscluster1;Memory;CRITICAL;HARD;3;CRITICAL - 6.3% (3105380 kB) free!
[1574761368] SERVICE ALERT: sservercluster2;Memory;WARNING;SOFT;1;WARNING - 19.0% (4652140 kB) free!
[1574761488] SERVICE ALERT: sservercluster2;Memory;WARNING;SOFT;2;WARNING - 18.3% (4493388 kB) free!
[1574761582] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(29) < 2019/11/26 15:06:57 [error] 24133#0: *9651105 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574761608] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 17.8% (4372136 kB) free!
[1574761608] SERVICE ALERT: sservercluster2;Memory;WARNING;HARD;3;WARNING - 17.8% (4372136 kB) free!
[1574761702] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574762088] SERVICE ALERT: rq-1;rq1-rabbitmqerror;CRITICAL;SOFT;1;(2) < {writer,send_failed,{error,timeout}}
[1574762208] SERVICE ALERT: rq-1;rq1-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1574762294] Auto-save of retention data completed successfully.
[1574762449] SERVICE ALERT: sigqscluster2;sigqscluster2-rabbitmqerror;CRITICAL;SOFT;1;(13) < {writer,send_failed,{error,timeout}}
[1574762569] SERVICE ALERT: sigqscluster2;sigqscluster2-rabbitmqerror;CRITICAL;SOFT;2;(8) < {writer,send_failed,{error,timeout}}
[1574762607] SERVICE ALERT: smscapp2;CPU Load;WARNING;SOFT;1;WARNING - load average: 40.10, 29.62, 22.01
[1574762650] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(8) < 2019/11/26 15:32:30 [error] 26852#0: *10275737 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:14001, upstream: "10.147.212.49:5001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574762690] SERVICE NOTIFICATION: nagiosadmin;sigqscluster2;sigqscluster2-rabbitmqerror;CRITICAL;notify-service-by-email;(9) < {writer,send_failed,{error,timeout}}
[1574762690] SERVICE ALERT: sigqscluster2;sigqscluster2-rabbitmqerror;CRITICAL;HARD;3;(9) < {writer,send_failed,{error,timeout}}
[1574762727] SERVICE ALERT: smscapp2;CPU Load;WARNING;SOFT;2;WARNING - load average: 50.57, 36.28, 25.31
[1574762809] SERVICE ALERT: rq-1;rq1-rabbitmqerror;CRITICAL;SOFT;1;(28) < {writer,send_failed,{error,timeout}}
[1574762830] SERVICE ALERT: rq-2;rq2-rabbitmqerror;CRITICAL;SOFT;1;(16) < {writer,send_failed,{error,timeout}}
[1574762847] SERVICE NOTIFICATION: nagiosadmin;smscapp2;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 142.02, 73.37, 39.95
[1574762847] SERVICE ALERT: smscapp2;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 142.02, 73.37, 39.95
[1574762903] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(20) < 2019/11/26 15:34:22 [error] 24131#0: *9656329 connect() failed (111: Connection refused) while connecting to upstream, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574762930] SERVICE ALERT: rq-1;rq1-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1574762950] SERVICE ALERT: rq-2;rq2-rabbitmqerror;CRITICAL;SOFT;2;(4) < {writer,send_failed,{error,timeout}}
[1574762955] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 103.255.146.164 [26/Nov/2019:15:37:31 +0530] TCP 502 0 0 0.001 "10.147.212.38:5001, 10.147.212.49:5001, 10.147.212.37:5001" "0, 0, 0" "0, 0, 0" "0.000, 0.000, 0.001"
[1574763023] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(56) < 2019/11/26 15:40:15 [error] 24132#0: *9657335 recv() failed (104: Connection reset by peer) while proxying connection, client: 169.38.76.212, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:43/0, bytes from/to upstream:0/43
[1574763070] SERVICE ALERT: rq-2;rq2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1574763143] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574763163] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1574763162
[1574763164] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 93.4% (23050368 kB) free.
[1574763225] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Memory;1574763223
[1574763225] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;OK;notify-service-by-email;OK - 94.2% (23091696 kB) free.
[1574763225] SERVICE ALERT: pservercluster2;Memory;OK;HARD;1;OK - 94.2% (23091696 kB) free.
[1574763232] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Memory;1574763230
[1574763238] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Memory;1574763236
[1574763290] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sigqscluster1;Memory;1574763288
[1574763291] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;OK;notify-service-by-email;OK - 80.6% (39715080 kB) free.
[1574763291] SERVICE ALERT: sigqscluster1;Memory;OK;HARD;1;OK - 80.6% (39715080 kB) free.
[1574763303] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sigqscluster1;Memory;1574763300
[1574763345] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster1;Memory;1574763344
[1574763346] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;OK;notify-service-by-email;OK - 74.8% (18333852 kB) free.
[1574763346] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 74.8% (18333852 kB) free.
[1574763354] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster1;Memory;1574763353
[1574763408] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 9.8% (2412340 kB) free!
[1574763408] SERVICE ALERT: sservercluster2;Memory;CRITICAL;HARD;3;CRITICAL - 9.8% (2412340 kB) free!
[1574763448] SERVICE NOTIFICATION: nagiosadmin;smscapp2;CPU Load;WARNING;notify-service-by-email;WARNING - load average: 20.39, 30.89, 34.17
[1574763448] SERVICE ALERT: smscapp2;CPU Load;WARNING;HARD;3;WARNING - load average: 20.39, 30.89, 34.17
[1574763529] SERVICE ALERT: rq-1;rq1-rabbitmqerror;CRITICAL;SOFT;1;(4) <                  {amqp_error,unexpected_frame,
[1574763650] SERVICE ALERT: rq-1;rq1-rabbitmqerror;CRITICAL;SOFT;2;(11) < {writer,send_failed,{error,timeout}}
[1574763671] SERVICE ALERT: rq-2;rq2-rabbitmqerror;CRITICAL;SOFT;1;(1) < {writer,send_failed,{error,timeout}}
[1574763743] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(25) < 2019/11/26 15:43:54 [error] 24132#0: *9658130 connect() failed (111: Connection refused) while connecting to upstream, client: 169.38.76.212, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574763771] SERVICE NOTIFICATION: nagiosadmin;rq-1;rq1-rabbitmqerror;CRITICAL;notify-service-by-email;(6) < {writer,send_failed,{error,timeout}}
[1574763771] SERVICE ALERT: rq-1;rq1-rabbitmqerror;CRITICAL;HARD;3;(6) < {writer,send_failed,{error,timeout}}
[1574763791] SERVICE ALERT: rq-2;rq2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1574763845] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 9.3% (4566616 kB) free!
[1574763845] SERVICE ALERT: qservercluster2;Memory;CRITICAL;HARD;3;CRITICAL - 9.3% (4566616 kB) free!
[1574763863] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574764391] SERVICE ALERT: rq-2;rq2-rabbitmqerror;CRITICAL;SOFT;1;(1) < {writer,send_failed,{error,timeout}}
[1574764511] SERVICE ALERT: rq-2;rq2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1574765050] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1574765050] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574765063] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(23) < 2019/11/26 16:10:04 [error] 24133#0: *9663139 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574765090] SERVICE NOTIFICATION: nagiosadmin;sigqscluster2;sigqscluster2-rabbitmqerror;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1574765090] SERVICE ALERT: sigqscluster2;sigqscluster2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1574765184] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(48) < 2019/11/26 16:15:59 [error] 24131#0: *9664225 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574765304] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574765355] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1574765355] SERVICE ALERT: secondary-server;Nginx Access Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574765564] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.7% (177436 kB) free!
[1574765684] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (189516 kB) free!
[1574765804] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.7% (173060 kB) free!
[1574765848] SERVICE NOTIFICATION: nagiosadmin;smscapp2;CPU Load;OK;notify-service-by-email;OK - load average: 31.57, 26.12, 27.18
[1574765848] SERVICE ALERT: smscapp2;CPU Load;OK;HARD;1;OK - load average: 31.57, 26.12, 27.18
[1574765894] Auto-save of retention data completed successfully.
[1574765904] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(25) < 2019/11/26 16:27:23 [error] 24129#0: *9664439 recv() failed (104: Connection reset by peer) while proxying connection, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.143:3000", bytes from/to client:393/1099946, bytes from/to upstream:1099946/393
[1574766024] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574766849] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 8.1% (10620428 kB) free!
[1574766969] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 28.5% (37612744 kB) free.
[1574767008] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.5% (357428 kB) free!
[1574767224] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(26) < 2019/11/26 16:46:06 [error] 24130#0: *9670027 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574767344] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(24) < 2019/11/26 16:52:09 [error] 24130#0: *9671210 connect() failed (111: Connection refused) while connecting to upstream, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574767371] SERVICE NOTIFICATION: nagiosadmin;rq-1;rq1-rabbitmqerror;CRITICAL;notify-service-by-email;(14) < Channel error on connection <0.23248.351> (10.147.212.191:44830 -> 10.147.212.203:5672, vhost: '/', user: 'guest'), channel 1:
[1574767445] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.6% (280844 kB) free!
[1574767464] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;HARD;3;(26) < 2019/11/26 16:53:11 [error] 24132#0: *9671333 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574767466] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1574767463
[1574767467] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 93.3% (23034000 kB) free.
[1574767475] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1574767473
[1574767503] SERVICE ALERT: sigqscluster1;Memory;WARNING;SOFT;1;WARNING - 20.0% (9856824 kB) free!
[1574767507] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;qservercluster2;Memory;1574767506
[1574767508] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;OK;notify-service-by-email;OK - 43.0% (21192724 kB) free.
[1574767508] SERVICE ALERT: qservercluster2;Memory;OK;HARD;1;OK - 43.0% (21192724 kB) free.
[1574767514] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;qservercluster2;Memory;1574767512
[1574767552] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster2;Memory;1574767550
[1574767552] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;OK;notify-service-by-email;OK - 94.1% (23064988 kB) free.
[1574767552] SERVICE ALERT: sservercluster2;Memory;OK;HARD;1;OK - 94.1% (23064988 kB) free.
[1574767557] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster2;Memory;1574767556
[1574767569] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 8.1% (10696268 kB) free!
[1574767623] SERVICE ALERT: sigqscluster1;Memory;WARNING;SOFT;2;WARNING - 20.0% (9858320 kB) free!
[1574767689] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 27.0% (35626952 kB) free.
[1574767743] SERVICE FLAPPING ALERT: sigqscluster1;Memory;STARTED; Service appears to have started flapping (20.1% change >= 20.0% threshold)
[1574767743] SERVICE ALERT: sigqscluster1;Memory;WARNING;HARD;3;WARNING - 20.0% (9831860 kB) free!
[1574768050] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/11/26 17:00:51 [error] 26846#0: *10341299 upstream timed out (110: Connection timed out) while reading response header from upstream, client: 183.82.105.122, server: webserver2.com, request: "POST /temtapp/index.php/DlrLoad/msisdn HTTP/1.1", upstream: "http://10.147.212.40:80/temtapp/index.php/DlrLoad/msisdn", host: "webserver2.com:8091", referrer: "http://webserver2.com:8091/temtapp/index.php/DlrLoad/msisdn"
[1574768075] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 1.1% (277352 kB) free!
[1574768111] SERVICE ALERT: rq-2;rq2-rabbitmqerror;CRITICAL;SOFT;1;(6) <                  {amqp_error,unexpected_frame,
[1574768170] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574768195] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (197560 kB) free!
[1574768231] SERVICE ALERT: rq-2;rq2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1574768289] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 7.0% (9251780 kB) free!
[1574768315] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.7% (165948 kB) free!
[1574768352] SERVICE ALERT: webservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 1.0% (167864 kB) free!
[1574768409] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 25.3% (33414360 kB) free.
[1574768472] SERVICE ALERT: webservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 1.0% (167296 kB) free!
[1574768592] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.1% (184436 kB) free!
[1574768592] SERVICE ALERT: webservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 1.1% (184436 kB) free!
[1574768664] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574768691] SERVICE ALERT: sigqscluster2;sigqscluster2-rabbitmqerror;CRITICAL;SOFT;1;(24) <                  {amqp_error,unexpected_frame,
[1574768811] SERVICE ALERT: sigqscluster2;sigqscluster2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1574768832] SERVICE ALERT: rq-2;rq2-rabbitmqerror;CRITICAL;SOFT;1;(2) <                  {amqp_error,unexpected_frame,
[1574768952] SERVICE ALERT: rq-2;rq2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1574769010] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 5.6% (7416144 kB) free!
[1574769130] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 25.9% (34142796 kB) free.
[1574769172] SERVICE NOTIFICATION: nagiosadmin;rq-1;rq1-rabbitmqerror;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1574769172] SERVICE ALERT: rq-1;rq1-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1574769264] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(29) < 2019/11/26 17:21:16 [error] 24131#0: *9676815 connect() failed (111: Connection refused) while connecting to upstream, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574769384] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574769494] Auto-save of retention data completed successfully.
[1574769730] SERVICE ALERT: redis-2;Memory;WARNING;SOFT;1;WARNING - 10.3% (13513844 kB) free!
[1574769850] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 25.0% (32898296 kB) free.
[1574769984] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(59) < 2019/11/26 17:29:44 [error] 24130#0: *9678402 recv() failed (104: Connection reset by peer) while proxying connection, client: 169.38.76.212, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:43/0, bytes from/to upstream:0/43
[1574770104] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574770450] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 8.6% (11371212 kB) free!
[1574770570] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 24.0% (31647652 kB) free.
[1574771170] SERVICE ALERT: redis-2;Memory;WARNING;SOFT;1;WARNING - 14.9% (19631712 kB) free!
[1574771290] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 21.7% (28625296 kB) free.
[1574771305] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(29) < 2019/11/26 17:56:12 [error] 24130#0: *9683611 connect() failed (111: Connection refused) while connecting to upstream, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574771425] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574771943] SERVICE ALERT: sigqscluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.5% (222928 kB) free!
[1574772025] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(76) < 2019/11/26 18:06:04 [error] 24130#0: *9685481 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574772145] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574772192] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.3% (207196 kB) free!
[1574772440] SERVICE ALERT: smscapp1;Memory;WARNING;SOFT;1;WARNING - 19.7% (9710400 kB) free!
[1574772490] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 9.2% (12072660 kB) free!
[1574772560] SERVICE ALERT: smscapp1;Memory;WARNING;SOFT;2;WARNING - 19.4% (9563316 kB) free!
[1574772610] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 30.8% (40666036 kB) free.
[1574772680] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;WARNING;notify-service-by-email;WARNING - 19.1% (9415204 kB) free!
[1574772680] SERVICE ALERT: smscapp1;Memory;WARNING;HARD;3;WARNING - 19.1% (9415204 kB) free!
[1574772954] SERVICE ALERT: sservercluster1;Memory;WARNING;SOFT;1;WARNING - 19.0% (4646360 kB) free!
[1574773074] SERVICE ALERT: sservercluster1;Memory;WARNING;SOFT;2;WARNING - 18.5% (4527108 kB) free!
[1574773094] Auto-save of retention data completed successfully.
[1574773194] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;WARNING;notify-service-by-email;WARNING - 17.9% (4397692 kB) free!
[1574773194] SERVICE ALERT: sservercluster1;Memory;WARNING;HARD;3;WARNING - 17.9% (4397692 kB) free!
[1574773210] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 9.3% (12311612 kB) free!
[1574773330] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 31.1% (41002224 kB) free.
[1574773345] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(23) < 2019/11/26 18:30:43 [error] 24130#0: *9690262 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574773465] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574773501] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1574773499
[1574773501] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 91.4% (22549072 kB) free.
[1574773514] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1574773512
[1574773553] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sigqscluster1;Memory;1574773551
[1574773553] SERVICE ALERT: sigqscluster1;Memory;OK;HARD;1;OK - 56.9% (28042312 kB) free.
[1574773579] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;webservercluster1;Memory;1574773577
[1574773580] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Memory;OK;notify-service-by-email;OK - 89.3% (14507584 kB) free.
[1574773580] SERVICE ALERT: webservercluster1;Memory;OK;HARD;1;OK - 89.3% (14507584 kB) free.
[1574773586] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;webservercluster1;Memory;1574773585
[1574773930] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 9.9% (13086392 kB) free!
[1574774050] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;2;CRITICAL - 7.6% (10045896 kB) free!
[1574774066] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(75) < 2019/11/26 18:44:01 [error] 24130#0: *9692963 connect() failed (111: Connection refused) while connecting to upstream, client: 185.255.8.58, server: 0.0.0.0:13001, upstream: "10.147.212.154:13001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574774114] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.8% (191660 kB) free!
[1574774154] SERVICE ALERT: sigqscluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.4% (221656 kB) free!
[1574774171] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 29.5% (38893828 kB) free.
[1574774186] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574774234] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.7% (178060 kB) free!
[1574774274] SERVICE ALERT: sigqscluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.4% (215116 kB) free!
[1574774354] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (188780 kB) free!
[1574774394] SERVICE ALERT: sigqscluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.5% (248512 kB) free!
[1574774639] SERVICE ALERT: pservercluster2;Memory;WARNING;SOFT;1;WARNING - 17.2% (4204592 kB) free!
[1574774759] SERVICE ALERT: pservercluster2;Memory;WARNING;SOFT;2;WARNING - 16.5% (4052652 kB) free!
[1574774770] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 8.0% (10578300 kB) free!
[1574774879] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 15.9% (3888580 kB) free!
[1574774879] SERVICE ALERT: pservercluster2;Memory;WARNING;HARD;3;WARNING - 15.9% (3888580 kB) free!
[1574774890] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 29.9% (39365356 kB) free.
[1574775386] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(27) < 2019/11/26 19:06:03 [error] 24130#0: *9697509 recv() failed (104: Connection reset by peer) while proxying connection, client: 169.38.76.212, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:43/0, bytes from/to upstream:0/43
[1574775490] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 8.0% (10515260 kB) free!
[1574775506] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574775594] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 8.2% (1999240 kB) free!
[1574775594] SERVICE ALERT: sservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 8.2% (1999240 kB) free!
[1574775610] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 29.3% (38649752 kB) free.
[1574776106] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(73) < 2019/11/26 19:17:51 [error] 24130#0: *9699758 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574776210] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 9.8% (12911908 kB) free!
[1574776226] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574776280] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;WARNING;notify-service-by-email;WARNING - 10.4% (5110512 kB) free!
[1574776330] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;2;CRITICAL - 7.2% (9468108 kB) free!
[1574776450] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 27.4% (36113656 kB) free.
[1574776679] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 8.9% (2170084 kB) free!
[1574776679] SERVICE ALERT: pservercluster2;Memory;CRITICAL;HARD;3;CRITICAL - 8.9% (2170084 kB) free!
[1574776694] Auto-save of retention data completed successfully.
[1574776880] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 9.1% (4485640 kB) free!
[1574776880] SERVICE ALERT: smscapp1;Memory;CRITICAL;HARD;3;CRITICAL - 9.1% (4485640 kB) free!
[1574777050] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 6.4% (8467332 kB) free!
[1574777170] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 28.4% (37444892 kB) free.
[1574777770] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 6.1% (8044692 kB) free!
[1574777890] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 28.2% (37227316 kB) free.
[1574778026] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(57) < 2019/11/26 19:47:25 [error] 24131#0: *9705492 recv() failed (104: Connection reset by peer) while proxying connection, client: 169.38.76.212, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:43/0, bytes from/to upstream:0/43
[1574778146] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(26) < 2019/11/26 19:52:00 [error] 24131#0: *9706340 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574778266] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;HARD;3;(23) < 2019/11/26 19:52:45 [error] 24130#0: *9706508 recv() failed (104: Connection reset by peer) while proxying connection, client: 94.237.68.73, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:39/0, bytes from/to upstream:0/39
[1574778490] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 9.9% (13025588 kB) free!
[1574778610] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 27.5% (36265036 kB) free.
[1574778866] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574779194] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (179840 kB) free!
[1574779210] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 8.5% (11233484 kB) free!
[1574779331] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 26.8% (35321972 kB) free.
[1574779930] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 7.9% (10397708 kB) free!
[1574780050] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;2;CRITICAL - 4.9% (6511344 kB) free!
[1574780067] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(47) < 2019/11/26 20:22:33 [error] 24129#0: *9712309 connect() failed (111: Connection refused) while connecting to upstream, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574780170] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 24.9% (32812344 kB) free.
[1574780187] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(28) < 2019/11/26 20:25:36 [error] 24130#0: *9712822 recv() failed (104: Connection reset by peer) while proxying connection, client: 94.237.68.73, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:39/0, bytes from/to upstream:0/39
[1574780279] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (186480 kB) free!
[1574780294] Auto-save of retention data completed successfully.
[1574780307] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;HARD;3;(21) < 2019/11/26 20:28:06 [error] 24130#0: *9713345 recv() failed (104: Connection reset by peer) while proxying connection, client: 94.237.65.17, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:39/0, bytes from/to upstream:0/39
[1574780480] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (220508 kB) free!
[1574780770] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 7.4% (9789908 kB) free!
[1574780890] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 25.3% (33326112 kB) free.
[1574780907] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574781490] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 7.4% (9748648 kB) free!
[1574781610] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 25.4% (33419884 kB) free.
[1574782107] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(54) < 2019/11/26 20:57:18 [error] 24130#0: *9719006 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574782210] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 7.3% (9610616 kB) free!
[1574782227] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(23) < 2019/11/26 21:00:25 [error] 24124#0: *9719097 recv() failed (104: Connection reset by peer) while proxying connection, client: 210.212.235.210, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:139/81, bytes from/to upstream:81/139
[1574782330] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 25.1% (33133468 kB) free.
[1574782348] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;HARD;3;(4) < 2019/11/26 21:00:32 [error] 24130#0: *9719664 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574782794] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (205520 kB) free!
[1574782930] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 8.9% (11678204 kB) free!
[1574783050] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 25.0% (32941560 kB) free.
[1574783548] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574783650] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 9.2% (12100868 kB) free!
[1574783770] SERVICE ALERT: redis-2;Memory;WARNING;SOFT;2;WARNING - 13.4% (17630604 kB) free!
[1574783879] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (176160 kB) free!
[1574783890] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 22.8% (30072536 kB) free.
[1574783894] Auto-save of retention data completed successfully.
[1574784080] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (237688 kB) free!
[1574784148] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(35) < 2019/11/26 21:32:12 [error] 24133#0: *9725838 recv() failed (104: Connection reset by peer) while proxying connection, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.142:13000", bytes from/to client:42/0, bytes from/to upstream:0/42
[1574784268] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574784491] SERVICE ALERT: redis-2;Memory;WARNING;SOFT;1;WARNING - 13.3% (17590788 kB) free!
[1574784611] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 23.2% (30536560 kB) free.
[1574784868] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(62) < 2019/11/26 21:37:56 [error] 24130#0: *9726878 recv() failed (104: Connection reset by peer) while proxying connection, client: 169.38.76.212, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:43/0, bytes from/to upstream:0/43
[1574784988] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574785101] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1574785099
[1574785102] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 94.4% (23304276 kB) free.
[1574785108] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1574785106
[1574785139] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Memory;1574785136
[1574785140] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;OK;notify-service-by-email;OK - 94.2% (23092604 kB) free.
[1574785140] SERVICE ALERT: pservercluster2;Memory;OK;HARD;1;OK - 94.2% (23092604 kB) free.
[1574785147] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Memory;1574785145
[1574785195] SERVICE ALERT: sigqscluster1;Memory;WARNING;HARD;3;WARNING - 13.8% (6797212 kB) free!
[1574785206] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sigqscluster1;Memory;1574785205
[1574785206] SERVICE ALERT: sigqscluster1;Memory;OK;HARD;1;OK - 80.5% (39670320 kB) free.
[1574785211] SERVICE ALERT: redis-2;Memory;CRITICAL;SOFT;1;CRITICAL - 6.4% (8401248 kB) free!
[1574785241] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;smscapp1;Memory;1574785238
[1574785241] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;OK;notify-service-by-email;OK - 40.9% (20152380 kB) free.
[1574785241] SERVICE ALERT: smscapp1;Memory;OK;HARD;1;OK - 40.9% (20152380 kB) free.
[1574785244] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;smscapp1;Memory;1574785243
[1574785274] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;redis-2;Memory;1574785273
[1574785274] SERVICE ALERT: redis-2;Memory;OK;HARD;1;OK - 39.4% (51896092 kB) free.
[1574785329] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster1;Memory;1574785324
[1574785329] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;OK;notify-service-by-email;OK - 74.8% (18328376 kB) free.
[1574785329] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 74.8% (18328376 kB) free.
[1574785334] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster1;Memory;1574785332
[1574786188] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(23) < 2019/11/26 22:02:20 [error] 24130#0: *9731693 connect() failed (111: Connection refused) while connecting to upstream, client: 185.255.8.58, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574786308] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574786908] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(66) < 2019/11/26 22:13:45 [error] 24130#0: *9733898 connect() failed (111: Connection refused) while connecting to upstream, client: 94.237.68.73, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574787028] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574787494] Auto-save of retention data completed successfully.
[1574788109] SERVICE ALERT: pservercluster1;Memory;WARNING;SOFT;1;WARNING - 13.2% (3254064 kB) free!
[1574788228] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(18) < 2019/11/26 22:38:17 [error] 24131#0: *9738656 connect() failed (111: Connection refused) while connecting to upstream, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574788229] SERVICE ALERT: pservercluster1;Memory;WARNING;SOFT;2;WARNING - 13.1% (3241964 kB) free!
[1574788348] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574788349] SERVICE ALERT: pservercluster1;Memory;WARNING;HARD;3;WARNING - 13.1% (3224156 kB) free!
[1574788949] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(61) < 2019/11/26 22:48:55 [error] 24130#0: *9740740 connect() failed (111: Connection refused) while connecting to upstream, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574789069] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574789681] SERVICE ALERT: redis-1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 401 processes
[1574789801] SERVICE ALERT: redis-1;CPU_Procs;OK;HARD;1;CPU OK: 400 processes
[1574790269] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(21) < 2019/11/26 23:13:56 [error] 24132#0: *9745586 connect() failed (111: Connection refused) while connecting to upstream, client: 180.179.244.32, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1574790389] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574790989] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(69) < 2019/11/26 23:24:20 [error] 24133#0: *9747570 recv() failed (104: Connection reset by peer) while proxying connection, client: 169.38.76.212, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:43/0, bytes from/to upstream:0/43
[1574791094] Auto-save of retention data completed successfully.
[1574791109] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1574791349] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 7.7% (1892156 kB) free!
[1574792909] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(64) < 2019/11/26 23:58:26 [error] 24130#0: *9754128 recv() failed (104: Connection reset by peer) while proxying connection, client: 94.237.68.73, server: 0.0.0.0:13000, upstream: "10.147.212.154:13000", bytes from/to client:39/0, bytes from/to upstream:0/39
