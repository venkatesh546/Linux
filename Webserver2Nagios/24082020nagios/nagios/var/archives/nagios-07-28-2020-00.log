[1595788200] LOG ROTATION: DAILY
[1595788200] LOG VERSION: 2.0
[1595788200] CURRENT HOST STATE: TempHP1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.37 ms
[1595788200] CURRENT HOST STATE: TempHP2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.29 ms
[1595788200] CURRENT HOST STATE: TempHP3;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.29 ms
[1595788200] CURRENT HOST STATE: TempHP4;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.23 ms
[1595788200] CURRENT HOST STATE: db1-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.54 ms
[1595788200] CURRENT HOST STATE: db2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.43 ms
[1595788200] CURRENT HOST STATE: mrq4;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.31 ms
[1595788200] CURRENT HOST STATE: primary-server;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.47 ms
[1595788200] CURRENT HOST STATE: pservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.42 ms
[1595788200] CURRENT HOST STATE: pservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.34 ms
[1595788200] CURRENT HOST STATE: qservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.39 ms
[1595788200] CURRENT HOST STATE: qservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.33 ms
[1595788200] CURRENT HOST STATE: redis-1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.31 ms
[1595788200] CURRENT HOST STATE: redis-2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.40 ms
[1595788200] CURRENT HOST STATE: rq-1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.27 ms
[1595788200] CURRENT HOST STATE: rq-2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.24 ms
[1595788200] CURRENT HOST STATE: secondary-server;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.41 ms
[1595788200] CURRENT HOST STATE: sig1-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.52 ms
[1595788200] CURRENT HOST STATE: sig2-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.39 ms
[1595788200] CURRENT HOST STATE: sig3-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.46 ms
[1595788200] CURRENT HOST STATE: sig4-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.46 ms
[1595788200] CURRENT HOST STATE: sig5-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.41 ms
[1595788200] CURRENT HOST STATE: sig6-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.50 ms
[1595788200] CURRENT HOST STATE: sigqscluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.47 ms
[1595788200] CURRENT HOST STATE: sigqscluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.37 ms
[1595788200] CURRENT HOST STATE: smscapp1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.34 ms
[1595788200] CURRENT HOST STATE: smscapp2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.31 ms
[1595788200] CURRENT HOST STATE: sservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.34 ms
[1595788200] CURRENT HOST STATE: sservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.35 ms
[1595788200] CURRENT HOST STATE: webserver1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.47 ms
[1595788200] CURRENT HOST STATE: webserver2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.09 ms
[1595788200] CURRENT HOST STATE: webservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.48 ms
[1595788200] CURRENT HOST STATE: webservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.38 ms
[1595788200] CURRENT SERVICE STATE: TempHP1;CPU Load;OK;HARD;1;OK - load average: 18.28, 18.37, 18.38
[1595788200] CURRENT SERVICE STATE: TempHP1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=67.44% system=29.06% iowait=0.00% idle=3.50%
[1595788200] CURRENT SERVICE STATE: TempHP1;Chrony;OK;HARD;1;PROCS OK: 1 process with command name 'chronyd'
[1595788200] CURRENT SERVICE STATE: TempHP1;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: TempHP1;Home;OK;HARD;1;DISK OK - free space: /home 511711 MB (99% inode=99%):
[1595788200] CURRENT SERVICE STATE: TempHP1;Memory;OK;HARD;1;OK - 89.5% (117755800 kB) free.
[1595788200] CURRENT SERVICE STATE: TempHP1;Open-Files;OK;HARD;1;OK: 11648 open files (0% of max 13142776)
[1595788200] CURRENT SERVICE STATE: TempHP1;Root;OK;HARD;1;DISK OK - free space: /var/tmp 43441 MB (84% inode=99%):
[1595788200] CURRENT SERVICE STATE: TempHP1;Total Processes;OK;HARD;1;PROCS OK: 358 processes
[1595788200] CURRENT SERVICE STATE: TempHP2;CPU Load;OK;HARD;1;OK - load average: 17.56, 17.54, 17.54
[1595788200] CURRENT SERVICE STATE: TempHP2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=69.81% system=28.80% iowait=0.00% idle=1.39%
[1595788200] CURRENT SERVICE STATE: TempHP2;Chrony;OK;HARD;1;PROCS OK: 1 process with command name 'chronyd'
[1595788200] CURRENT SERVICE STATE: TempHP2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: TempHP2;Home;OK;HARD;1;DISK OK - free space: /home 511591 MB (99% inode=99%):
[1595788200] CURRENT SERVICE STATE: TempHP2;Memory;OK;HARD;1;OK - 93.9% (123599856 kB) free.
[1595788200] CURRENT SERVICE STATE: TempHP2;Open-Files;OK;HARD;1;OK: 11776 open files (0% of max 13142787)
[1595788200] CURRENT SERVICE STATE: TempHP2;Root;OK;HARD;1;DISK OK - free space: /var/tmp 35512 MB (69% inode=99%):
[1595788200] CURRENT SERVICE STATE: TempHP2;Total Processes;OK;HARD;1;PROCS OK: 332 processes
[1595788200] CURRENT SERVICE STATE: TempHP3;CPU Load;OK;HARD;1;OK - load average: 17.77, 17.70, 17.61
[1595788200] CURRENT SERVICE STATE: TempHP3;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=69.36% system=28.59% iowait=0.00% idle=2.05%
[1595788200] CURRENT SERVICE STATE: TempHP3;Chrony;OK;HARD;1;PROCS OK: 1 process with command name 'chronyd'
[1595788200] CURRENT SERVICE STATE: TempHP3;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: TempHP3;Home;OK;HARD;1;DISK OK - free space: /home 511675 MB (99% inode=99%):
[1595788200] CURRENT SERVICE STATE: TempHP3;Memory;OK;HARD;1;OK - 94.9% (124980932 kB) free.
[1595788200] CURRENT SERVICE STATE: TempHP3;Open-Files;OK;HARD;1;OK: 9824 open files (0% of max 13142787)
[1595788200] CURRENT SERVICE STATE: TempHP3;Root;OK;HARD;1;DISK OK - free space: /var/tmp 43269 MB (84% inode=99%):
[1595788200] CURRENT SERVICE STATE: TempHP3;Total Processes;OK;HARD;1;PROCS OK: 331 processes
[1595788200] CURRENT SERVICE STATE: TempHP4;CPU Load;OK;HARD;1;OK - load average: 17.44, 17.59, 17.62
[1595788200] CURRENT SERVICE STATE: TempHP4;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=68.49% system=29.54% iowait=0.00% idle=1.97%
[1595788200] CURRENT SERVICE STATE: TempHP4;Chrony;OK;HARD;1;PROCS OK: 1 process with command name 'chronyd'
[1595788200] CURRENT SERVICE STATE: TempHP4;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: TempHP4;Home;OK;HARD;1;DISK OK - free space: /home 511027 MB (99% inode=99%):
[1595788200] CURRENT SERVICE STATE: TempHP4;Memory;OK;HARD;1;OK - 94.9% (124963548 kB) free.
[1595788200] CURRENT SERVICE STATE: TempHP4;Open-Files;OK;HARD;1;OK: 9984 open files (15% of max 64000)
[1595788200] CURRENT SERVICE STATE: TempHP4;Root;OK;HARD;1;DISK OK - free space: /var/tmp 42913 MB (83% inode=99%):
[1595788200] CURRENT SERVICE STATE: TempHP4;Total Processes;OK;HARD;1;PROCS OK: 331 processes
[1595788200] CURRENT SERVICE STATE: db1-vm2;CPU Load;OK;HARD;1;OK - load average: 4.02, 3.51, 3.56
[1595788200] CURRENT SERVICE STATE: db1-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=3.07% system=13.70% iowait=0.00% idle=81.73%
[1595788200] CURRENT SERVICE STATE: db1-vm2;CPU_Procs;OK;HARD;1;CPU OK: 390 processes
[1595788200] CURRENT SERVICE STATE: db1-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: db1-vm2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 26956 MB (67% inode=99%):
[1595788200] CURRENT SERVICE STATE: db1-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44385 MB (86% inode=99%):
[1595788200] CURRENT SERVICE STATE: db1-vm2;Memory;OK;HARD;1;OK - 92.2% (22747460 kB) free.
[1595788200] CURRENT SERVICE STATE: db1-vm2;Open-Files;OK;HARD;1;OK: 11648 open files (0% of max 2441815)
[1595788200] CURRENT SERVICE STATE: db1-vm2;OutOfMemory-killer--oom-killer;OK;HARD;1;Log check ok - 0 pattern matches found
[1595788200] CURRENT SERVICE STATE: db1-vm2;PING;OK;HARD;1;PING OK - Packet loss = 0%, RTA = 0.07 ms
[1595788200] CURRENT SERVICE STATE: db1-vm2;Total Processes;OK;HARD;1;PROCS OK: 390 processes
[1595788200] CURRENT SERVICE STATE: db2;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.02, 0.05
[1595788200] CURRENT SERVICE STATE: db2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.34% system=0.38% iowait=0.00% idle=99.29%
[1595788200] CURRENT SERVICE STATE: db2;CPU_Procs;OK;HARD;1;CPU OK: 290 processes
[1595788200] CURRENT SERVICE STATE: db2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: db2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 69276 MB (30% inode=99%):
[1595788200] CURRENT SERVICE STATE: db2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44497 MB (86% inode=99%):
[1595788200] CURRENT SERVICE STATE: db2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: db2;Mariadb status;OK;HARD;1;PROCS OK: 1 process with command name 'mysqld'
[1595788200] CURRENT SERVICE STATE: db2;Memory;CRITICAL;HARD;3;CRITICAL - 6.1% (3010976 kB) free!
[1595788200] CURRENT SERVICE STATE: db2;Open-Files;OK;HARD;1;OK: 6592 open files (0% of max 4878253)
[1595788200] CURRENT SERVICE STATE: db2;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: db2;Total Processes;OK;HARD;1;PROCS OK: 288 processes
[1595788200] CURRENT SERVICE STATE: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 64.15, 51.22, 49.30
[1595788200] CURRENT SERVICE STATE: mrq4;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=13.54% system=41.93% iowait=0.00% idle=44.53%
[1595788200] CURRENT SERVICE STATE: mrq4;CPU_Procs;OK;HARD;1;CPU OK: 1435 processes
[1595788200] CURRENT SERVICE STATE: mrq4;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: mrq4;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 211035 MB (95% inode=99%):
[1595788200] CURRENT SERVICE STATE: mrq4;HDD_Root status;OK;HARD;1;DISK OK - free space: / 45381 MB (88% inode=99%):
[1595788200] CURRENT SERVICE STATE: mrq4;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: mrq4;Memory;OK;HARD;1;OK - 43.9% (14378248 kB) free.
[1595788200] CURRENT SERVICE STATE: mrq4;Open-Files;OK;HARD;1;OK: 71008 open files (2% of max 3240801)
[1595788200] CURRENT SERVICE STATE: mrq4;Total Processes;CRITICAL;HARD;3;PROCS CRITICAL: 1441 processes
[1595788200] CURRENT SERVICE STATE: primary-server;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.03, 0.05
[1595788200] CURRENT SERVICE STATE: primary-server;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.03% system=0.19% iowait=0.00% idle=99.79%
[1595788200] CURRENT SERVICE STATE: primary-server;CPU_Procs;OK;HARD;1;CPU OK: 306 processes
[1595788200] CURRENT SERVICE STATE: primary-server;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595788200] CURRENT SERVICE STATE: primary-server;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 204578 MB (91% inode=99%):
[1595788200] CURRENT SERVICE STATE: primary-server;HDD_Root status;OK;HARD;1;DISK OK - free space: / 13891 MB (27% inode=99%):
[1595788200] CURRENT SERVICE STATE: primary-server;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: primary-server;Memory;OK;HARD;1;OK - 89.7% (21977536 kB) free.
[1595788200] CURRENT SERVICE STATE: primary-server;Nginx Access Log Status;CRITICAL;HARD;3;(1424) < 182.18.184.244 [26/Jul/2020:23:52:03 +0530] TCP 502 0 0 0.002 "10.147.212.37:5500, 10.147.212.38:5500, 10.147.212.49:5500, backend_5001" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.001, 0.000"
[1595788200] CURRENT SERVICE STATE: primary-server;Nginx Error Log Status;CRITICAL;HARD;3;(3052) < 2020/07/26 23:52:53 [error] 1786#0: *2573902 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5001, upstream: "backend_5001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595788200] CURRENT SERVICE STATE: primary-server;Nginx Status;OK;HARD;1;NGINX OK -  0.087 sec. response time, Active: 0 (Writing: 0 Reading: 0 Waiting: 0) ReqPerSec: 0.000 ConnPerSec: 0.000 ReqPerConn: 0.000
[1595788200] CURRENT SERVICE STATE: primary-server;Open-Files;OK;HARD;1;OK: 7008 open files (0% of max 2423416)
[1595788200] CURRENT SERVICE STATE: primary-server;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: primary-server;Total Processes;OK;HARD;1;PROCS OK: 307 processes
[1595788200] CURRENT SERVICE STATE: pservercluster1;CPU Load;OK;HARD;1;OK - load average: 1.97, 2.26, 2.22
[1595788200] CURRENT SERVICE STATE: pservercluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=2.47% system=10.34% iowait=0.01% idle=87.18%
[1595788200] CURRENT SERVICE STATE: pservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 338 processes
[1595788200] CURRENT SERVICE STATE: pservercluster1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595788200] CURRENT SERVICE STATE: pservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 190429 MB (86% inode=99%):
[1595788200] CURRENT SERVICE STATE: pservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39498 MB (77% inode=99%):
[1595788200] CURRENT SERVICE STATE: pservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: pservercluster1;Memory;OK;HARD;1;OK - 88.2% (21763844 kB) free.
[1595788200] CURRENT SERVICE STATE: pservercluster1;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1595788200] CURRENT SERVICE STATE: pservercluster1;Open-Files;OK;HARD;1;OK: 11232 open files (0% of max 2440681)
[1595788200] CURRENT SERVICE STATE: pservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: pservercluster1;Total Processes;OK;HARD;1;PROCS OK: 338 processes
[1595788200] CURRENT SERVICE STATE: pservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.92, 1.13, 1.13
[1595788200] CURRENT SERVICE STATE: pservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.82% system=7.22% iowait=0.00% idle=90.97%
[1595788200] CURRENT SERVICE STATE: pservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 332 processes
[1595788200] CURRENT SERVICE STATE: pservercluster2;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595788200] CURRENT SERVICE STATE: pservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 172112 MB (76% inode=99%):
[1595788200] CURRENT SERVICE STATE: pservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 38297 MB (74% inode=98%):
[1595788200] CURRENT SERVICE STATE: pservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: pservercluster2;Memory;OK;HARD;1;OK - 89.7% (21985972 kB) free.
[1595788200] CURRENT SERVICE STATE: pservercluster2;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1595788200] CURRENT SERVICE STATE: pservercluster2;Open-Files;OK;HARD;1;OK: 7168 open files (0% of max 2424156)
[1595788200] CURRENT SERVICE STATE: pservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: pservercluster2;Total Processes;OK;HARD;1;PROCS OK: 331 processes
[1595788200] CURRENT SERVICE STATE: qservercluster1;CPU Load;OK;HARD;1;OK - load average: 7.21, 6.96, 6.80
[1595788200] CURRENT SERVICE STATE: qservercluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=30.14% system=14.04% iowait=0.00% idle=55.81%
[1595788200] CURRENT SERVICE STATE: qservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 299 processes
[1595788200] CURRENT SERVICE STATE: qservercluster1;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: qservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 224641 MB (99% inode=99%):
[1595788200] CURRENT SERVICE STATE: qservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 43649 MB (85% inode=99%):
[1595788200] CURRENT SERVICE STATE: qservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: qservercluster1;Memory;OK;HARD;1;OK - 91.7% (45179932 kB) free.
[1595788200] CURRENT SERVICE STATE: qservercluster1;Open-Files;OK;HARD;1;OK: 9184 open files (0% of max 4874250)
[1595788200] CURRENT SERVICE STATE: qservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: qservercluster1;Total Processes;OK;HARD;1;PROCS OK: 297 processes
[1595788200] CURRENT SERVICE STATE: qservercluster2;CPU Load;OK;HARD;1;OK - load average: 3.58, 4.40, 4.78
[1595788200] CURRENT SERVICE STATE: qservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=7.44% system=20.43% iowait=0.12% idle=72.01%
[1595788200] CURRENT SERVICE STATE: qservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 768 processes
[1595788200] CURRENT SERVICE STATE: qservercluster2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: qservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 166020 MB (73% inode=99%):
[1595788200] CURRENT SERVICE STATE: qservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 27002 MB (52% inode=98%):
[1595788200] CURRENT SERVICE STATE: qservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: qservercluster2;Memory;OK;HARD;1;OK - 44.4% (21861232 kB) free.
[1595788200] CURRENT SERVICE STATE: qservercluster2;Open-Files;OK;HARD;1;OK: 22528 open files (0% of max 4878254)
[1595788200] CURRENT SERVICE STATE: qservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: qservercluster2;Total Processes;WARNING;HARD;3;PROCS WARNING: 770 processes
[1595788200] CURRENT SERVICE STATE: redis-1;CPU Load;OK;HARD;1;OK - load average: 2.00, 1.39, 0.81
[1595788200] CURRENT SERVICE STATE: redis-1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.73% system=1.10% iowait=0.01% idle=98.17%
[1595788200] CURRENT SERVICE STATE: redis-1;CPU_Procs;OK;HARD;1;CPU OK: 409 processes
[1595788200] CURRENT SERVICE STATE: redis-1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595788200] CURRENT SERVICE STATE: redis-1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 348653 MB (93% inode=99%):
[1595788200] CURRENT SERVICE STATE: redis-1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44224 MB (86% inode=99%):
[1595788200] CURRENT SERVICE STATE: redis-1;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /vns1 597854 MB (55% inode=99%):
[1595788200] CURRENT SERVICE STATE: redis-1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: redis-1;Memory;OK;HARD;1;OK - 34.2% (45041860 kB) free.
[1595788200] CURRENT SERVICE STATE: redis-1;Open-Files;OK;HARD;1;OK: 25152 open files (0% of max 13066864)
[1595788200] CURRENT SERVICE STATE: redis-1;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: redis-1;Total Processes;OK;HARD;1;PROCS OK: 408 processes
[1595788200] CURRENT SERVICE STATE: redis-2;CPU Load;OK;HARD;1;OK - load average: 0.16, 0.15, 0.14
[1595788200] CURRENT SERVICE STATE: redis-2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.35% system=0.70% iowait=0.01% idle=98.94%
[1595788200] CURRENT SERVICE STATE: redis-2;CPU_Procs;OK;HARD;1;CPU OK: 346 processes
[1595788200] CURRENT SERVICE STATE: redis-2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: redis-2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 234412 MB (62% inode=99%):
[1595788200] CURRENT SERVICE STATE: redis-2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44253 MB (86% inode=99%):
[1595788200] CURRENT SERVICE STATE: redis-2;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /vns1 1069171 MB (99% inode=99%):
[1595788200] CURRENT SERVICE STATE: redis-2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: redis-2;Memory;OK;HARD;1;OK - 57.6% (75964040 kB) free.
[1595788200] CURRENT SERVICE STATE: redis-2;Open-Files;OK;HARD;1;OK: 12720 open files (19% of max 65536)
[1595788200] CURRENT SERVICE STATE: redis-2;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: redis-2;Total Processes;OK;HARD;1;PROCS OK: 345 processes
[1595788200] CURRENT SERVICE STATE: rq-1;CPU Load;OK;HARD;1;OK - load average: 14.87, 14.85, 15.30
[1595788200] CURRENT SERVICE STATE: rq-1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=48.80% system=17.24% iowait=0.00% idle=33.96%
[1595788200] CURRENT SERVICE STATE: rq-1;CPU_Procs;WARNING;HARD;3;CPU WARNING: 1 warn out of 353 processes
[1595788200] CURRENT SERVICE STATE: rq-1;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: rq-1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 400998 MB (99% inode=99%):
[1595788200] CURRENT SERVICE STATE: rq-1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40946 MB (80% inode=99%):
[1595788200] CURRENT SERVICE STATE: rq-1;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /rq1vns1 1068147 MB (99% inode=99%):
[1595788200] CURRENT SERVICE STATE: rq-1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: rq-1;Memory;OK;HARD;1;OK - 80.5% (106151108 kB) free.
[1595788200] CURRENT SERVICE STATE: rq-1;Open-Files;OK;HARD;1;OK: 11232 open files (0% of max 13066902)
[1595788200] CURRENT SERVICE STATE: rq-1;Total Processes;OK;HARD;1;PROCS OK: 353 processes
[1595788200] CURRENT SERVICE STATE: rq-1;rq1-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1595788200] CURRENT SERVICE STATE: rq-2;CPU Load;OK;HARD;1;OK - load average: 16.79, 15.48, 15.16
[1595788200] CURRENT SERVICE STATE: rq-2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=48.08% system=17.30% iowait=0.01% idle=34.61%
[1595788200] CURRENT SERVICE STATE: rq-2;CPU_Procs;OK;HARD;1;CPU OK: 343 processes
[1595788200] CURRENT SERVICE STATE: rq-2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: rq-2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 401126 MB (99% inode=99%):
[1595788200] CURRENT SERVICE STATE: rq-2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 45548 MB (89% inode=99%):
[1595788200] CURRENT SERVICE STATE: rq-2;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /dev 64349 MB (100% inode=99%):
[1595788200] CURRENT SERVICE STATE: rq-2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: rq-2;Memory;OK;HARD;1;OK - 94.5% (124628096 kB) free.
[1595788200] CURRENT SERVICE STATE: rq-2;Open-Files;OK;HARD;1;OK: 10992 open files (0% of max 13066939)
[1595788200] CURRENT SERVICE STATE: rq-2;Total Processes;OK;HARD;1;PROCS OK: 345 processes
[1595788200] CURRENT SERVICE STATE: rq-2;rq2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1595788200] CURRENT SERVICE STATE: secondary-server;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.01, 0.05
[1595788200] CURRENT SERVICE STATE: secondary-server;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.03% system=0.08% iowait=0.00% idle=99.90%
[1595788200] CURRENT SERVICE STATE: secondary-server;CPU_Procs;OK;HARD;1;CPU OK: 304 processes
[1595788200] CURRENT SERVICE STATE: secondary-server;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595788200] CURRENT SERVICE STATE: secondary-server;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 101007 MB (44% inode=99%):
[1595788200] CURRENT SERVICE STATE: secondary-server;HDD_Root status;OK;HARD;1;DISK OK - free space: / 36620 MB (71% inode=99%):
[1595788200] CURRENT SERVICE STATE: secondary-server;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: secondary-server;Memory Status;OK;HARD;1;OK - 74.2% (18196524 kB) free.
[1595788200] CURRENT SERVICE STATE: secondary-server;Nginx Access Log Status;CRITICAL;HARD;3;(4) < 15.206.135.98 [26/Jul/2020:23:50:45 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1595788200] CURRENT SERVICE STATE: secondary-server;Nginx Error Log Status;CRITICAL;HARD;3;(4) < 2020/07/26 23:50:45 [error] 1823#0: *810418 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595788200] CURRENT SERVICE STATE: secondary-server;Nginx Status;OK;HARD;1;NGINX OK -  0.087 sec. response time, Active: 0 (Writing: 0 Reading: 0 Waiting: 0) ReqPerSec: 0.000 ConnPerSec: 0.000 ReqPerConn: 0.000
[1595788200] CURRENT SERVICE STATE: secondary-server;Open-Files;OK;HARD;1;OK: 6144 open files (0% of max 2423397)
[1595788200] CURRENT SERVICE STATE: secondary-server;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: secondary-server;Total Processes;OK;HARD;1;PROCS OK: 304 processes
[1595788200] CURRENT SERVICE STATE: sig1-vm2;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.00, 0.00
[1595788200] CURRENT SERVICE STATE: sig1-vm2;CPU_Procs;OK;HARD;1;CPU OK: 287 processes
[1595788200] CURRENT SERVICE STATE: sig1-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: sig1-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: sig1-vm2;Memory;OK;HARD;1;OK - 96.5% (15757372 kB) free.
[1595788200] CURRENT SERVICE STATE: sig1-vm2;Open-Files;OK;HARD;1;OK: 2688 open files (0% of max 1620608)
[1595788200] CURRENT SERVICE STATE: sig1-vm2;Root status;OK;HARD;1;DISK OK - free space: / 117793 MB (87% inode=96%):
[1595788200] CURRENT SERVICE STATE: sig1-vm2;Total Processes;OK;HARD;1;PROCS OK: 287 processes
[1595788200] CURRENT SERVICE STATE: sig2-vm2;CPU Load;OK;HARD;1;OK - load average: 3.65, 4.11, 4.13
[1595788200] CURRENT SERVICE STATE: sig2-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.75% system=6.15% iowait=0.00% idle=91.03%
[1595788200] CURRENT SERVICE STATE: sig2-vm2;CPU_Procs;OK;HARD;1;CPU OK: 381 processes
[1595788200] CURRENT SERVICE STATE: sig2-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: sig2-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 124095 MB (89% inode=99%):
[1595788200] CURRENT SERVICE STATE: sig2-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: sig2-vm2;Memory;OK;HARD;1;OK - 93.9% (32707060 kB) free.
[1595788200] CURRENT SERVICE STATE: sig2-vm2;Open-Files;OK;HARD;1;OK: 11968 open files (0% of max 3443846)
[1595788200] CURRENT SERVICE STATE: sig2-vm2;Total Processes;OK;HARD;1;PROCS OK: 381 processes
[1595788200] CURRENT SERVICE STATE: sig3-vm2;CPU Load;OK;HARD;1;OK - load average: 4.45, 3.34, 2.97
[1595788200] CURRENT SERVICE STATE: sig3-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=3.11% system=15.29% iowait=0.22% idle=81.38%
[1595788200] CURRENT SERVICE STATE: sig3-vm2;CPU_Procs;OK;HARD;1;CPU OK: 467 processes
[1595788200] CURRENT SERVICE STATE: sig3-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: sig3-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 90129 MB (75% inode=96%):
[1595788200] CURRENT SERVICE STATE: sig3-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 2 processes with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: sig3-vm2;Memory;OK;HARD;1;OK - 96.1% (22640968 kB) free.
[1595788200] CURRENT SERVICE STATE: sig3-vm2;Open-Files;OK;HARD;1;OK: 9536 open files (0% of max 2339574)
[1595788200] CURRENT SERVICE STATE: sig3-vm2;Total Processes;OK;HARD;1;PROCS OK: 467 processes
[1595788200] CURRENT SERVICE STATE: sig4-vm2;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.01, 0.05
[1595788200] CURRENT SERVICE STATE: sig4-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.06% system=0.00% iowait=0.00% idle=99.91%
[1595788200] CURRENT SERVICE STATE: sig4-vm2;CPU_Procs;OK;HARD;1;CPU OK: 220 processes
[1595788200] CURRENT SERVICE STATE: sig4-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: sig4-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 87127 MB (67% inode=99%):
[1595788200] CURRENT SERVICE STATE: sig4-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: sig4-vm2;Memory;OK;HARD;1;OK - 97.2% (33850400 kB) free.
[1595788200] CURRENT SERVICE STATE: sig4-vm2;Open-Files;OK;HARD;1;OK: 5728 open files (0% of max 3443901)
[1595788200] CURRENT SERVICE STATE: sig4-vm2;Total Processes;OK;HARD;1;PROCS OK: 225 processes
[1595788200] CURRENT SERVICE STATE: sig5-vm2;CPU Load;OK;HARD;1;OK - load average: 3.88, 4.07, 4.06
[1595788200] CURRENT SERVICE STATE: sig5-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.72% system=7.41% iowait=0.00% idle=89.71%
[1595788200] CURRENT SERVICE STATE: sig5-vm2;CPU_Procs;OK;HARD;1;CPU OK: 384 processes
[1595788200] CURRENT SERVICE STATE: sig5-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: sig5-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 230066 MB (91% inode=99%):
[1595788200] CURRENT SERVICE STATE: sig5-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: sig5-vm2;Memory;OK;HARD;1;OK - 92.3% (32341468 kB) free.
[1595788200] CURRENT SERVICE STATE: sig5-vm2;Open-Files;OK;HARD;1;OK: 11936 open files (0% of max 3462151)
[1595788200] CURRENT SERVICE STATE: sig5-vm2;Total Processes;OK;HARD;1;PROCS OK: 382 processes
[1595788200] CURRENT SERVICE STATE: sig6-vm2;CPU Load;OK;HARD;1;OK - load average: 5.26, 4.63, 4.34
[1595788200] CURRENT SERVICE STATE: sig6-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.97% system=7.85% iowait=0.00% idle=89.01%
[1595788200] CURRENT SERVICE STATE: sig6-vm2;CPU_Procs;OK;HARD;1;CPU OK: 382 processes
[1595788200] CURRENT SERVICE STATE: sig6-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: sig6-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 178524 MB (91% inode=99%):
[1595788200] CURRENT SERVICE STATE: sig6-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: sig6-vm2;Memory;OK;HARD;1;OK - 88.2% (19809512 kB) free.
[1595788200] CURRENT SERVICE STATE: sig6-vm2;Open-Files;OK;HARD;1;OK: 12000 open files (0% of max 2220276)
[1595788200] CURRENT SERVICE STATE: sig6-vm2;OutOfMemory-killer--oom-killer;OK;HARD;1;Log check ok - 0 pattern matches found
[1595788200] CURRENT SERVICE STATE: sig6-vm2;Total Processes;OK;HARD;1;PROCS OK: 380 processes
[1595788200] CURRENT SERVICE STATE: sigqscluster1;CPU Load;OK;HARD;1;OK - load average: 0.55, 0.30, 0.34
[1595788200] CURRENT SERVICE STATE: sigqscluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.20% system=1.22% iowait=0.50% idle=97.08%
[1595788200] CURRENT SERVICE STATE: sigqscluster1;CPU_Procs;OK;HARD;1;CPU OK: 1362 processes
[1595788200] CURRENT SERVICE STATE: sigqscluster1;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: sigqscluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 88784 MB (39% inode=99%):
[1595788200] CURRENT SERVICE STATE: sigqscluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39939 MB (78% inode=99%):
[1595788200] CURRENT SERVICE STATE: sigqscluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: sigqscluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.5% (226840 kB) free!
[1595788200] CURRENT SERVICE STATE: sigqscluster1;Open-Files;OK;HARD;1;OK: 61600 open files (1% of max 4878272)
[1595788200] CURRENT SERVICE STATE: sigqscluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: sigqscluster1;Total Processes;OK;HARD;1;PROCS OK: 1361 processes
[1595788200] CURRENT SERVICE STATE: sigqscluster2;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.01, 0.05
[1595788200] CURRENT SERVICE STATE: sigqscluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.33% system=0.25% iowait=0.00% idle=99.42%
[1595788200] CURRENT SERVICE STATE: sigqscluster2;CPU_Procs;OK;HARD;1;CPU OK: 292 processes
[1595788200] CURRENT SERVICE STATE: sigqscluster2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: sigqscluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 208151 MB (99% inode=99%):
[1595788200] CURRENT SERVICE STATE: sigqscluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44717 MB (87% inode=99%):
[1595788200] CURRENT SERVICE STATE: sigqscluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: sigqscluster2;Memory;OK;HARD;1;OK - 97.9% (48263156 kB) free.
[1595788200] CURRENT SERVICE STATE: sigqscluster2;Open-Files;OK;HARD;1;OK: 5696 open files (0% of max 4878254)
[1595788200] CURRENT SERVICE STATE: sigqscluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: sigqscluster2;Total Processes;OK;HARD;1;PROCS OK: 291 processes
[1595788200] CURRENT SERVICE STATE: sigqscluster2;sigqscluster2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1595788200] CURRENT SERVICE STATE: smscapp1;CPU Load;OK;HARD;1;OK - load average: 7.60, 7.51, 7.46
[1595788200] CURRENT SERVICE STATE: smscapp1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=7.13% system=18.05% iowait=0.00% idle=74.64%
[1595788200] CURRENT SERVICE STATE: smscapp1;CPU_Procs;OK;HARD;1;CPU OK: 1023 processes
[1595788200] CURRENT SERVICE STATE: smscapp1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595788200] CURRENT SERVICE STATE: smscapp1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 168447 MB (74% inode=99%):
[1595788200] CURRENT SERVICE STATE: smscapp1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39108 MB (76% inode=98%):
[1595788200] CURRENT SERVICE STATE: smscapp1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: smscapp1;Memory;WARNING;HARD;3;WARNING - 14.9% (7366952 kB) free!
[1595788200] CURRENT SERVICE STATE: smscapp1;Open-Files;OK;HARD;1;OK: 33088 open files (0% of max 4878253)
[1595788200] CURRENT SERVICE STATE: smscapp1;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: smscapp1;Total Processes;CRITICAL;HARD;3;PROCS CRITICAL: 1024 processes
[1595788200] CURRENT SERVICE STATE: smscapp2;CPU Load;OK;HARD;1;OK - load average: 9.27, 9.35, 9.44
[1595788200] CURRENT SERVICE STATE: smscapp2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=10.14% system=33.26% iowait=0.09% idle=56.50%
[1595788200] CURRENT SERVICE STATE: smscapp2;CPU_Procs;OK;HARD;1;CPU OK: 1776 processes
[1595788200] CURRENT SERVICE STATE: smscapp2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: smscapp2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 121072 MB (53% inode=99%):
[1595788200] CURRENT SERVICE STATE: smscapp2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 38776 MB (75% inode=98%):
[1595788200] CURRENT SERVICE STATE: smscapp2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: smscapp2;Memory;OK;HARD;1;OK - 84.8% (41801164 kB) free.
[1595788200] CURRENT SERVICE STATE: smscapp2;Open-Files;OK;HARD;1;OK: 88832 open files (1% of max 4878254)
[1595788200] CURRENT SERVICE STATE: smscapp2;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: smscapp2;Total Processes;OK;HARD;1;PROCS OK: 1777 processes
[1595788200] CURRENT SERVICE STATE: sservercluster1;CPU Load;OK;HARD;1;OK - load average: 1.22, 0.98, 0.96
[1595788200] CURRENT SERVICE STATE: sservercluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.38% system=5.09% iowait=0.01% idle=93.52%
[1595788200] CURRENT SERVICE STATE: sservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 334 processes
[1595788200] CURRENT SERVICE STATE: sservercluster1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595788200] CURRENT SERVICE STATE: sservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 188113 MB (85% inode=99%):
[1595788200] CURRENT SERVICE STATE: sservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40512 MB (79% inode=99%):
[1595788200] CURRENT SERVICE STATE: sservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: sservercluster1;Memory;OK;HARD;1;OK - 90.7% (22231416 kB) free.
[1595788200] CURRENT SERVICE STATE: sservercluster1;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1595788200] CURRENT SERVICE STATE: sservercluster1;Open-Files;OK;HARD;1;OK: 6304 open files (0% of max 2424092)
[1595788200] CURRENT SERVICE STATE: sservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: sservercluster1;Total Processes;OK;HARD;1;PROCS OK: 336 processes
[1595788200] CURRENT SERVICE STATE: sservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.38, 0.58, 0.67
[1595788200] CURRENT SERVICE STATE: sservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.89% system=3.81% iowait=0.04% idle=95.25%
[1595788200] CURRENT SERVICE STATE: sservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 331 processes
[1595788200] CURRENT SERVICE STATE: sservercluster2;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595788200] CURRENT SERVICE STATE: sservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 196716 MB (89% inode=99%):
[1595788200] CURRENT SERVICE STATE: sservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 33129 MB (64% inode=98%):
[1595788200] CURRENT SERVICE STATE: sservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: sservercluster2;Memory;OK;HARD;1;OK - 87.8% (21528344 kB) free.
[1595788200] CURRENT SERVICE STATE: sservercluster2;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1595788200] CURRENT SERVICE STATE: sservercluster2;Open-Files;OK;HARD;1;OK: 7136 open files (0% of max 2424092)
[1595788200] CURRENT SERVICE STATE: sservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: sservercluster2;Total Processes;OK;HARD;1;PROCS OK: 332 processes
[1595788200] CURRENT SERVICE STATE: webserver1;CPU Load;OK;HARD;1;OK - load average: 0.01, 0.02, 0.05
[1595788200] CURRENT SERVICE STATE: webserver1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.01% system=0.03% iowait=0.00% idle=99.96%
[1595788200] CURRENT SERVICE STATE: webserver1;CPU_Procs;OK;HARD;1;CPU OK: 325 processes
[1595788200] CURRENT SERVICE STATE: webserver1;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595788200] CURRENT SERVICE STATE: webserver1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 224773 MB (99% inode=99%):
[1595788200] CURRENT SERVICE STATE: webserver1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40123 MB (78% inode=99%):
[1595788200] CURRENT SERVICE STATE: webserver1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: webserver1;Memory;OK;HARD;1;OK - 94.2% (23055316 kB) free.
[1595788200] CURRENT SERVICE STATE: webserver1;Nginx_status;OK;HARD;1;NGINX OK -  0.091 sec. response time, Active: 1 (Writing: 1 Reading: 0 Waiting: 0) ReqPerSec: 0.735 ConnPerSec: 0.742 ReqPerConn: 0.997
[1595788200] CURRENT SERVICE STATE: webserver1;Open-Files;OK;HARD;1;OK: 6208 open files (0% of max 2419418)
[1595788200] CURRENT SERVICE STATE: webserver1;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: webserver1;Total Processes;OK;HARD;1;PROCS OK: 326 processes
[1595788200] CURRENT SERVICE STATE: webserver2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.26% system=0.19% iowait=0.03% idle=99.52%
[1595788200] CURRENT SERVICE STATE: webserver2;CPU_Procs;OK;HARD;1;CPU OK: 347 processes
[1595788200] CURRENT SERVICE STATE: webserver2;Current Load;OK;HARD;1;OK - load average: 0.00, 0.01, 0.05
[1595788200] CURRENT SERVICE STATE: webserver2;Current Users;OK;HARD;1;USERS OK - 4 users currently logged in
[1595788200] CURRENT SERVICE STATE: webserver2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 101968 MB (45.37% inode=100%):
[1595788200] CURRENT SERVICE STATE: webserver2;HTTP;OK;HARD;1;HTTP OK: HTTP/1.1 200 OK - 355 bytes in 0.001 second response time
[1595788200] CURRENT SERVICE STATE: webserver2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: webserver2;Memory;OK;HARD;1;OK - 68.3% (16729720 kB) free.
[1595788200] CURRENT SERVICE STATE: webserver2;Open-Files;OK;HARD;1;OK: 6720 open files (0% of max 2423406)
[1595788200] CURRENT SERVICE STATE: webserver2;PING;OK;HARD;1;PING OK - Packet loss = 0%, RTA = 0.08 ms
[1595788200] CURRENT SERVICE STATE: webserver2;Root Partition;OK;HARD;1;DISK OK - free space: / 14844 MB (29.00% inode=99%):
[1595788200] CURRENT SERVICE STATE: webserver2;SSH;OK;HARD;1;SSH OK - OpenSSH_7.4 (protocol 2.0)
[1595788200] CURRENT SERVICE STATE: webserver2;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: webserver2;Total Processes;OK;HARD;1;PROCS OK: 159 processes with STATE = RSZDT
[1595788200] CURRENT SERVICE STATE: webservercluster1;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.01, 0.05
[1595788200] CURRENT SERVICE STATE: webservercluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.63% system=0.58% iowait=0.13% idle=98.67%
[1595788200] CURRENT SERVICE STATE: webservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 318 processes
[1595788200] CURRENT SERVICE STATE: webservercluster1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595788200] CURRENT SERVICE STATE: webservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: / 20108 MB (39% inode=99%):
[1595788200] CURRENT SERVICE STATE: webservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: /home 80234 MB (35% inode=99%):
[1595788200] CURRENT SERVICE STATE: webservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: webservercluster1;Memory;OK;HARD;1;OK - 82.2% (13367224 kB) free.
[1595788200] CURRENT SERVICE STATE: webservercluster1;Open-Files;OK;HARD;1;OK: 4576 open files (0% of max 1607067)
[1595788200] CURRENT SERVICE STATE: webservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: webservercluster1;Total Processes;OK;HARD;1;PROCS OK: 322 processes
[1595788200] CURRENT SERVICE STATE: webservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.64, 0.49, 0.43
[1595788200] CURRENT SERVICE STATE: webservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.34% system=0.69% iowait=0.05% idle=98.92%
[1595788200] CURRENT SERVICE STATE: webservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 287 processes
[1595788200] CURRENT SERVICE STATE: webservercluster2;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595788200] CURRENT SERVICE STATE: webservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 223899 MB (99% inode=99%):
[1595788200] CURRENT SERVICE STATE: webservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39448 MB (77% inode=99%):
[1595788200] CURRENT SERVICE STATE: webservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595788200] CURRENT SERVICE STATE: webservercluster2;Memory;OK;HARD;1;OK - 75.2% (12220316 kB) free.
[1595788200] CURRENT SERVICE STATE: webservercluster2;Open-Files;OK;HARD;1;OK: 8672 open files (0% of max 1607066)
[1595788200] CURRENT SERVICE STATE: webservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1595788200] CURRENT SERVICE STATE: webservercluster2;Total Processes;OK;HARD;1;PROCS OK: 292 processes
[1595788324] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1410) < 182.18.184.244 [27/Jul/2020:00:02:04 +0530] TCP 502 0 0 0.002 "10.147.212.61:5500, 10.147.212.37:5500, 10.147.212.49:5500, 10.147.212.38:5500" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.001, 0.000"
[1595788339] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:00:00:45 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1595788618] SERVICE ALERT: pservercluster2;Open-Files;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595788738] SERVICE ALERT: pservercluster2;Open-Files;OK;HARD;1;OK: 7328 open files (0% of max 2424156)
[1595788856] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 9.9% (2450124 kB) free!
[1595788920] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;WARNING;notify-service-by-email;WARNING - load average: 9.87, 31.36, 41.71
[1595788920] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 9.87, 31.36, 41.71
[1595788945] Auto-save of retention data completed successfully.
[1595788976] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 9.7% (2405352 kB) free!
[1595789074] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1441 processes
[1595789096] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 9.7% (2392732 kB) free!
[1595789096] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 9.7% (2392732 kB) free!
[1595789541] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.1% (3006416 kB) free!
[1595789696] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;OK;notify-service-by-email;OK - 85.8% (21178288 kB) free.
[1595789696] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 85.8% (21178288 kB) free.
[1595790105] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;WARNING;notify-service-by-email;WARNING - 14.3% (7036992 kB) free!
[1595790120] SERVICE FLAPPING ALERT: mrq4;CPU Load;STARTED; Service appears to have started flapping (22.2% change >= 20.0% threshold)
[1595790120] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 60.16, 52.50, 44.56
[1595790190] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1023 processes
[1595790755] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (230148 kB) free!
[1595791122] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 770 processes
[1595791375] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3025) < 2020/07/27 00:52:54 [error] 1785#0: *2614600 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "backend_5002", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595791390] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/27 00:50:45 [error] 1823#0: *819032 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595791722] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 352 processes
[1595791939] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:01:00:46 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1595792477] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.8% (197188 kB) free!
[1595792524] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1429) < 182.18.184.244 [27/Jul/2020:01:12:03 +0530] TCP 502 0 0 0.000 "backend_5002" "0" "0" "0.000"
[1595792545] Auto-save of retention data completed successfully.
[1595792597] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (191272 kB) free!
[1595792674] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1440 processes
[1595792718] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 86.9% (21310036 kB) free.
[1595793142] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.1% (3005732 kB) free!
[1595793317] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 8.7% (2126792 kB) free!
[1595793372] SERVICE ALERT: redis-1;Memory;WARNING;SOFT;1;WARNING - 11.0% (14493384 kB) free!
[1595793437] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.7% (167796 kB) free!
[1595793492] SERVICE ALERT: redis-1;Memory;CRITICAL;SOFT;2;CRITICAL - 3.7% (4901196 kB) free!
[1595793557] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (187016 kB) free!
[1595793557] SERVICE ALERT: sservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (187016 kB) free!
[1595793593] SERVICE ALERT: smscapp2;Memory;CRITICAL;SOFT;1;CRITICAL - 0.5% (234604 kB) free!
[1595793612] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.3% (453020 kB) free!
[1595793612] SERVICE ALERT: redis-1;Memory;CRITICAL;HARD;3;CRITICAL - 0.3% (453020 kB) free!
[1595793705] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;WARNING;notify-service-by-email;WARNING - 13.6% (6693612 kB) free!
[1595793713] SERVICE ALERT: smscapp2;Memory;CRITICAL;SOFT;2;CRITICAL - 0.4% (214856 kB) free!
[1595793790] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1024 processes
[1595793833] SERVICE NOTIFICATION: nagiosadmin;smscapp2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (233712 kB) free!
[1595793833] SERVICE ALERT: smscapp2;Memory;CRITICAL;HARD;3;CRITICAL - 0.5% (233712 kB) free!
[1595794157] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;WARNING;notify-service-by-email;WARNING - 10.2% (2506332 kB) free!
[1595794157] SERVICE ALERT: sservercluster1;Memory;WARNING;HARD;3;WARNING - 10.2% (2506332 kB) free!
[1595794356] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (243000 kB) free!
[1595794722] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 768 processes
[1595794757] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;OK;notify-service-by-email;OK - 85.4% (20930344 kB) free.
[1595794757] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 85.4% (20930344 kB) free.
[1595794975] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3305) < 2020/07/27 01:52:54 [error] 1784#0: *2656898 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "10.147.212.49:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595795322] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 351 processes
[1595795521] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 54.32, 44.22, 44.23
[1595795590] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/27 02:00:45 [error] 1822#0: *827627 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595795633] SERVICE NOTIFICATION: nagiosadmin;smscapp2;Memory;OK;notify-service-by-email;OK - 26.0% (12811580 kB) free.
[1595795633] SERVICE ALERT: smscapp2;Memory;OK;HARD;1;OK - 26.0% (12811580 kB) free.
[1595795822] SERVICE ALERT: pservercluster2;Memory;WARNING;SOFT;1;WARNING - 18.0% (4399884 kB) free!
[1595795942] SERVICE ALERT: pservercluster2;Memory;OK;HARD;1;OK - 86.5% (21199924 kB) free.
[1595795957] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.9% (216300 kB) free!
[1595796077] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (206244 kB) free!
[1595796124] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1432) < 182.18.184.244 [27/Jul/2020:02:12:03 +0530] TCP 502 0 0 0.000 "backend_5000" "0" "0" "0.000"
[1595796138] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:02:10:45 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1595796145] Auto-save of retention data completed successfully.
[1595796197] SERVICE FLAPPING ALERT: sservercluster1;Memory;STARTED; Service appears to have started flapping (23.8% change >= 20.0% threshold)
[1595796197] SERVICE ALERT: sservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (191068 kB) free!
[1595796274] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1436 processes
[1595797212] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (528488 kB) free!
[1595797305] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;OK;notify-service-by-email;OK - 80.5% (39684056 kB) free.
[1595797305] SERVICE ALERT: smscapp1;Memory;OK;HARD;1;OK - 80.5% (39684056 kB) free.
[1595797341] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.1% (3004632 kB) free!
[1595797390] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1595797397] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 87.4% (21420772 kB) free.
[1595797921] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 68.91, 48.33, 44.33
[1595797956] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (248392 kB) free!
[1595798322] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 768 processes
[1595798575] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3376) < 2020/07/27 02:52:54 [error] 1783#0: *2700222 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "10.147.212.37:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595798922] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 351 processes
[1595799190] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(329) < 2020/07/27 03:03:07 [error] 1811#0: *836040 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595799721] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 33.58, 41.47, 44.59
[1595799738] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:03:10:45 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1595799745] Auto-save of retention data completed successfully.
[1595799797] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.8% (195240 kB) free!
[1595799874] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1437 processes
[1595799918] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 82.6% (20249668 kB) free.
[1595800321] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 62.26, 46.25, 45.32
[1595800324] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1433) < 182.18.184.244 [27/Jul/2020:03:22:04 +0530] TCP 502 0 0 0.002 "10.147.212.61:5500, 10.147.212.37:5500, 10.147.212.38:5500, 10.147.212.49:5500" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.001, 0.000"
[1595800517] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.7% (163020 kB) free!
[1595800637] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (188644 kB) free!
[1595800757] SERVICE ALERT: sservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (193044 kB) free!
[1595800812] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (577716 kB) free!
[1595800921] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 52.67, 45.52, 44.60
[1595800941] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.1% (3016700 kB) free!
[1595800990] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1022 processes
[1595801357] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 90.9% (22277128 kB) free.
[1595801556] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (219784 kB) free!
[1595801922] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 769 processes
[1595802121] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 65.22, 50.43, 45.97
[1595802175] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3756) < 2020/07/27 03:52:54 [error] 1782#0: *2751810 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "10.147.212.37:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595802522] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 352 processes
[1595802721] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 38.30, 42.38, 44.23
[1595802790] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(150) < 2020/07/27 04:03:08 [error] 1816#0: *848368 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595803321] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 52.13, 49.38, 46.51
[1595803339] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:04:10:45 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1595803345] Auto-save of retention data completed successfully.
[1595803474] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1439 processes
[1595803921] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 32.59, 38.81, 42.17
[1595804412] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (707896 kB) free!
[1595804523] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1431) < 182.18.184.244 [27/Jul/2020:04:32:03 +0530] TCP 502 0 0 0.000 "backend_5000" "0" "0" "0.000"
[1595804541] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.1% (2996836 kB) free!
[1595804590] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1020 processes
[1595805157] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (382156 kB) free!
[1595805522] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 768 processes
[1595805721] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 60.06, 46.88, 43.15
[1595806122] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 354 processes
[1595806321] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 43.63, 47.80, 44.68
[1595806374] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3652) < 2020/07/27 05:02:54 [error] 1777#0: *2809752 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5001, upstream: "10.147.212.37:5500", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595806945] Auto-save of retention data completed successfully.
[1595806989] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(151) < 2020/07/27 05:13:06 [error] 1809#0: *864663 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595807074] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1436 processes
[1595807539] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:05:20:45 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1595808012] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.6% (816016 kB) free!
[1595808124] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1430) < 182.18.184.244 [27/Jul/2020:05:32:03 +0530] TCP 502 0 0 0.000 "backend_5003" "0" "0" "0.000"
[1595808141] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.1% (2998540 kB) free!
[1595808190] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1022 processes
[1595809123] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 769 processes
[1595809356] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (235712 kB) free!
[1595809722] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 354 processes
[1595809974] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3279) < 2020/07/27 06:02:54 [error] 1785#0: *2857730 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5000, upstream: "backend_5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595810545] Auto-save of retention data completed successfully.
[1595810589] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(134) < 2020/07/27 06:12:58 [error] 1823#0: *885712 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595810675] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1438 processes
[1595811612] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.3% (400320 kB) free!
[1595811721] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 123.58, 72.27, 55.99
[1595811738] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:06:30:45 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1595811741] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.1% (2998924 kB) free!
[1595811790] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1595812323] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1433) < 182.18.184.244 [27/Jul/2020:06:42:03 +0530] TCP 502 0 0 0.000 "backend_5002" "0" "0" "0.000"
[1595812757] SERVICE FLAPPING ALERT: sservercluster1;Memory;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1595812757] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;OK;notify-service-by-email;OK - 86.4% (21177584 kB) free.
[1595812812] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;OK;notify-service-by-email;OK - 46.4% (61148916 kB) free.
[1595812812] SERVICE ALERT: redis-1;Memory;OK;HARD;1;OK - 46.4% (61148916 kB) free.
[1595812957] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (227520 kB) free!
[1595813322] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 357 processes
[1595813322] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 771 processes
[1595813574] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3446) < 2020/07/27 07:02:54 [error] 1786#0: *2904927 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5000, upstream: "10.147.212.49:5500", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595814145] Auto-save of retention data completed successfully.
[1595814189] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(134) < 2020/07/27 07:13:07 [error] 1820#0: *906737 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595814874] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1644 processes
[1595815339] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:07:30:45 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1595815341] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.1% (2999380 kB) free!
[1595815390] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1022 processes
[1595815924] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1427) < 182.18.184.244 [27/Jul/2020:07:42:02 +0530] TCP 502 0 0 0.000 "backend_5003" "0" "0" "0.000"
[1595816922] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 772 processes
[1595816922] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 354 processes
[1595817156] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (337136 kB) free!
[1595817174] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3511) < 2020/07/27 08:02:53 [error] 1790#0: *2952014 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "10.147.212.38:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595817745] Auto-save of retention data completed successfully.
[1595817789] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(152) < 2020/07/27 08:13:09 [error] 1814#0: *927790 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595818321] SERVICE FLAPPING ALERT: mrq4;CPU Load;STOPPED; Service appears to have stopped flapping (4.8% change < 5.0% threshold)
[1595818321] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 55.17, 64.16, 70.23
[1595818474] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1644 processes
[1595818941] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.1% (2996504 kB) free!
[1595818990] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1023 processes
[1595819538] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:08:40:45 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1595820124] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1431) < 182.18.184.244 [27/Jul/2020:08:52:03 +0530] TCP 502 0 0 0.000 "backend_5002" "0" "0" "0.000"
[1595820522] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 351 processes
[1595820522] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 771 processes
[1595820756] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (409076 kB) free!
[1595820774] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3532) < 2020/07/27 09:02:54 [error] 1786#0: *2994197 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5001, upstream: "10.147.212.37:5500", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595821238] SERVICE ALERT: webservercluster1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 319 processes
[1595821345] Auto-save of retention data completed successfully.
[1595821358] SERVICE ALERT: webservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 317 processes
[1595821389] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(216) < 2020/07/27 09:13:01 [error] 1809#0: *949975 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595821921] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 84.60, 87.09, 87.47
[1595822074] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1645 processes
[1595822541] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.1% (2998152 kB) free!
[1595822591] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1024 processes
[1595823138] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:09:40:45 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1595824122] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 353 processes
[1595824123] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 771 processes
[1595824323] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1419) < 182.18.184.244 [27/Jul/2020:10:02:03 +0530] TCP 502 0 0 0.000 "backend_5000" "0" "0" "0.000"
[1595824356] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.5% (722948 kB) free!
[1595824375] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3624) < 2020/07/27 10:02:54 [error] 1786#0: *3045370 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "10.147.212.37:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595824945] Auto-save of retention data completed successfully.
[1595824989] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(232) < 2020/07/27 10:13:05 [error] 1811#0: *981767 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595825521] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 119.63, 99.88, 98.07
[1595825675] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1636 processes
[1595826142] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.1% (2996876 kB) free!
[1595826191] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1024 processes
[1595826558] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;SOFT;1;CRITICAL - load average: 16119.13, 13521.91, 7159.09
[1595826672] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;SOFT;1;CRITICAL - load average: 15067.21, 6831.11, 2621.64
[1595826678] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;SOFT;2;CRITICAL - load average: 16121.23, 14381.97, 8245.74
[1595826739] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:10:40:45 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1595826792] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;SOFT;2;CRITICAL - load average: 15951.37, 9894.43, 4254.60
[1595826798] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 16122.45, 14958.05, 9200.86
[1595826798] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 16122.45, 14958.05, 9200.86
[1595826851] SERVICE ALERT: pservercluster1;CPU Load;CRITICAL;SOFT;1;CRITICAL - load average: 16083.50, 13122.09, 6751.03
[1595826912] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 16071.00, 11944.18, 5689.55
[1595826912] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 16071.00, 11944.18, 5689.55
[1595826971] SERVICE ALERT: pservercluster1;CPU Load;CRITICAL;SOFT;2;CRITICAL - load average: 16086.80, 14103.21, 7883.05
[1595827091] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 16087.47, 14759.74, 8877.82
[1595827091] SERVICE ALERT: pservercluster1;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 16087.47, 14759.74, 8877.82
[1595827722] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 356 processes
[1595827923] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1416) < 182.18.184.244 [27/Jul/2020:11:02:03 +0530] TCP 502 0 0 0.002 "10.147.212.61:5501, 10.147.212.38:5501, 10.147.212.49:5501, 10.147.212.37:5501" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.001, 0.000"
[1595827956] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.4% (697344 kB) free!
[1595828322] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 770 processes
[1595828545] Auto-save of retention data completed successfully.
[1595828558] SERVICE ALERT: webservercluster1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 315 processes
[1595828566] SERVICE ALERT: pservercluster2;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 329 processes
[1595828575] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3835) < 2020/07/27 11:12:53 [error] 1784#0: *3105740 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "10.147.212.37:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595828590] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(235) < 2020/07/27 11:13:09 [error] 1817#0: *1012015 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595828678] SERVICE ALERT: webservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 316 processes
[1595828686] SERVICE ALERT: pservercluster2;CPU_Procs;WARNING;SOFT;2;CPU WARNING: 1 warn out of 329 processes
[1595828807] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 333 processes
[1595828807] SERVICE ALERT: pservercluster2;CPU_Procs;WARNING;HARD;3;CPU WARNING: 1 warn out of 333 processes
[1595829121] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 110.17, 108.37, 102.24
[1595829791] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1025 processes
[1595829798] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU Load;OK;notify-service-by-email;OK - load average: 2.68, 3.23, 412.28
[1595829798] SERVICE ALERT: pservercluster2;CPU Load;OK;HARD;1;OK - load average: 2.68, 3.23, 412.28
[1595829874] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1635 processes
[1595830339] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:11:40:45 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1595830341] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.1% (3004600 kB) free!
[1595830424] Caught SIGTERM, shutting down...
[1595830424] Caught SIGTERM, shutting down...
[1595830424] Successfully shutdown... (PID=12317)
[1595830424] Nagios 4.4.2 starting... (PID=4948)
[1595830424] Local time is Mon Jul 27 11:43:44 IST 2020
[1595830424] LOG VERSION: 2.0
[1595830424] qh: Socket '/usr/local/nagios/var/rw/nagios.qh' successfully initialized
[1595830424] qh: core query handler registered
[1595830424] qh: echo service query handler registered
[1595830424] qh: help for the query handler registered
[1595830424] wproc: Successfully registered manager as @wproc with query handler
[1595830424] wproc: Registry request: name=Core Worker 4951;pid=4951
[1595830424] wproc: Registry request: name=Core Worker 4953;pid=4953
[1595830424] wproc: Registry request: name=Core Worker 4952;pid=4952
[1595830424] wproc: Registry request: name=Core Worker 4954;pid=4954
[1595830424] wproc: Registry request: name=Core Worker 4955;pid=4955
[1595830424] wproc: Registry request: name=Core Worker 4956;pid=4956
[1595830424] wproc: Registry request: name=Core Worker 4957;pid=4957
[1595830424] wproc: Registry request: name=Core Worker 4958;pid=4958
[1595830424] wproc: Registry request: name=Core Worker 4960;pid=4960
[1595830424] wproc: Registry request: name=Core Worker 4959;pid=4959
[1595830424] wproc: Registry request: name=Core Worker 4961;pid=4961
[1595830424] wproc: Registry request: name=Core Worker 4962;pid=4962
[1595830424] wproc: Registry request: name=Core Worker 4964;pid=4964
[1595830424] wproc: Registry request: name=Core Worker 4963;pid=4963
[1595830424] wproc: Registry request: name=Core Worker 4965;pid=4965
[1595830424] wproc: Registry request: name=Core Worker 4967;pid=4967
[1595830424] wproc: Registry request: name=Core Worker 4966;pid=4966
[1595830424] wproc: Registry request: name=Core Worker 4968;pid=4968
[1595830424] wproc: Registry request: name=Core Worker 4969;pid=4969
[1595830424] wproc: Registry request: name=Core Worker 4970;pid=4970
[1595830424] wproc: Registry request: name=Core Worker 4971;pid=4971
[1595830424] wproc: Registry request: name=Core Worker 4973;pid=4973
[1595830424] wproc: Registry request: name=Core Worker 4974;pid=4974
[1595830424] wproc: Registry request: name=Core Worker 4972;pid=4972
[1595830434] Successfully launched command file worker with pid 4975
[1595830512] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU Load;OK;notify-service-by-email;OK - load average: 1.46, 2.53, 397.67
[1595830512] SERVICE ALERT: sservercluster1;CPU Load;OK;HARD;1;OK - load average: 1.46, 2.53, 397.67
[1595830691] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU Load;OK;notify-service-by-email;OK - load average: 1.68, 2.07, 262.98
[1595830691] SERVICE ALERT: pservercluster1;CPU Load;OK;HARD;1;OK - load average: 1.68, 2.07, 262.98
[1595830767] Caught SIGTERM, shutting down...
[1595830767] Caught SIGTERM, shutting down...
[1595830767] Caught SIGTERM, shutting down...
[1595830767] Successfully shutdown... (PID=4948)
[1595830767] Nagios 4.4.2 starting... (PID=5521)
[1595830767] Local time is Mon Jul 27 11:49:27 IST 2020
[1595830767] LOG VERSION: 2.0
[1595830767] qh: Socket '/usr/local/nagios/var/rw/nagios.qh' successfully initialized
[1595830767] qh: core query handler registered
[1595830767] qh: echo service query handler registered
[1595830767] qh: help for the query handler registered
[1595830767] wproc: Successfully registered manager as @wproc with query handler
[1595830767] wproc: Registry request: name=Core Worker 5522;pid=5522
[1595830767] wproc: Registry request: name=Core Worker 5523;pid=5523
[1595830767] wproc: Registry request: name=Core Worker 5524;pid=5524
[1595830767] wproc: Registry request: name=Core Worker 5525;pid=5525
[1595830767] wproc: Registry request: name=Core Worker 5526;pid=5526
[1595830767] wproc: Registry request: name=Core Worker 5527;pid=5527
[1595830767] wproc: Registry request: name=Core Worker 5529;pid=5529
[1595830767] wproc: Registry request: name=Core Worker 5528;pid=5528
[1595830767] wproc: Registry request: name=Core Worker 5530;pid=5530
[1595830767] wproc: Registry request: name=Core Worker 5532;pid=5532
[1595830767] wproc: Registry request: name=Core Worker 5531;pid=5531
[1595830767] wproc: Registry request: name=Core Worker 5533;pid=5533
[1595830767] wproc: Registry request: name=Core Worker 5534;pid=5534
[1595830767] wproc: Registry request: name=Core Worker 5535;pid=5535
[1595830767] wproc: Registry request: name=Core Worker 5536;pid=5536
[1595830767] wproc: Registry request: name=Core Worker 5537;pid=5537
[1595830767] wproc: Registry request: name=Core Worker 5538;pid=5538
[1595830767] wproc: Registry request: name=Core Worker 5540;pid=5540
[1595830767] wproc: Registry request: name=Core Worker 5539;pid=5539
[1595830767] wproc: Registry request: name=Core Worker 5544;pid=5544
[1595830767] wproc: Registry request: name=Core Worker 5543;pid=5543
[1595830767] wproc: Registry request: name=Core Worker 5541;pid=5541
[1595830767] wproc: Registry request: name=Core Worker 5542;pid=5542
[1595830767] wproc: Registry request: name=Core Worker 5545;pid=5545
[1595830777] Successfully launched command file worker with pid 5548
[1595831156] Caught SIGTERM, shutting down...
[1595831156] Caught SIGTERM, shutting down...
[1595831156] Caught SIGTERM, shutting down...
[1595831156] Successfully shutdown... (PID=5521)
[1595831156] Nagios 4.4.2 starting... (PID=6173)
[1595831156] Local time is Mon Jul 27 11:55:56 IST 2020
[1595831156] LOG VERSION: 2.0
[1595831156] qh: Socket '/usr/local/nagios/var/rw/nagios.qh' successfully initialized
[1595831156] qh: core query handler registered
[1595831156] qh: echo service query handler registered
[1595831156] qh: help for the query handler registered
[1595831156] wproc: Successfully registered manager as @wproc with query handler
[1595831156] wproc: Registry request: name=Core Worker 6175;pid=6175
[1595831156] wproc: Registry request: name=Core Worker 6174;pid=6174
[1595831156] wproc: Registry request: name=Core Worker 6176;pid=6176
[1595831156] wproc: Registry request: name=Core Worker 6178;pid=6178
[1595831156] wproc: Registry request: name=Core Worker 6177;pid=6177
[1595831156] wproc: Registry request: name=Core Worker 6179;pid=6179
[1595831156] wproc: Registry request: name=Core Worker 6181;pid=6181
[1595831156] wproc: Registry request: name=Core Worker 6180;pid=6180
[1595831156] wproc: Registry request: name=Core Worker 6182;pid=6182
[1595831156] wproc: Registry request: name=Core Worker 6183;pid=6183
[1595831156] wproc: Registry request: name=Core Worker 6184;pid=6184
[1595831156] wproc: Registry request: name=Core Worker 6185;pid=6185
[1595831156] wproc: Registry request: name=Core Worker 6186;pid=6186
[1595831156] wproc: Registry request: name=Core Worker 6188;pid=6188
[1595831156] wproc: Registry request: name=Core Worker 6187;pid=6187
[1595831156] wproc: Registry request: name=Core Worker 6190;pid=6190
[1595831156] wproc: Registry request: name=Core Worker 6192;pid=6192
[1595831156] wproc: Registry request: name=Core Worker 6191;pid=6191
[1595831156] wproc: Registry request: name=Core Worker 6193;pid=6193
[1595831156] wproc: Registry request: name=Core Worker 6194;pid=6194
[1595831156] wproc: Registry request: name=Core Worker 6189;pid=6189
[1595831156] wproc: Registry request: name=Core Worker 6196;pid=6196
[1595831156] wproc: Registry request: name=Core Worker 6195;pid=6195
[1595831156] wproc: Registry request: name=Core Worker 6197;pid=6197
[1595831166] Successfully launched command file worker with pid 6200
[1595831322] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 353 processes
[1595831524] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1428) < 182.18.184.244 [27/Jul/2020:12:02:03 +0530] TCP 502 0 0 0.002 "10.147.212.61:5501, 10.147.212.37:5501, 10.147.212.38:5501, 10.147.212.49:5501" "0, 0, 0, 0" "0, 0, 0, 0" "0.000, 0.001, 0.000, 0.001"
[1595831556] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.8% (869608 kB) free!
[1595831923] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 773 processes
[1595832190] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(235) < 2020/07/27 12:13:06 [error] 1820#0: *1038782 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595832217] Caught SIGTERM, shutting down...
[1595832217] Caught SIGTERM, shutting down...
[1595832217] Caught SIGTERM, shutting down...
[1595832217] Successfully shutdown... (PID=6173)
[1595832217] Nagios 4.4.2 starting... (PID=8501)
[1595832217] Local time is Mon Jul 27 12:13:37 IST 2020
[1595832217] LOG VERSION: 2.0
[1595832217] qh: Socket '/usr/local/nagios/var/rw/nagios.qh' successfully initialized
[1595832217] qh: core query handler registered
[1595832217] qh: echo service query handler registered
[1595832217] qh: help for the query handler registered
[1595832217] wproc: Successfully registered manager as @wproc with query handler
[1595832217] wproc: Registry request: name=Core Worker 8502;pid=8502
[1595832217] wproc: Registry request: name=Core Worker 8503;pid=8503
[1595832217] wproc: Registry request: name=Core Worker 8505;pid=8505
[1595832217] wproc: Registry request: name=Core Worker 8504;pid=8504
[1595832217] wproc: Registry request: name=Core Worker 8507;pid=8507
[1595832217] wproc: Registry request: name=Core Worker 8508;pid=8508
[1595832217] wproc: Registry request: name=Core Worker 8510;pid=8510
[1595832217] wproc: Registry request: name=Core Worker 8506;pid=8506
[1595832217] wproc: Registry request: name=Core Worker 8509;pid=8509
[1595832217] wproc: Registry request: name=Core Worker 8511;pid=8511
[1595832217] wproc: Registry request: name=Core Worker 8514;pid=8514
[1595832217] wproc: Registry request: name=Core Worker 8512;pid=8512
[1595832217] wproc: Registry request: name=Core Worker 8516;pid=8516
[1595832217] wproc: Registry request: name=Core Worker 8513;pid=8513
[1595832217] wproc: Registry request: name=Core Worker 8515;pid=8515
[1595832217] wproc: Registry request: name=Core Worker 8517;pid=8517
[1595832217] wproc: Registry request: name=Core Worker 8518;pid=8518
[1595832217] wproc: Registry request: name=Core Worker 8519;pid=8519
[1595832217] wproc: Registry request: name=Core Worker 8521;pid=8521
[1595832217] wproc: Registry request: name=Core Worker 8520;pid=8520
[1595832217] wproc: Registry request: name=Core Worker 8522;pid=8522
[1595832217] wproc: Registry request: name=Core Worker 8525;pid=8525
[1595832217] wproc: Registry request: name=Core Worker 8524;pid=8524
[1595832217] wproc: Registry request: name=Core Worker 8523;pid=8523
[1595832227] Successfully launched command file worker with pid 8529
[1595832407] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 334 processes
[1595832721] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 95.15, 90.46, 95.38
[1595832774] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3721) < 2020/07/27 12:22:53 [error] 1786#0: *3167123 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "backend_5002", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595833012] SERVICE ALERT: mrq4;Memory;WARNING;SOFT;1;WARNING - 19.8% (6480136 kB) free!
[1595833132] SERVICE ALERT: mrq4;Memory;WARNING;SOFT;2;WARNING - 19.5% (6372924 kB) free!
[1595833252] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;WARNING;notify-service-by-email;WARNING - 19.2% (6279528 kB) free!
[1595833252] SERVICE ALERT: mrq4;Memory;WARNING;HARD;3;WARNING - 19.2% (6279528 kB) free!
[1595833391] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1026 processes
[1595833466] Caught SIGTERM, shutting down...
[1595833466] Caught SIGTERM, shutting down...
[1595833466] Caught SIGTERM, shutting down...
[1595833466] Successfully shutdown... (PID=8501)
[1595833466] Nagios 4.4.2 starting... (PID=11236)
[1595833466] Local time is Mon Jul 27 12:34:26 IST 2020
[1595833466] LOG VERSION: 2.0
[1595833466] qh: Socket '/usr/local/nagios/var/rw/nagios.qh' successfully initialized
[1595833466] qh: core query handler registered
[1595833466] qh: echo service query handler registered
[1595833466] qh: help for the query handler registered
[1595833466] wproc: Successfully registered manager as @wproc with query handler
[1595833466] wproc: Registry request: name=Core Worker 11239;pid=11239
[1595833466] wproc: Registry request: name=Core Worker 11237;pid=11237
[1595833466] wproc: Registry request: name=Core Worker 11238;pid=11238
[1595833466] wproc: Registry request: name=Core Worker 11241;pid=11241
[1595833466] wproc: Registry request: name=Core Worker 11244;pid=11244
[1595833466] wproc: Registry request: name=Core Worker 11246;pid=11246
[1595833466] wproc: Registry request: name=Core Worker 11243;pid=11243
[1595833466] wproc: Registry request: name=Core Worker 11240;pid=11240
[1595833466] wproc: Registry request: name=Core Worker 11242;pid=11242
[1595833466] wproc: Registry request: name=Core Worker 11245;pid=11245
[1595833466] wproc: Registry request: name=Core Worker 11247;pid=11247
[1595833466] wproc: Registry request: name=Core Worker 11248;pid=11248
[1595833466] wproc: Registry request: name=Core Worker 11250;pid=11250
[1595833466] wproc: Registry request: name=Core Worker 11253;pid=11253
[1595833466] wproc: Registry request: name=Core Worker 11249;pid=11249
[1595833466] wproc: Registry request: name=Core Worker 11252;pid=11252
[1595833466] wproc: Registry request: name=Core Worker 11251;pid=11251
[1595833466] wproc: Registry request: name=Core Worker 11256;pid=11256
[1595833466] wproc: Registry request: name=Core Worker 11257;pid=11257
[1595833466] wproc: Registry request: name=Core Worker 11255;pid=11255
[1595833466] wproc: Registry request: name=Core Worker 11259;pid=11259
[1595833466] wproc: Registry request: name=Core Worker 11254;pid=11254
[1595833466] wproc: Registry request: name=Core Worker 11260;pid=11260
[1595833466] wproc: Registry request: name=Core Worker 11258;pid=11258
[1595833476] Successfully launched command file worker with pid 11264
[1595833476] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1635 processes
[1595833515] SERVICE ALERT: TempHP1;zombie_procs;UNKNOWN;SOFT;1;NRPE: Command 'check_zombie_procs' not defined
[1595833607] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU_Procs;OK;notify-service-by-email;CPU OK: 329 processes
[1595833607] SERVICE ALERT: pservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 329 processes
[1595833635] SERVICE ALERT: TempHP1;zombie_procs;UNKNOWN;SOFT;2;NRPE: Command 'check_zombie_procs' not defined
[1595833711] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;TempHP1;zombie_procs;1595833709
[1595833711] SERVICE ALERT: TempHP1;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595833718] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;TempHP1;zombie_procs;1595833716
[1595833941] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.1% (2987964 kB) free!
[1595834364] Caught SIGTERM, shutting down...
[1595834364] Caught SIGTERM, shutting down...
[1595834364] Caught SIGTERM, shutting down...
[1595834365] Successfully shutdown... (PID=11236)
[1595834365] Nagios 4.4.2 starting... (PID=13581)
[1595834365] Local time is Mon Jul 27 12:49:25 IST 2020
[1595834365] LOG VERSION: 2.0
[1595834365] qh: Socket '/usr/local/nagios/var/rw/nagios.qh' successfully initialized
[1595834365] qh: core query handler registered
[1595834365] qh: echo service query handler registered
[1595834365] qh: help for the query handler registered
[1595834365] wproc: Successfully registered manager as @wproc with query handler
[1595834365] wproc: Registry request: name=Core Worker 13583;pid=13583
[1595834365] wproc: Registry request: name=Core Worker 13582;pid=13582
[1595834365] wproc: Registry request: name=Core Worker 13585;pid=13585
[1595834365] wproc: Registry request: name=Core Worker 13584;pid=13584
[1595834365] wproc: Registry request: name=Core Worker 13586;pid=13586
[1595834365] wproc: Registry request: name=Core Worker 13588;pid=13588
[1595834365] wproc: Registry request: name=Core Worker 13587;pid=13587
[1595834365] wproc: Registry request: name=Core Worker 13591;pid=13591
[1595834365] wproc: Registry request: name=Core Worker 13590;pid=13590
[1595834365] wproc: Registry request: name=Core Worker 13589;pid=13589
[1595834365] wproc: Registry request: name=Core Worker 13592;pid=13592
[1595834365] wproc: Registry request: name=Core Worker 13593;pid=13593
[1595834365] wproc: Registry request: name=Core Worker 13594;pid=13594
[1595834365] wproc: Registry request: name=Core Worker 13595;pid=13595
[1595834365] wproc: Registry request: name=Core Worker 13596;pid=13596
[1595834365] wproc: Registry request: name=Core Worker 13597;pid=13597
[1595834365] wproc: Registry request: name=Core Worker 13598;pid=13598
[1595834365] wproc: Registry request: name=Core Worker 13601;pid=13601
[1595834365] wproc: Registry request: name=Core Worker 13600;pid=13600
[1595834365] wproc: Registry request: name=Core Worker 13599;pid=13599
[1595834365] wproc: Registry request: name=Core Worker 13602;pid=13602
[1595834365] wproc: Registry request: name=Core Worker 13603;pid=13603
[1595834365] wproc: Registry request: name=Core Worker 13604;pid=13604
[1595834365] wproc: Registry request: name=Core Worker 13605;pid=13605
[1595834375] Successfully launched command file worker with pid 13612
[1595834538] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:12:50:45 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1595834922] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 352 processes
[1595835156] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.9% (934792 kB) free!
[1595835443] Caught SIGTERM, shutting down...
[1595835443] Caught SIGTERM, shutting down...
[1595835443] Caught SIGTERM, shutting down...
[1595835443] Successfully shutdown... (PID=13581)
[1595835443] Nagios 4.4.2 starting... (PID=16026)
[1595835443] Local time is Mon Jul 27 13:07:23 IST 2020
[1595835443] LOG VERSION: 2.0
[1595835443] qh: Socket '/usr/local/nagios/var/rw/nagios.qh' successfully initialized
[1595835443] qh: core query handler registered
[1595835443] qh: echo service query handler registered
[1595835443] qh: help for the query handler registered
[1595835443] wproc: Successfully registered manager as @wproc with query handler
[1595835443] wproc: Registry request: name=Core Worker 16028;pid=16028
[1595835443] wproc: Registry request: name=Core Worker 16027;pid=16027
[1595835443] wproc: Registry request: name=Core Worker 16031;pid=16031
[1595835443] wproc: Registry request: name=Core Worker 16029;pid=16029
[1595835443] wproc: Registry request: name=Core Worker 16030;pid=16030
[1595835443] wproc: Registry request: name=Core Worker 16033;pid=16033
[1595835443] wproc: Registry request: name=Core Worker 16032;pid=16032
[1595835443] wproc: Registry request: name=Core Worker 16034;pid=16034
[1595835443] wproc: Registry request: name=Core Worker 16035;pid=16035
[1595835443] wproc: Registry request: name=Core Worker 16036;pid=16036
[1595835443] wproc: Registry request: name=Core Worker 16038;pid=16038
[1595835443] wproc: Registry request: name=Core Worker 16040;pid=16040
[1595835443] wproc: Registry request: name=Core Worker 16039;pid=16039
[1595835443] wproc: Registry request: name=Core Worker 16041;pid=16041
[1595835443] wproc: Registry request: name=Core Worker 16043;pid=16043
[1595835443] wproc: Registry request: name=Core Worker 16042;pid=16042
[1595835443] wproc: Registry request: name=Core Worker 16045;pid=16045
[1595835443] wproc: Registry request: name=Core Worker 16044;pid=16044
[1595835443] wproc: Registry request: name=Core Worker 16037;pid=16037
[1595835443] wproc: Registry request: name=Core Worker 16048;pid=16048
[1595835443] wproc: Registry request: name=Core Worker 16050;pid=16050
[1595835443] wproc: Registry request: name=Core Worker 16047;pid=16047
[1595835443] wproc: Registry request: name=Core Worker 16049;pid=16049
[1595835443] wproc: Registry request: name=Core Worker 16046;pid=16046
[1595835453] Successfully launched command file worker with pid 16085
[1595835548] SERVICE ALERT: pservercluster2;Open-Files;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595835552] SERVICE ALERT: pservercluster2;Memory;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595835618] SERVICE ALERT: pservercluster2;Current Users;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595835621] SERVICE ALERT: pservercluster2;CPU-STATISTICS;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595835668] SERVICE ALERT: pservercluster2;Total Processes;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595835668] SERVICE ALERT: pservercluster2;Open-Files;CRITICAL;SOFT;2;NRPE: Call to popen() failed
[1595835672] SERVICE ALERT: pservercluster2;Memory;CRITICAL;SOFT;2;NRPE: Call to popen() failed
[1595835723] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1391) < 182.18.184.244 [27/Jul/2020:13:12:03 +0530] TCP 502 0 0 0.000 "backend_5003" "0" "0" "0.000"
[1595835738] SERVICE ALERT: pservercluster2;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595835746] SERVICE ALERT: pservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=2.95% system=5.87% iowait=0.00% idle=91.19%
[1595835761] SERVICE ALERT: pservercluster2;Messages Log Status;CRITICAL;SOFT;1;(21) < Jul 27 13:11:03 pservercluster2 xinetd[1487]: nrpe: fork failed: Cannot allocate memory (errno = 12)
[1595835788] SERVICE ALERT: pservercluster2;Total Processes;OK;HARD;1;PROCS OK: 330 processes
[1595835788] SERVICE ALERT: pservercluster2;Open-Files;OK;HARD;1;OK: 7488 open files (0% of max 2424156)
[1595835792] SERVICE ALERT: pservercluster2;Memory;OK;HARD;1;OK - 43.5% (10659688 kB) free.
[1595835881] SERVICE ALERT: pservercluster2;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1595836114] SERVICE ALERT: sservercluster1;Total Processes;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595836115] SERVICE ALERT: sservercluster1;zombie_procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595836122] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 771 processes
[1595836167] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595836234] SERVICE ALERT: sservercluster1;Total Processes;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1595836235] SERVICE ALERT: sservercluster1;zombie_procs;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1595836287] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 78.7% (19290704 kB) free.
[1595836321] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 96.45, 112.52, 104.93
[1595836354] SERVICE ALERT: sservercluster1;Total Processes;OK;HARD;1;PROCS OK: 332 processes
[1595836355] SERVICE ALERT: sservercluster1;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595836375] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3532) < 2020/07/27 13:22:53 [error] 1776#0: *3216078 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "10.147.212.49:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595836389] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(262) < 2020/07/27 13:22:43 [error] 1823#0: *1062562 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595836555] SERVICE ALERT: sservercluster1;Messages Log Status;CRITICAL;SOFT;1;(19) < Jul 27 13:20:17 sservercluster1 ksmtuned: /usr/sbin/ksmtuned: fork: Cannot allocate memory
[1595836675] SERVICE ALERT: sservercluster1;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1595836852] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;WARNING;notify-service-by-email;WARNING - 13.9% (4539968 kB) free!
[1595836905] SERVICE ALERT: smscapp1;Memory;WARNING;SOFT;1;WARNING - 19.2% (9481084 kB) free!
[1595836992] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1026 processes
[1595837025] SERVICE ALERT: smscapp1;Memory;WARNING;SOFT;2;WARNING - 18.7% (9207580 kB) free!
[1595837076] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1635 processes
[1595837145] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;WARNING;notify-service-by-email;WARNING - 18.1% (8936412 kB) free!
[1595837145] SERVICE ALERT: smscapp1;Memory;WARNING;HARD;3;WARNING - 18.1% (8936412 kB) free!
[1595837541] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.1% (2998836 kB) free!
[1595837550] Caught SIGTERM, shutting down...
[1595837550] Caught SIGTERM, shutting down...
[1595837550] Caught SIGTERM, shutting down...
[1595837551] Successfully shutdown... (PID=16026)
[1595837551] Nagios 4.4.2 starting... (PID=19959)
[1595837551] Local time is Mon Jul 27 13:42:31 IST 2020
[1595837551] LOG VERSION: 2.0
[1595837551] qh: Socket '/usr/local/nagios/var/rw/nagios.qh' successfully initialized
[1595837551] qh: core query handler registered
[1595837551] qh: echo service query handler registered
[1595837551] qh: help for the query handler registered
[1595837551] wproc: Successfully registered manager as @wproc with query handler
[1595837551] wproc: Registry request: name=Core Worker 19960;pid=19960
[1595837551] wproc: Registry request: name=Core Worker 19961;pid=19961
[1595837551] wproc: Registry request: name=Core Worker 19962;pid=19962
[1595837551] wproc: Registry request: name=Core Worker 19963;pid=19963
[1595837551] wproc: Registry request: name=Core Worker 19964;pid=19964
[1595837551] wproc: Registry request: name=Core Worker 19965;pid=19965
[1595837551] wproc: Registry request: name=Core Worker 19966;pid=19966
[1595837551] wproc: Registry request: name=Core Worker 19967;pid=19967
[1595837551] wproc: Registry request: name=Core Worker 19968;pid=19968
[1595837551] wproc: Registry request: name=Core Worker 19972;pid=19972
[1595837551] wproc: Registry request: name=Core Worker 19971;pid=19971
[1595837551] wproc: Registry request: name=Core Worker 19969;pid=19969
[1595837551] wproc: Registry request: name=Core Worker 19973;pid=19973
[1595837551] wproc: Registry request: name=Core Worker 19974;pid=19974
[1595837551] wproc: Registry request: name=Core Worker 19970;pid=19970
[1595837551] wproc: Registry request: name=Core Worker 19975;pid=19975
[1595837551] wproc: Registry request: name=Core Worker 19976;pid=19976
[1595837551] wproc: Registry request: name=Core Worker 19977;pid=19977
[1595837551] wproc: Registry request: name=Core Worker 19978;pid=19978
[1595837551] wproc: Registry request: name=Core Worker 19980;pid=19980
[1595837551] wproc: Registry request: name=Core Worker 19982;pid=19982
[1595837551] wproc: Registry request: name=Core Worker 19983;pid=19983
[1595837551] wproc: Registry request: name=Core Worker 19979;pid=19979
[1595837551] wproc: Registry request: name=Core Worker 19981;pid=19981
[1595837561] Successfully launched command file worker with pid 19986
[1595837598] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;SOFT;1;CRITICAL - load average: 15584.58, 7772.96, 3072.42
[1595837718] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;SOFT;2;CRITICAL - load average: 16124.30, 10563.94, 4665.11
[1595837838] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 16196.05, 12431.18, 6064.59
[1595837838] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 16196.05, 12431.18, 6064.59
[1595838052] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;CRITICAL;notify-service-by-email;CRITICAL - 9.6% (3143764 kB) free!
[1595838052] SERVICE ALERT: mrq4;Memory;CRITICAL;HARD;3;CRITICAL - 9.6% (3143764 kB) free!
[1595838119] Caught SIGTERM, shutting down...
[1595838119] Caught SIGTERM, shutting down...
[1595838119] Caught SIGTERM, shutting down...
[1595838119] Successfully shutdown... (PID=19959)
[1595838119] Nagios 4.4.2 starting... (PID=21042)
[1595838119] Local time is Mon Jul 27 13:51:59 IST 2020
[1595838119] LOG VERSION: 2.0
[1595838119] qh: Socket '/usr/local/nagios/var/rw/nagios.qh' successfully initialized
[1595838119] qh: core query handler registered
[1595838119] qh: echo service query handler registered
[1595838119] qh: help for the query handler registered
[1595838119] wproc: Successfully registered manager as @wproc with query handler
[1595838119] wproc: Registry request: name=Core Worker 21043;pid=21043
[1595838119] wproc: Registry request: name=Core Worker 21045;pid=21045
[1595838119] wproc: Registry request: name=Core Worker 21044;pid=21044
[1595838119] wproc: Registry request: name=Core Worker 21046;pid=21046
[1595838119] wproc: Registry request: name=Core Worker 21047;pid=21047
[1595838119] wproc: Registry request: name=Core Worker 21048;pid=21048
[1595838119] wproc: Registry request: name=Core Worker 21050;pid=21050
[1595838119] wproc: Registry request: name=Core Worker 21052;pid=21052
[1595838119] wproc: Registry request: name=Core Worker 21051;pid=21051
[1595838119] wproc: Registry request: name=Core Worker 21055;pid=21055
[1595838119] wproc: Registry request: name=Core Worker 21049;pid=21049
[1595838119] wproc: Registry request: name=Core Worker 21054;pid=21054
[1595838119] wproc: Registry request: name=Core Worker 21053;pid=21053
[1595838119] wproc: Registry request: name=Core Worker 21056;pid=21056
[1595838119] wproc: Registry request: name=Core Worker 21057;pid=21057
[1595838119] wproc: Registry request: name=Core Worker 21058;pid=21058
[1595838119] wproc: Registry request: name=Core Worker 21059;pid=21059
[1595838119] wproc: Registry request: name=Core Worker 21061;pid=21061
[1595838119] wproc: Registry request: name=Core Worker 21060;pid=21060
[1595838119] wproc: Registry request: name=Core Worker 21062;pid=21062
[1595838119] wproc: Registry request: name=Core Worker 21063;pid=21063
[1595838119] wproc: Registry request: name=Core Worker 21064;pid=21064
[1595838119] wproc: Registry request: name=Core Worker 21065;pid=21065
[1595838119] wproc: Registry request: name=Core Worker 21066;pid=21066
[1595838129] Successfully launched command file worker with pid 21069
[1595838138] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:13:50:45 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1595838419] Caught SIGTERM, shutting down...
[1595838419] Caught SIGTERM, shutting down...
[1595838419] Caught SIGTERM, shutting down...
[1595838419] Successfully shutdown... (PID=21042)
[1595838419] Nagios 4.4.2 starting... (PID=21703)
[1595838419] Local time is Mon Jul 27 13:56:59 IST 2020
[1595838419] LOG VERSION: 2.0
[1595838419] qh: Socket '/usr/local/nagios/var/rw/nagios.qh' successfully initialized
[1595838419] qh: core query handler registered
[1595838419] qh: echo service query handler registered
[1595838419] qh: help for the query handler registered
[1595838419] wproc: Successfully registered manager as @wproc with query handler
[1595838419] wproc: Registry request: name=Core Worker 21706;pid=21706
[1595838419] wproc: Registry request: name=Core Worker 21707;pid=21707
[1595838419] wproc: Registry request: name=Core Worker 21704;pid=21704
[1595838419] wproc: Registry request: name=Core Worker 21709;pid=21709
[1595838419] wproc: Registry request: name=Core Worker 21705;pid=21705
[1595838419] wproc: Registry request: name=Core Worker 21708;pid=21708
[1595838419] wproc: Registry request: name=Core Worker 21713;pid=21713
[1595838419] wproc: Registry request: name=Core Worker 21716;pid=21716
[1595838419] wproc: Registry request: name=Core Worker 21715;pid=21715
[1595838419] wproc: Registry request: name=Core Worker 21711;pid=21711
[1595838419] wproc: Registry request: name=Core Worker 21717;pid=21717
[1595838419] wproc: Registry request: name=Core Worker 21710;pid=21710
[1595838419] wproc: Registry request: name=Core Worker 21719;pid=21719
[1595838419] wproc: Registry request: name=Core Worker 21714;pid=21714
[1595838419] wproc: Registry request: name=Core Worker 21722;pid=21722
[1595838419] wproc: Registry request: name=Core Worker 21712;pid=21712
[1595838419] wproc: Registry request: name=Core Worker 21720;pid=21720
[1595838419] wproc: Registry request: name=Core Worker 21718;pid=21718
[1595838419] wproc: Registry request: name=Core Worker 21721;pid=21721
[1595838419] wproc: Registry request: name=Core Worker 21726;pid=21726
[1595838419] wproc: Registry request: name=Core Worker 21725;pid=21725
[1595838419] wproc: Registry request: name=Core Worker 21723;pid=21723
[1595838419] wproc: Registry request: name=Core Worker 21727;pid=21727
[1595838419] wproc: Registry request: name=Core Worker 21724;pid=21724
[1595838430] Successfully launched command file worker with pid 21730
[1595838523] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 355 processes
[1595838652] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;WARNING;notify-service-by-email;WARNING - 12.4% (4066700 kB) free!
[1595838652] SERVICE ALERT: mrq4;Memory;WARNING;HARD;3;WARNING - 12.4% (4066700 kB) free!
[1595838730] Caught SIGTERM, shutting down...
[1595838730] Caught SIGTERM, shutting down...
[1595838730] Caught SIGTERM, shutting down...
[1595838730] Successfully shutdown... (PID=21703)
[1595838730] Nagios 4.4.2 starting... (PID=22371)
[1595838730] Local time is Mon Jul 27 14:02:10 IST 2020
[1595838730] LOG VERSION: 2.0
[1595838730] qh: Socket '/usr/local/nagios/var/rw/nagios.qh' successfully initialized
[1595838730] qh: core query handler registered
[1595838730] qh: echo service query handler registered
[1595838730] qh: help for the query handler registered
[1595838730] wproc: Successfully registered manager as @wproc with query handler
[1595838730] wproc: Registry request: name=Core Worker 22372;pid=22372
[1595838730] wproc: Registry request: name=Core Worker 22373;pid=22373
[1595838730] wproc: Registry request: name=Core Worker 22374;pid=22374
[1595838730] wproc: Registry request: name=Core Worker 22376;pid=22376
[1595838730] wproc: Registry request: name=Core Worker 22377;pid=22377
[1595838730] wproc: Registry request: name=Core Worker 22378;pid=22378
[1595838730] wproc: Registry request: name=Core Worker 22380;pid=22380
[1595838730] wproc: Registry request: name=Core Worker 22375;pid=22375
[1595838730] wproc: Registry request: name=Core Worker 22381;pid=22381
[1595838730] wproc: Registry request: name=Core Worker 22379;pid=22379
[1595838730] wproc: Registry request: name=Core Worker 22382;pid=22382
[1595838730] wproc: Registry request: name=Core Worker 22383;pid=22383
[1595838730] wproc: Registry request: name=Core Worker 22384;pid=22384
[1595838730] wproc: Registry request: name=Core Worker 22385;pid=22385
[1595838730] wproc: Registry request: name=Core Worker 22386;pid=22386
[1595838730] wproc: Registry request: name=Core Worker 22387;pid=22387
[1595838730] wproc: Registry request: name=Core Worker 22388;pid=22388
[1595838730] wproc: Registry request: name=Core Worker 22389;pid=22389
[1595838730] wproc: Registry request: name=Core Worker 22391;pid=22391
[1595838730] wproc: Registry request: name=Core Worker 22390;pid=22390
[1595838730] wproc: Registry request: name=Core Worker 22392;pid=22392
[1595838730] wproc: Registry request: name=Core Worker 22395;pid=22395
[1595838730] wproc: Registry request: name=Core Worker 22394;pid=22394
[1595838730] wproc: Registry request: name=Core Worker 22393;pid=22393
[1595838740] Successfully launched command file worker with pid 22400
[1595838744] Caught SIGTERM, shutting down...
[1595838744] Caught SIGTERM, shutting down...
[1595838744] Caught SIGTERM, shutting down...
[1595838744] Successfully shutdown... (PID=22371)
[1595838744] Nagios 4.4.2 starting... (PID=22436)
[1595838744] Local time is Mon Jul 27 14:02:24 IST 2020
[1595838744] LOG VERSION: 2.0
[1595838744] qh: Socket '/usr/local/nagios/var/rw/nagios.qh' successfully initialized
[1595838744] qh: core query handler registered
[1595838744] qh: echo service query handler registered
[1595838744] qh: help for the query handler registered
[1595838744] wproc: Successfully registered manager as @wproc with query handler
[1595838744] wproc: Registry request: name=Core Worker 22437;pid=22437
[1595838744] wproc: Registry request: name=Core Worker 22438;pid=22438
[1595838744] wproc: Registry request: name=Core Worker 22440;pid=22440
[1595838744] wproc: Registry request: name=Core Worker 22439;pid=22439
[1595838744] wproc: Registry request: name=Core Worker 22441;pid=22441
[1595838744] wproc: Registry request: name=Core Worker 22442;pid=22442
[1595838744] wproc: Registry request: name=Core Worker 22443;pid=22443
[1595838744] wproc: Registry request: name=Core Worker 22445;pid=22445
[1595838744] wproc: Registry request: name=Core Worker 22444;pid=22444
[1595838744] wproc: Registry request: name=Core Worker 22448;pid=22448
[1595838744] wproc: Registry request: name=Core Worker 22449;pid=22449
[1595838744] wproc: Registry request: name=Core Worker 22450;pid=22450
[1595838744] wproc: Registry request: name=Core Worker 22447;pid=22447
[1595838744] wproc: Registry request: name=Core Worker 22452;pid=22452
[1595838744] wproc: Registry request: name=Core Worker 22451;pid=22451
[1595838744] wproc: Registry request: name=Core Worker 22453;pid=22453
[1595838744] wproc: Registry request: name=Core Worker 22446;pid=22446
[1595838744] wproc: Registry request: name=Core Worker 22454;pid=22454
[1595838744] wproc: Registry request: name=Core Worker 22456;pid=22456
[1595838744] wproc: Registry request: name=Core Worker 22459;pid=22459
[1595838744] wproc: Registry request: name=Core Worker 22455;pid=22455
[1595838744] wproc: Registry request: name=Core Worker 22457;pid=22457
[1595838744] wproc: Registry request: name=Core Worker 22458;pid=22458
[1595838744] wproc: Registry request: name=Core Worker 22460;pid=22460
[1595838754] Successfully launched command file worker with pid 22472
[1595838761] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 2.0% (963296 kB) free!
[1595838798] SERVICE ALERT: pservercluster2;Open-Files;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595838919] SERVICE ALERT: pservercluster2;Open-Files;OK;HARD;1;OK: 7872 open files (0% of max 2424156)
[1595839006] Caught SIGTERM, shutting down...
[1595839006] Caught SIGTERM, shutting down...
[1595839006] Caught SIGTERM, shutting down...
[1595839006] Successfully shutdown... (PID=22436)
[1595839006] Nagios 4.4.2 starting... (PID=23005)
[1595839006] Local time is Mon Jul 27 14:06:46 IST 2020
[1595839006] LOG VERSION: 2.0
[1595839006] qh: Socket '/usr/local/nagios/var/rw/nagios.qh' successfully initialized
[1595839006] qh: core query handler registered
[1595839006] qh: echo service query handler registered
[1595839006] qh: help for the query handler registered
[1595839006] wproc: Successfully registered manager as @wproc with query handler
[1595839006] wproc: Registry request: name=Core Worker 23006;pid=23006
[1595839006] wproc: Registry request: name=Core Worker 23008;pid=23008
[1595839006] wproc: Registry request: name=Core Worker 23009;pid=23009
[1595839006] wproc: Registry request: name=Core Worker 23007;pid=23007
[1595839006] wproc: Registry request: name=Core Worker 23012;pid=23012
[1595839006] wproc: Registry request: name=Core Worker 23011;pid=23011
[1595839006] wproc: Registry request: name=Core Worker 23010;pid=23010
[1595839006] wproc: Registry request: name=Core Worker 23013;pid=23013
[1595839006] wproc: Registry request: name=Core Worker 23016;pid=23016
[1595839006] wproc: Registry request: name=Core Worker 23014;pid=23014
[1595839006] wproc: Registry request: name=Core Worker 23015;pid=23015
[1595839006] wproc: Registry request: name=Core Worker 23019;pid=23019
[1595839006] wproc: Registry request: name=Core Worker 23020;pid=23020
[1595839006] wproc: Registry request: name=Core Worker 23021;pid=23021
[1595839006] wproc: Registry request: name=Core Worker 23018;pid=23018
[1595839006] wproc: Registry request: name=Core Worker 23017;pid=23017
[1595839006] wproc: Registry request: name=Core Worker 23022;pid=23022
[1595839006] wproc: Registry request: name=Core Worker 23023;pid=23023
[1595839006] wproc: Registry request: name=Core Worker 23025;pid=23025
[1595839006] wproc: Registry request: name=Core Worker 23024;pid=23024
[1595839006] wproc: Registry request: name=Core Worker 23026;pid=23026
[1595839006] wproc: Registry request: name=Core Worker 23027;pid=23027
[1595839006] wproc: Registry request: name=Core Worker 23028;pid=23028
[1595839006] wproc: Registry request: name=Core Worker 23029;pid=23029
[1595839016] Successfully launched command file worker with pid 23033
[1595839329] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1301) < 182.18.184.244 [27/Jul/2020:14:12:09 +0530] TCP 502 0 0 0.000 "backend_5001" "0" "0" "0.000"
[1595839458] Caught SIGTERM, shutting down...
[1595839458] Caught SIGTERM, shutting down...
[1595839458] Caught SIGTERM, shutting down...
[1595839458] Successfully shutdown... (PID=23005)
[1595839458] Nagios 4.4.2 starting... (PID=24030)
[1595839458] Local time is Mon Jul 27 14:14:18 IST 2020
[1595839458] LOG VERSION: 2.0
[1595839458] qh: Socket '/usr/local/nagios/var/rw/nagios.qh' successfully initialized
[1595839458] qh: core query handler registered
[1595839458] qh: echo service query handler registered
[1595839458] qh: help for the query handler registered
[1595839458] wproc: Successfully registered manager as @wproc with query handler
[1595839458] wproc: Registry request: name=Core Worker 24031;pid=24031
[1595839458] wproc: Registry request: name=Core Worker 24032;pid=24032
[1595839458] wproc: Registry request: name=Core Worker 24033;pid=24033
[1595839458] wproc: Registry request: name=Core Worker 24035;pid=24035
[1595839458] wproc: Registry request: name=Core Worker 24036;pid=24036
[1595839458] wproc: Registry request: name=Core Worker 24037;pid=24037
[1595839458] wproc: Registry request: name=Core Worker 24038;pid=24038
[1595839458] wproc: Registry request: name=Core Worker 24039;pid=24039
[1595839458] wproc: Registry request: name=Core Worker 24034;pid=24034
[1595839458] wproc: Registry request: name=Core Worker 24041;pid=24041
[1595839458] wproc: Registry request: name=Core Worker 24043;pid=24043
[1595839458] wproc: Registry request: name=Core Worker 24042;pid=24042
[1595839458] wproc: Registry request: name=Core Worker 24044;pid=24044
[1595839458] wproc: Registry request: name=Core Worker 24045;pid=24045
[1595839458] wproc: Registry request: name=Core Worker 24040;pid=24040
[1595839458] wproc: Registry request: name=Core Worker 24046;pid=24046
[1595839458] wproc: Registry request: name=Core Worker 24047;pid=24047
[1595839458] wproc: Registry request: name=Core Worker 24048;pid=24048
[1595839458] wproc: Registry request: name=Core Worker 24049;pid=24049
[1595839458] wproc: Registry request: name=Core Worker 24050;pid=24050
[1595839458] wproc: Registry request: name=Core Worker 24051;pid=24051
[1595839458] wproc: Registry request: name=Core Worker 24053;pid=24053
[1595839458] wproc: Registry request: name=Core Worker 24052;pid=24052
[1595839458] wproc: Registry request: name=Core Worker 24054;pid=24054
[1595839468] Successfully launched command file worker with pid 24057
[1595839545] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 7.7% (3801876 kB) free!
[1595839545] SERVICE ALERT: smscapp1;Memory;CRITICAL;HARD;3;CRITICAL - 7.7% (3801876 kB) free!
[1595839722] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 772 processes
[1595839852] SERVICE FLAPPING ALERT: mrq4;Memory;STARTED; Service appears to have started flapping (22.9% change >= 20.0% threshold)
[1595839852] SERVICE ALERT: mrq4;Memory;CRITICAL;HARD;3;CRITICAL - 8.6% (2807684 kB) free!
[1595839929] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 86.93, 96.85, 100.81
[1595839975] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3932) < 2020/07/27 14:22:54 [error] 1785#0: *3262822 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5001, upstream: "backend_5001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595839989] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(238) < 2020/07/27 14:23:09 [error] 1809#0: *1084689 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595840425] Caught SIGTERM, shutting down...
[1595840425] Caught SIGTERM, shutting down...
[1595840425] Caught SIGTERM, shutting down...
[1595840425] Successfully shutdown... (PID=24030)
[1595840425] Nagios 4.4.2 starting... (PID=26045)
[1595840425] Local time is Mon Jul 27 14:30:25 IST 2020
[1595840425] LOG VERSION: 2.0
[1595840425] qh: Socket '/usr/local/nagios/var/rw/nagios.qh' successfully initialized
[1595840425] qh: core query handler registered
[1595840425] qh: echo service query handler registered
[1595840425] qh: help for the query handler registered
[1595840425] wproc: Successfully registered manager as @wproc with query handler
[1595840425] wproc: Registry request: name=Core Worker 26046;pid=26046
[1595840425] wproc: Registry request: name=Core Worker 26047;pid=26047
[1595840425] wproc: Registry request: name=Core Worker 26050;pid=26050
[1595840425] wproc: Registry request: name=Core Worker 26051;pid=26051
[1595840425] wproc: Registry request: name=Core Worker 26053;pid=26053
[1595840425] wproc: Registry request: name=Core Worker 26049;pid=26049
[1595840425] wproc: Registry request: name=Core Worker 26052;pid=26052
[1595840425] wproc: Registry request: name=Core Worker 26055;pid=26055
[1595840425] wproc: Registry request: name=Core Worker 26054;pid=26054
[1595840425] wproc: Registry request: name=Core Worker 26056;pid=26056
[1595840425] wproc: Registry request: name=Core Worker 26048;pid=26048
[1595840425] wproc: Registry request: name=Core Worker 26059;pid=26059
[1595840425] wproc: Registry request: name=Core Worker 26057;pid=26057
[1595840425] wproc: Registry request: name=Core Worker 26060;pid=26060
[1595840425] wproc: Registry request: name=Core Worker 26061;pid=26061
[1595840425] wproc: Registry request: name=Core Worker 26062;pid=26062
[1595840425] wproc: Registry request: name=Core Worker 26066;pid=26066
[1595840425] wproc: Registry request: name=Core Worker 26064;pid=26064
[1595840425] wproc: Registry request: name=Core Worker 26058;pid=26058
[1595840425] wproc: Registry request: name=Core Worker 26065;pid=26065
[1595840425] wproc: Registry request: name=Core Worker 26067;pid=26067
[1595840425] wproc: Registry request: name=Core Worker 26069;pid=26069
[1595840425] wproc: Registry request: name=Core Worker 26063;pid=26063
[1595840425] wproc: Registry request: name=Core Worker 26068;pid=26068
[1595840425] SERVICE FLAPPING ALERT: mrq4;Memory;STARTED; Service appears to have started flapping (22.9% change >= 20.0% threshold)
[1595840435] Successfully launched command file worker with pid 26081
[1595840676] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1637 processes
[1595840838] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU Load;WARNING;notify-service-by-email;WARNING - load average: 1.92, 4.93, 676.69
[1595840838] SERVICE ALERT: pservercluster2;CPU Load;WARNING;HARD;3;WARNING - load average: 1.92, 4.93, 676.69
[1595841141] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.1% (3001336 kB) free!
[1595841191] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1023 processes
[1595841313] SERVICE ALERT: sig6-vm2;Memory;WARNING;SOFT;1;WARNING - 18.7% (4199448 kB) free!
[1595841433] SERVICE ALERT: sig6-vm2;Memory;WARNING;SOFT;2;WARNING - 17.1% (3829520 kB) free!
[1595841438] SERVICE FLAPPING ALERT: pservercluster2;CPU Load;STARTED; Service appears to have started flapping (21.6% change >= 20.0% threshold)
[1595841438] SERVICE ALERT: pservercluster2;CPU Load;OK;HARD;1;OK - load average: 2.69, 2.64, 357.49
[1595841553] SERVICE NOTIFICATION: nagiosadmin;sig6-vm2;Memory;WARNING;notify-service-by-email;WARNING - 15.4% (3453864 kB) free!
[1595841553] SERVICE ALERT: sig6-vm2;Memory;WARNING;HARD;3;WARNING - 15.4% (3453864 kB) free!
[1595841741] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:14:50:36 +0530] TCP 502 0 0 0.000 "10.147.212.61:14001" "0" "0" "0.000"
[1595842153] SERVICE NOTIFICATION: nagiosadmin;sig6-vm2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 8.2% (1842872 kB) free!
[1595842153] SERVICE ALERT: sig6-vm2;Memory;CRITICAL;HARD;3;CRITICAL - 8.2% (1842872 kB) free!
[1595842361] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.9% (930536 kB) free!
[1595842722] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 361 processes
[1595842753] SERVICE NOTIFICATION: nagiosadmin;sig6-vm2;Memory;OK;notify-service-by-email;OK - 95.2% (21366344 kB) free.
[1595842753] SERVICE ALERT: sig6-vm2;Memory;OK;HARD;1;OK - 95.2% (21366344 kB) free.
[1595842930] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1355) < 182.18.184.244 [27/Jul/2020:15:12:09 +0530] TCP 502 0 0 0.002 "10.147.212.61:5501, 10.147.212.37:5501, 10.147.212.49:5501, 10.147.212.38:5501" "0, 0, 0, 0" "0, 0, 0, 0" "0.000, 0.001, 0.000, 0.001"
[1595843145] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (326656 kB) free!
[1595843322] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 770 processes
[1595843529] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 79.50, 89.01, 93.30
[1595843575] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3650) < 2020/07/27 15:22:54 [error] 1785#0: *3316174 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "backend_5003", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595843589] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(234) < 2020/07/27 15:23:08 [error] 1814#0: *1106785 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595844025] Auto-save of retention data completed successfully.
[1595844276] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1637 processes
[1595844742] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.1% (3004800 kB) free!
[1595844792] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1023 processes
[1595845341] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:15:50:35 +0530] TCP 502 0 0 0.001 "10.147.212.61:14001" "0" "0" "0.001"
[1595845512] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;SOFT;1;CRITICAL - load average: 15780.77, 8770.80, 3602.25
[1595845632] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;SOFT;2;CRITICAL - load average: 16054.65, 11194.96, 5117.27
[1595845752] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 16091.95, 12817.25, 6448.68
[1595845752] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 16091.95, 12817.25, 6448.68
[1595845892] SERVICE ALERT: sservercluster1;Memory;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1595845962] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.4% (691684 kB) free!
[1595845971] SERVICE ALERT: sservercluster1;Total Processes;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595845971] SERVICE ALERT: sservercluster1;zombie_procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595845971] SERVICE ALERT: sservercluster1;HDD_Home status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595845985] SERVICE ALERT: sservercluster1;CPU_Procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595845992] SERVICE ALERT: sservercluster1;LocalService-NTPD SERVICE;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595846012] SERVICE ALERT: sservercluster1;HDD_Root status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595846022] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595846045] SERVICE ALERT: sservercluster1;CPU-STATISTICS;CRITICAL;SOFT;1;NRPE: Call to popen() failed
[1595846091] SERVICE ALERT: sservercluster1;Total Processes;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1595846091] SERVICE ALERT: sservercluster1;zombie_procs;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1595846091] SERVICE ALERT: sservercluster1;HDD_Home status;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1595846105] SERVICE ALERT: sservercluster1;CPU_Procs;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1595846112] SERVICE ALERT: sservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595846132] SERVICE ALERT: sservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 38684 MB (75% inode=99%):
[1595846142] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 62.0% (15195112 kB) free.
[1595846170] SERVICE ALERT: sservercluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.56% system=12.90% iowait=0.04% idle=85.49%
[1595846211] SERVICE ALERT: sservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 166901 MB (75% inode=99%):
[1595846211] SERVICE ALERT: sservercluster1;Total Processes;OK;HARD;1;PROCS OK: 393 processes
[1595846211] SERVICE ALERT: sservercluster1;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595846225] SERVICE ALERT: sservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 392 processes
[1595846276] SERVICE ALERT: sservercluster1;Messages Log Status;CRITICAL;SOFT;1;(40) < Jul 27 16:04:27 sservercluster1 ksmtuned: /usr/sbin/ksmtuned: fork: Cannot allocate memory
[1595846322] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 359 processes
[1595846396] SERVICE ALERT: sservercluster1;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1595846530] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1192) < 182.18.184.244 [27/Jul/2020:16:12:09 +0530] TCP 502 0 0 0.002 "10.147.212.61:5500, 10.147.212.49:5500, 10.147.212.37:5500, 10.147.212.38:5500" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.000, 0.001"
[1595846745] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.6% (279464 kB) free!
[1595846922] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 772 processes
[1595847129] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 110.98, 96.13, 89.66
[1595847189] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(229) < 2020/07/27 16:22:58 [error] 1818#0: *1124801 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595847625] Auto-save of retention data completed successfully.
[1595847775] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3313) < 2020/07/27 16:32:54 [error] 1785#0: *3369675 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "backend_5003", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595847876] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1642 processes
[1595848929] SERVICE ALERT: qservercluster2;Memory;WARNING;SOFT;1;WARNING - 19.6% (9634796 kB) free!
[1595848941] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.0% (2980328 kB) free!
[1595848991] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1024 processes
[1595849049] SERVICE ALERT: qservercluster2;Memory;WARNING;SOFT;2;WARNING - 19.3% (9524568 kB) free!
[1595849169] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 19.1% (9404412 kB) free!
[1595849169] SERVICE ALERT: qservercluster2;Memory;WARNING;HARD;3;WARNING - 19.1% (9404412 kB) free!
[1595849352] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU Load;OK;notify-service-by-email;OK - load average: 2.09, 2.68, 343.08
[1595849352] SERVICE ALERT: sservercluster1;CPU Load;OK;HARD;1;OK - load average: 2.09, 2.68, 343.08
[1595849541] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:17:00:34 +0530] TCP 502 0 0 0.001 "10.147.212.61:14001" "0" "0" "0.001"
[1595849835] SERVICE ALERT: pservercluster1;Messages Log Status;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1595849842] SERVICE ALERT: pservercluster1;HDD_Root status;CRITICAL;SOFT;1;NRPE: Call to popen() failed
[1595849864] SERVICE ALERT: pservercluster1;Current Users;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1595849888] SERVICE ALERT: pservercluster1;CPU-STATISTICS;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595849901] SERVICE ALERT: pservercluster1;CPU Load;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595849918] SERVICE ALERT: pservercluster1;Open-Files;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595849922] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 355 processes
[1595849931] SERVICE ALERT: pservercluster1;Sensors Status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595849935] SERVICE ALERT: pservercluster1;CPU_Procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595849965] SERVICE ALERT: pservercluster1;Messages Log Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595849972] SERVICE ALERT: pservercluster1;HDD_Root status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595849987] SERVICE ALERT: pservercluster1;Total Processes;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595849994] SERVICE ALERT: pservercluster1;Current Users;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850018] SERVICE ALERT: pservercluster1;CPU-STATISTICS;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850021] SERVICE ALERT: pservercluster1;CPU Load;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1595850048] SERVICE ALERT: pservercluster1;Open-Files;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850061] SERVICE ALERT: pservercluster1;Sensors Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850065] SERVICE ALERT: pservercluster1;CPU_Procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850090] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Messages Log Status;UNKNOWN;notify-service-by-email;NRPE: Call to fork() failed
[1595850090] SERVICE ALERT: pservercluster1;Messages Log Status;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595850092] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;HDD_Root status;CRITICAL;notify-service-by-email;NRPE: Call to popen() failed
[1595850092] SERVICE ALERT: pservercluster1;HDD_Root status;CRITICAL;HARD;3;NRPE: Call to popen() failed
[1595850107] SERVICE ALERT: pservercluster1;Total Processes;OK;HARD;1;PROCS OK: 334 processes
[1595850114] SERVICE ALERT: pservercluster1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595850138] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU-STATISTICS;CRITICAL;notify-service-by-email;NRPE: Call to popen() failed
[1595850138] SERVICE ALERT: pservercluster1;CPU-STATISTICS;CRITICAL;HARD;3;NRPE: Call to popen() failed
[1595850139] SERVICE ALERT: pservercluster1;LocalService-NTPD SERVICE;UNKNOWN;SOFT;1;Could not open pipe: /usr/bin/ps
[1595850141] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU Load;CRITICAL;notify-service-by-email;NRPE: Call to popen() failed
[1595850141] SERVICE ALERT: pservercluster1;CPU Load;CRITICAL;HARD;3;NRPE: Call to popen() failed
[1595850161] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (219752 kB) free!
[1595850168] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Open-Files;UNKNOWN;notify-service-by-email;NRPE: Call to fork() failed
[1595850168] SERVICE ALERT: pservercluster1;Open-Files;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595850172] SERVICE ALERT: pservercluster1;HDD_Home status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850181] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Sensors Status;UNKNOWN;notify-service-by-email;NRPE: Call to fork() failed
[1595850181] SERVICE ALERT: pservercluster1;Sensors Status;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595850195] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU_Procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850195] SERVICE ALERT: pservercluster1;CPU_Procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850269] SERVICE ALERT: pservercluster1;LocalService-NTPD SERVICE;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850287] SERVICE ALERT: pservercluster1;zombie_procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850296] SERVICE ALERT: pservercluster1;Memory;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1595850299] SERVICE ALERT: pservercluster1;HDD_Home status;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1595850345] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.6% (284432 kB) free!
[1595850394] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;LocalService-NTPD SERVICE;UNKNOWN;notify-service-by-email;NRPE: Call to fork() failed
[1595850394] SERVICE ALERT: pservercluster1;LocalService-NTPD SERVICE;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595850417] SERVICE ALERT: pservercluster1;zombie_procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850426] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850429] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;HDD_Home status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850429] SERVICE ALERT: pservercluster1;HDD_Home status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850430] SERVICE ALERT: sservercluster2;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 324 processes
[1595850522] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 772 processes
[1595850547] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;zombie_procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850547] SERVICE ALERT: pservercluster1;zombie_procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850550] SERVICE ALERT: sservercluster2;CPU_Procs;WARNING;SOFT;2;CPU WARNING: 1 warn out of 324 processes
[1595850556] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850556] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850652] SERVICE FLAPPING ALERT: mrq4;Memory;STOPPED; Service appears to have stopped flapping (3.9% change < 5.0% threshold)
[1595850652] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.9% (290432 kB) free!
[1595850670] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 322 processes
[1595850670] SERVICE ALERT: sservercluster2;CPU_Procs;WARNING;HARD;3;CPU WARNING: 1 warn out of 322 processes
[1595850692] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;HDD_Root status;UNKNOWN;notify-service-by-email;NRPE: Call to fork() failed
[1595850692] SERVICE ALERT: pservercluster1;HDD_Root status;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595850724] SERVICE ALERT: pservercluster1;Current Users;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850729] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1180) < 182.18.184.244 [27/Jul/2020:17:22:07 +0530] TCP 502 0 0 0.000 "backend_5003" "0" "0" "0.000"
[1595850729] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 96.54, 96.38, 92.18
[1595850778] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Open-Files;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850778] SERVICE ALERT: pservercluster1;Open-Files;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850789] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(44) < 2020/07/27 17:22:39 [error] 1819#0: *1141583 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595850791] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Sensors Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850791] SERVICE ALERT: pservercluster1;Sensors Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850854] SERVICE ALERT: pservercluster1;Current Users;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850984] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Current Users;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595850984] SERVICE ALERT: pservercluster1;Current Users;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851004] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;LocalService-NTPD SERVICE;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851004] SERVICE ALERT: pservercluster1;LocalService-NTPD SERVICE;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851225] Auto-save of retention data completed successfully.
[1595851292] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;HDD_Root status;CRITICAL;notify-service-by-email;NRPE: Call to popen() failed
[1595851292] SERVICE ALERT: pservercluster1;HDD_Root status;CRITICAL;HARD;3;NRPE: Call to popen() failed
[1595851300] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Messages Log Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851300] SERVICE ALERT: pservercluster1;Messages Log Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851327] SERVICE ALERT: pservercluster2;zombie_procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851339] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851350] SERVICE ALERT: pservercluster2;Current Users;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851371] SERVICE ALERT: pservercluster2;HDD_Home status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851398] SERVICE ALERT: pservercluster2;Total Processes;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851402] SERVICE ALERT: pservercluster2;Memory;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851404] SERVICE ALERT: pservercluster2;CPU-STATISTICS;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851408] SERVICE ALERT: pservercluster2;HDD_Root status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851457] SERVICE ALERT: pservercluster2;zombie_procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851469] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851476] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1636 processes
[1595851480] SERVICE ALERT: pservercluster2;Current Users;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851491] SERVICE ALERT: pservercluster2;Messages Log Status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851501] SERVICE ALERT: pservercluster2;HDD_Home status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851518] SERVICE ALERT: pservercluster2;Total Processes;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1595851518] SERVICE ALERT: pservercluster2;Open-Files;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1595851522] SERVICE ALERT: pservercluster2;Memory;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1595851534] SERVICE ALERT: pservercluster2;CPU-STATISTICS;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851538] SERVICE ALERT: pservercluster2;HDD_Root status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851587] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;zombie_procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851587] SERVICE ALERT: pservercluster2;zombie_procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851599] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;LocalService-NTPD SERVICE;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851599] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851610] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Current Users;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851610] SERVICE ALERT: pservercluster2;Current Users;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851621] SERVICE ALERT: pservercluster2;Messages Log Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851626] SERVICE ALERT: pservercluster2;CPU_Procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851631] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;HDD_Home status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851631] SERVICE ALERT: pservercluster2;HDD_Home status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851643] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;SOFT;1;CHECK_NRPE: Error - Could not complete SSL handshake.
[1595851648] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Total Processes;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851648] SERVICE ALERT: pservercluster2;Total Processes;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851648] SERVICE ALERT: pservercluster2;Open-Files;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851652] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851652] SERVICE ALERT: pservercluster2;Memory;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851654] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU-STATISTICS;CRITICAL;notify-service-by-email;CHECK_NRPE: Error - Could not complete SSL handshake.
[1595851654] SERVICE ALERT: pservercluster2;CPU-STATISTICS;CRITICAL;HARD;3;CHECK_NRPE: Error - Could not complete SSL handshake.
[1595851663] SERVICE ALERT: pservercluster2;Sensors Status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851668] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;HDD_Root status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851668] SERVICE ALERT: pservercluster2;HDD_Root status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851751] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Messages Log Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851751] SERVICE ALERT: pservercluster2;Messages Log Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851756] SERVICE ALERT: pservercluster2;CPU_Procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851773] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851778] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Open-Files;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851778] SERVICE ALERT: pservercluster2;Open-Files;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851793] SERVICE ALERT: pservercluster2;Sensors Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851886] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851886] SERVICE ALERT: pservercluster2;CPU_Procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851900] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Messages Log Status;UNKNOWN;notify-service-by-email;NRPE: Call to fork() failed
[1595851900] SERVICE ALERT: pservercluster1;Messages Log Status;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595851903] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851917] SERVICE ALERT: pservercluster1;Total Processes;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851923] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Sensors Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851923] SERVICE ALERT: pservercluster2;Sensors Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595851975] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2890) < 2020/07/27 17:42:54 [error] 1785#0: *3412097 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "backend_5003", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595852047] SERVICE ALERT: pservercluster1;Total Processes;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595852177] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Total Processes;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595852177] SERVICE ALERT: pservercluster1;Total Processes;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595852184] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Current Users;UNKNOWN;notify-service-by-email;NRPE: Call to fork() failed
[1595852184] SERVICE ALERT: pservercluster1;Current Users;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595852497] SERVICE FLAPPING ALERT: pservercluster1;HDD_Root status;STARTED; Service appears to have started flapping (23.8% change >= 20.0% threshold)
[1595852497] SERVICE ALERT: pservercluster1;HDD_Root status;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595852500] SERVICE FLAPPING ALERT: pservercluster1;Messages Log Status;STARTED; Service appears to have started flapping (24.1% change >= 20.0% threshold)
[1595852500] SERVICE ALERT: pservercluster1;Messages Log Status;WARNING;HARD;3;NRPE: Unable to read output
[1595852541] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.0% (2972712 kB) free!
[1595852548] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU Load;UNKNOWN;notify-service-by-email;NRPE: Call to fork() failed
[1595852548] SERVICE ALERT: pservercluster1;CPU Load;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595852591] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1022 processes
[1595852769] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 13.6% (6690288 kB) free!
[1595852794] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Current Users;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595852794] SERVICE ALERT: pservercluster1;Current Users;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595852804] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;LocalService-NTPD SERVICE;UNKNOWN;notify-service-by-email;NRPE: Call to fork() failed
[1595852804] SERVICE ALERT: pservercluster1;LocalService-NTPD SERVICE;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595853102] SERVICE ALERT: pservercluster1;HDD_Root status;CRITICAL;HARD;3;CHECK_NRPE: Error - Could not complete SSL handshake.
[1595853110] SERVICE ALERT: pservercluster1;Messages Log Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595853141] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:18:00:34 +0530] TCP 502 0 0 0.001 "10.147.212.61:14001" "0" "0" "0.001"
[1595853158] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU Load;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595853158] SERVICE ALERT: pservercluster1;CPU Load;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595853414] SERVICE FLAPPING ALERT: pservercluster1;LocalService-NTPD SERVICE;STARTED; Service appears to have started flapping (23.7% change >= 20.0% threshold)
[1595853414] SERVICE ALERT: pservercluster1;LocalService-NTPD SERVICE;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595853522] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 351 processes
[1595853748] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU-STATISTICS;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595853761] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (225404 kB) free!
[1595853805] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU_Procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595853945] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.6% (293844 kB) free!
[1595854039] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;HDD_Home status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595854122] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 774 processes
[1595854157] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;zombie_procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595854166] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595854252] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.4% (458936 kB) free!
[1595854270] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 325 processes
[1595854329] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 70.46, 72.51, 74.81
[1595854329] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1184) < 182.18.184.244 [27/Jul/2020:18:22:09 +0530] TCP 502 0 0 0.000 "backend_5003" "0" "0" "0.000"
[1595854388] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Open-Files;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595854389] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(23) < 2020/07/27 18:21:51 [error] 1821#0: *1143485 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595854398] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Sensors Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Error - Could not complete SSL handshake.
[1595854825] Auto-save of retention data completed successfully.
[1595854943] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU-STATISTICS;UNKNOWN;notify-service-by-email;NRPE: Call to fork() failed
[1595854943] SERVICE ALERT: pservercluster1;CPU-STATISTICS;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595855076] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1636 processes
[1595855197] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;zombie_procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595855209] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;LocalService-NTPD SERVICE;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595855220] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Current Users;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595855241] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;HDD_Home status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595855258] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Total Processes;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595855262] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595855264] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU-STATISTICS;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595855278] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;HDD_Root status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595855361] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Messages Log Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595855388] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Open-Files;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595855496] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595855533] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Sensors Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595855553] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU-STATISTICS;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595855553] SERVICE ALERT: pservercluster1;CPU-STATISTICS;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595855769] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 9.9% (4900216 kB) free!
[1595855769] SERVICE ALERT: qservercluster2;Memory;CRITICAL;HARD;3;CRITICAL - 9.9% (4900216 kB) free!
[1595855787] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Total Processes;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595856141] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.7% (2832060 kB) free!
[1595856175] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2799) < 2020/07/27 18:52:54 [error] 1789#0: *3438516 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5000, upstream: "10.147.212.49:5500", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595856192] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1023 processes
[1595856404] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Current Users;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595856768] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU Load;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595857068] Warning: Return code of 255 for check of service 'HDD_Root status' on host 'pservercluster2' was out of bounds.
[1595857068] HOST ALERT: pservercluster2;DOWN;SOFT;1;CRITICAL - Host Unreachable (10.147.212.38)
[1595857073] wproc: Core Worker 26067: job 534 (pid=30749) timed out. Killing it
[1595857073] wproc: CHECK job 534 from worker Core Worker 26067 timed out after 30.04s
[1595857073] wproc:   host=pservercluster1; service=(null);
[1595857073] wproc:   early_timeout=1; exited_ok=0; wait_status=0; error_code=62;
[1595857073] Warning: Check of host 'pservercluster1' timed out after 30.04 seconds
[1595857073] HOST ALERT: pservercluster1;DOWN;SOFT;1;(Host check timed out after 30.04 seconds)
[1595857073] wproc: Core Worker 26067: job 534 (pid=30749): Dormant child reaped
[1595857122] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 352 processes
[1595857150] Warning: Return code of 255 for check of service 'zombie_procs' on host 'pservercluster1' was out of bounds.
[1595857154] Warning: Return code of 255 for check of service 'Messages Log Status' on host 'pservercluster2' was out of bounds.
[1595857159] Warning: Return code of 255 for check of service 'Memory' on host 'pservercluster1' was out of bounds.
[1595857181] Warning: Return code of 255 for check of service 'Open-Files' on host 'pservercluster2' was out of bounds.
[1595857258] HOST ALERT: pservercluster2;UP;SOFT;1;PING OK - Packet loss = 0%, RTA = 0.44 ms
[1595857262] HOST ALERT: pservercluster1;UP;SOFT;1;PING OK - Packet loss = 0%, RTA = 0.46 ms
[1595857287] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU_Procs;OK;notify-service-by-email;CPU OK: 331 processes
[1595857287] SERVICE ALERT: pservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 331 processes
[1595857302] SERVICE ALERT: pservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39507 MB (77% inode=99%):
[1595857303] SERVICE ALERT: pservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.75, 0.45, 0.18
[1595857323] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Sensors Status;OK;notify-service-by-email;SENSORS OK
[1595857323] SERVICE ALERT: pservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1595857341] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(296) < 103.16.101.72 [27/Jul/2020:19:12:20 +0530] TCP 502 0 0 0.000 "backend3" "0" "0" "0.000"
[1595857358] SERVICE FLAPPING ALERT: pservercluster1;CPU Load;STARTED; Service appears to have started flapping (21.4% change >= 20.0% threshold)
[1595857358] SERVICE ALERT: pservercluster1;CPU Load;OK;HARD;1;OK - load average: 0.08, 0.10, 0.05
[1595857358] SERVICE FLAPPING ALERT: pservercluster1;CPU-STATISTICS;STARTED; Service appears to have started flapping (22.5% change >= 20.0% threshold)
[1595857358] SERVICE ALERT: pservercluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.01% system=0.03% iowait=0.03% idle=99.94%
[1595857361] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (215320 kB) free!
[1595857379] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Open-Files;OK;notify-service-by-email;OK: 4224 open files (0% of max 2440681)
[1595857379] SERVICE ALERT: pservercluster1;Open-Files;OK;HARD;1;OK: 4224 open files (0% of max 2440681)
[1595857391] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Sensors Status;OK;notify-service-by-email;SENSORS OK
[1595857391] SERVICE ALERT: pservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1595857395] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU_Procs;OK;notify-service-by-email;CPU OK: 313 processes
[1595857395] SERVICE ALERT: pservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 313 processes
[1595857545] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.6% (293320 kB) free!
[1595857577] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Total Processes;OK;notify-service-by-email;PROCS OK: 318 processes
[1595857577] SERVICE ALERT: pservercluster1;Total Processes;OK;HARD;1;PROCS OK: 318 processes
[1595857587] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;zombie_procs;OK;notify-service-by-email;PROCS OK: 0 processes with STATE = Z
[1595857587] SERVICE ALERT: pservercluster2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595857594] SERVICE FLAPPING ALERT: pservercluster1;Current Users;STARTED; Service appears to have started flapping (21.3% change >= 20.0% threshold)
[1595857594] SERVICE ALERT: pservercluster1;Current Users;OK;HARD;1;USERS OK - 5 users currently logged in
[1595857599] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;LocalService-NTPD SERVICE;OK;notify-service-by-email;PROCS OK: 1 process with command name 'ntpd'
[1595857599] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595857610] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Current Users;OK;notify-service-by-email;USERS OK - 2 users currently logged in
[1595857610] SERVICE ALERT: pservercluster2;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1595857614] SERVICE ALERT: pservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595857629] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;HDD_Home status;OK;notify-service-by-email;DISK OK - free space: /home 172668 MB (78% inode=99%):
[1595857629] SERVICE ALERT: pservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 172668 MB (78% inode=99%):
[1595857631] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;HDD_Home status;OK;notify-service-by-email;DISK OK - free space: /home 147534 MB (65% inode=99%):
[1595857631] SERVICE ALERT: pservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 147534 MB (65% inode=99%):
[1595857648] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Total Processes;OK;notify-service-by-email;PROCS OK: 327 processes
[1595857648] SERVICE ALERT: pservercluster2;Total Processes;OK;HARD;1;PROCS OK: 327 processes
[1595857652] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;OK;notify-service-by-email;OK - 95.0% (23280088 kB) free.
[1595857652] SERVICE ALERT: pservercluster2;Memory;OK;HARD;1;OK - 95.0% (23280088 kB) free.
[1595857659] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU-STATISTICS;OK;notify-service-by-email;CPU STATISTICS OK: user=2.07% system=4.77% iowait=0.51% idle=92.64%
[1595857659] SERVICE ALERT: pservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=2.07% system=4.77% iowait=0.51% idle=92.64%
[1595857668] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;HDD_Root status;OK;notify-service-by-email;DISK OK - free space: / 38293 MB (74% inode=98%):
[1595857668] SERVICE ALERT: pservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 38293 MB (74% inode=98%):
[1595857722] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 772 processes
[1595857747] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;zombie_procs;OK;notify-service-by-email;PROCS OK: 0 processes with STATE = Z
[1595857747] SERVICE ALERT: pservercluster1;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595857756] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;OK;notify-service-by-email;OK - 95.4% (23541016 kB) free.
[1595857756] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 95.4% (23541016 kB) free.
[1595857778] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Open-Files;OK;notify-service-by-email;OK: 6432 open files (0% of max 2424156)
[1595857778] SERVICE ALERT: pservercluster2;Open-Files;OK;HARD;1;OK: 6432 open files (0% of max 2424156)
[1595857852] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.6% (512464 kB) free!
[1595857870] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 323 processes
[1595857911] SERVICE ALERT: pservercluster1;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1595857929] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 69.13, 72.53, 70.93
[1595857930] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1430) < 182.18.184.244 [27/Jul/2020:19:22:07 +0530] TCP 502 0 0 0.002 "10.147.212.61:5500, 10.147.212.49:5500, 10.147.212.38:5500, 10.147.212.37:5500" "0, 0, 0, 0" "0, 0, 0, 0" "0.000, 0.001, 0.000, 0.001"
[1595857989] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(646) < 2020/07/27 19:23:09 [error] 1823#0: *1149275 recv() failed (104: Connection reset by peer) while proxying connection, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.38:4000", bytes from/to client:45/0, bytes from/to upstream:0/45
[1595858329] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Messages Log Status;1595858327
[1595858329] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Messages Log Status;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1595858329] SERVICE ALERT: pservercluster2;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1595858425] Auto-save of retention data completed successfully.
[1595858677] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1636 processes
[1595859369] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 7.6% (3728804 kB) free!
[1595859741] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.8% (2857572 kB) free!
[1595860270] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 332 processes
[1595860270] SERVICE ALERT: sservercluster2;CPU_Procs;CRITICAL;HARD;3;CPU CRITICAL: 1 crit, 0 warn out of 332 processes
[1595860375] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2961) < 2020/07/27 20:02:54 [error] 1785#0: *3483231 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595860391] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1023 processes
[1595860722] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 357 processes
[1595860941] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:20:10:34 +0530] TCP 502 0 0 0.000 "10.147.212.61:14001" "0" "0" "0.000"
[1595860961] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;OK;notify-service-by-email;OK - 89.3% (44020684 kB) free.
[1595860961] SERVICE ALERT: sigqscluster1;Memory;OK;HARD;1;OK - 89.3% (44020684 kB) free.
[1595861122] SERVICE ALERT: sservercluster1;LocalService-NTPD SERVICE;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861142] SERVICE ALERT: sservercluster1;HDD_Root status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861146] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.6% (301892 kB) free!
[1595861152] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861165] SERVICE ALERT: sservercluster1;Current Users;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861175] SERVICE ALERT: sservercluster1;CPU-STATISTICS;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861176] SERVICE ALERT: sservercluster1;Sensors Status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861221] SERVICE ALERT: sservercluster1;Total Processes;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861221] SERVICE ALERT: sservercluster1;zombie_procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861221] SERVICE ALERT: sservercluster1;HDD_Home status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861235] SERVICE ALERT: sservercluster1;CPU_Procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861240] SERVICE ALERT: sservercluster1;Open-Files;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861252] SERVICE ALERT: sservercluster1;LocalService-NTPD SERVICE;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861272] SERVICE ALERT: sservercluster1;HDD_Root status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861282] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861295] SERVICE ALERT: sservercluster1;Current Users;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861305] SERVICE ALERT: sservercluster1;CPU-STATISTICS;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861306] SERVICE ALERT: sservercluster1;Sensors Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861322] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 773 processes
[1595861351] SERVICE ALERT: sservercluster1;Total Processes;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861351] SERVICE ALERT: sservercluster1;zombie_procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861351] SERVICE ALERT: sservercluster1;HDD_Home status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861362] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861366] SERVICE ALERT: sservercluster1;CPU_Procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861370] SERVICE ALERT: sservercluster1;Open-Files;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861382] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;LocalService-NTPD SERVICE;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861382] SERVICE ALERT: sservercluster1;LocalService-NTPD SERVICE;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861402] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;HDD_Root status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861402] SERVICE ALERT: sservercluster1;HDD_Root status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861406] SERVICE ALERT: sservercluster1;Messages Log Status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861412] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861412] SERVICE ALERT: sservercluster1;Memory;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861415] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Current Users;UNKNOWN;notify-service-by-email;NRPE: Call to fork() failed
[1595861415] SERVICE ALERT: sservercluster1;Current Users;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595861435] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU-STATISTICS;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861435] SERVICE ALERT: sservercluster1;CPU-STATISTICS;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861436] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Sensors Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861436] SERVICE ALERT: sservercluster1;Sensors Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861452] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (234824 kB) free!
[1595861481] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Total Processes;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861481] SERVICE ALERT: sservercluster1;Total Processes;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861481] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;zombie_procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861481] SERVICE ALERT: sservercluster1;zombie_procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861481] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;HDD_Home status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861481] SERVICE ALERT: sservercluster1;HDD_Home status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861490] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Open-Files;CRITICAL;notify-service-by-email;CHECK_NRPE: Error - Could not complete SSL handshake.
[1595861490] SERVICE ALERT: sservercluster1;Open-Files;CRITICAL;HARD;3;CHECK_NRPE: Error - Could not complete SSL handshake.
[1595861492] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861496] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU_Procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861496] SERVICE ALERT: sservercluster1;CPU_Procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861529] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 79.48, 76.67, 75.33
[1595861536] SERVICE ALERT: sservercluster1;Messages Log Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861589] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(29) < 2020/07/27 20:22:49 [error] 1820#0: *1165569 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595861622] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU Load;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861622] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861666] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Messages Log Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595861666] SERVICE ALERT: sservercluster1;Messages Log Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595862025] Auto-save of retention data completed successfully.
[1595862025] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Current Users;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595862025] SERVICE ALERT: sservercluster1;Current Users;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595862129] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1191) < 182.18.184.244 [27/Jul/2020:20:32:09 +0530] TCP 502 0 0 0.004 "10.147.212.61:5500, 10.147.212.49:5500, 10.147.212.37:5500, 10.147.212.38:5500" "0, 0, 0, 0" "0, 0, 0, 0" "0.000, 0.001, 0.002, 0.001"
[1595862277] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1647 processes
[1595862969] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.2% (2566120 kB) free!
[1595863341] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.7% (2784848 kB) free!
[1595863782] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;LocalService-NTPD SERVICE;OK;notify-service-by-email;PROCS OK: 1 process with command name 'ntpd'
[1595863782] SERVICE ALERT: sservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595863802] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;HDD_Root status;OK;notify-service-by-email;DISK OK - free space: / 40508 MB (79% inode=99%):
[1595863802] SERVICE ALERT: sservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40508 MB (79% inode=99%):
[1595863812] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;OK;notify-service-by-email;OK - 84.4% (20680532 kB) free.
[1595863812] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 84.4% (20680532 kB) free.
[1595863825] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Current Users;OK;notify-service-by-email;USERS OK - 2 users currently logged in
[1595863825] SERVICE ALERT: sservercluster1;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1595863836] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Sensors Status;OK;notify-service-by-email;SENSORS OK
[1595863836] SERVICE ALERT: sservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1595863841] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU-STATISTICS;OK;notify-service-by-email;CPU STATISTICS OK: user=2.98% system=11.37% iowait=0.04% idle=85.61%
[1595863841] SERVICE ALERT: sservercluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=2.98% system=11.37% iowait=0.04% idle=85.61%
[1595863852] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;OK;notify-service-by-email;OK - 25.5% (8349256 kB) free.
[1595863852] SERVICE ALERT: mrq4;Memory;OK;HARD;1;OK - 25.5% (8349256 kB) free.
[1595863870] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 335 processes
[1595863881] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;HDD_Home status;OK;notify-service-by-email;DISK OK - free space: /home 149760 MB (67% inode=99%):
[1595863881] SERVICE ALERT: sservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 149760 MB (67% inode=99%):
[1595863881] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Total Processes;OK;notify-service-by-email;PROCS OK: 346 processes
[1595863881] SERVICE ALERT: sservercluster1;Total Processes;OK;HARD;1;PROCS OK: 346 processes
[1595863881] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;zombie_procs;OK;notify-service-by-email;PROCS OK: 0 processes with STATE = Z
[1595863881] SERVICE ALERT: sservercluster1;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595863890] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Open-Files;OK;notify-service-by-email;OK: 12480 open files (0% of max 2424092)
[1595863890] SERVICE ALERT: sservercluster1;Open-Files;OK;HARD;1;OK: 12480 open files (0% of max 2424092)
[1595863896] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU_Procs;OK;notify-service-by-email;CPU OK: 346 processes
[1595863896] SERVICE ALERT: sservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 346 processes
[1595863904] SERVICE FLAPPING ALERT: pservercluster2;CPU Load;STOPPED; Service appears to have stopped flapping (4.8% change < 5.0% threshold)
[1595863975] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2767) < 2020/07/27 21:02:54 [error] 1785#0: *3510076 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "10.147.212.37:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595863991] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1024 processes
[1595864022] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU Load;OK;notify-service-by-email;OK - load average: 1.75, 2.26, 2.46
[1595864022] SERVICE ALERT: sservercluster1;CPU Load;OK;HARD;1;OK - load average: 1.75, 2.26, 2.46
[1595864322] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 353 processes
[1595864666] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Messages Log Status;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1595864666] SERVICE ALERT: sservercluster1;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1595864795] SERVICE FLAPPING ALERT: pservercluster1;Current Users;STOPPED; Service appears to have stopped flapping (4.7% change < 5.0% threshold)
[1595864922] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 770 processes
[1595865102] SERVICE FLAPPING ALERT: pservercluster1;HDD_Root status;STOPPED; Service appears to have stopped flapping (4.5% change < 5.0% threshold)
[1595865102] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;HDD_Root status;OK;notify-service-by-email;DISK OK - free space: / 39506 MB (77% inode=99%):
[1595865111] SERVICE FLAPPING ALERT: pservercluster1;Messages Log Status;STOPPED; Service appears to have stopped flapping (4.7% change < 5.0% threshold)
[1595865111] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Messages Log Status;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1595865129] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 72.37, 68.49, 68.20
[1595865141] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:21:20:34 +0530] TCP 502 0 0 0.001 "10.147.212.61:14001" "0" "0" "0.001"
[1595865158] SERVICE FLAPPING ALERT: pservercluster1;CPU Load;STOPPED; Service appears to have stopped flapping (4.5% change < 5.0% threshold)
[1595865189] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(143) < 2020/07/27 21:23:06 [error] 1822#0: *1172481 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595865345] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (324628 kB) free!
[1595865414] SERVICE FLAPPING ALERT: pservercluster1;LocalService-NTPD SERVICE;STOPPED; Service appears to have stopped flapping (4.5% change < 5.0% threshold)
[1595865414] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;LocalService-NTPD SERVICE;OK;notify-service-by-email;PROCS OK: 1 process with command name 'ntpd'
[1595865625] Auto-save of retention data completed successfully.
[1595865730] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1183) < 182.18.184.244 [27/Jul/2020:21:32:09 +0530] TCP 502 0 0 0.000 "backend_5002" "0" "0" "0.000"
[1595866476] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1436 processes
[1595866569] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 2.6% (1267096 kB) free!
[1595866941] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.7% (2796424 kB) free!
[1595867470] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 338 processes
[1595867564] SERVICE FLAPPING ALERT: pservercluster1;CPU-STATISTICS;STOPPED; Service appears to have stopped flapping (4.0% change < 5.0% threshold)
[1595867575] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2846) < 2020/07/27 22:02:55 [error] 1777#0: *3548304 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595867592] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1024 processes
[1595867638] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;SOFT;1;PROCS WARNING: 1520 processes
[1595867758] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;SOFT;2;PROCS WARNING: 1522 processes
[1595867879] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 1519 processes
[1595867879] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;HARD;3;PROCS WARNING: 1519 processes
[1595867922] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 357 processes
[1595868524] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 771 processes
[1595868729] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 46.81, 49.80, 51.98
[1595868741] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [27/Jul/2020:22:20:34 +0530] TCP 502 0 0 0.000 "10.147.212.61:14001" "0" "0" "0.000"
[1595868789] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(129) < 2020/07/27 22:23:02 [error] 1823#0: *1184497 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595868945] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (326564 kB) free!
[1595869225] Auto-save of retention data completed successfully.
[1595869930] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1189) < 182.18.184.244 [27/Jul/2020:22:42:09 +0530] TCP 502 0 0 0.000 "backend_5002" "0" "0" "0.000"
[1595870076] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1435 processes
[1595870169] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.8% (865256 kB) free!
[1595870541] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.7% (2797496 kB) free!
[1595871070] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 333 processes
[1595871175] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2851) < 2020/07/27 23:02:54 [error] 1790#0: *3590093 connect() failed (111: Connection refused) while connecting to upstream, client: 203.212.70.170, server: 0.0.0.0:3001, upstream: "10.147.212.155:3001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595871479] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 1505 processes
[1595871522] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 351 processes
[1595871791] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1022 processes
[1595872329] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 43.06, 49.26, 50.43
[1595872341] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(195) < 15.206.135.98 [27/Jul/2020:23:20:34 +0530] TCP 502 0 0 0.001 "10.147.212.61:14001" "0" "0" "0.001"
[1595872389] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(368) < 2020/07/27 23:20:34 [error] 1817#0: *1196490 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595872545] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.6% (274500 kB) free!
[1595872723] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 777 processes
[1595872825] Auto-save of retention data completed successfully.
[1595872871] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;OK;notify-service-by-email;CPU OK: 331 processes
[1595872871] SERVICE ALERT: sservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 331 processes
[1595873677] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1436 processes
[1595873769] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.3% (632560 kB) free!
[1595874129] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;WARNING;notify-service-by-email;WARNING - load average: 32.37, 33.66, 38.76
[1595874129] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 32.37, 33.66, 38.76
[1595874130] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1183) < 182.18.184.244 [27/Jul/2020:23:52:09 +0530] TCP 502 0 0 0.002 "10.147.212.61:5500, 10.147.212.49:5500, 10.147.212.38:5500, 10.147.212.37:5500" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.001, 0.000"
[1595874141] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.7% (2805120 kB) free!
