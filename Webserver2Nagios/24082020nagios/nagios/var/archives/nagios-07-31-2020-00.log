[1596047400] LOG ROTATION: DAILY
[1596047400] LOG VERSION: 2.0
[1596047400] CURRENT HOST STATE: TempHP1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.30 ms
[1596047400] CURRENT HOST STATE: TempHP2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.33 ms
[1596047400] CURRENT HOST STATE: TempHP3;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.29 ms
[1596047400] CURRENT HOST STATE: TempHP4;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.28 ms
[1596047400] CURRENT HOST STATE: db1-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.41 ms
[1596047400] CURRENT HOST STATE: db2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.37 ms
[1596047400] CURRENT HOST STATE: mrq4;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.27 ms
[1596047400] CURRENT HOST STATE: primary-server;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.43 ms
[1596047400] CURRENT HOST STATE: pservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.36 ms
[1596047400] CURRENT HOST STATE: pservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.35 ms
[1596047400] CURRENT HOST STATE: qservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.34 ms
[1596047400] CURRENT HOST STATE: qservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.36 ms
[1596047400] CURRENT HOST STATE: redis-1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.35 ms
[1596047400] CURRENT HOST STATE: redis-2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.40 ms
[1596047400] CURRENT HOST STATE: rq-1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.31 ms
[1596047400] CURRENT HOST STATE: rq-2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.31 ms
[1596047400] CURRENT HOST STATE: secondary-server;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.47 ms
[1596047400] CURRENT HOST STATE: sig1-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.50 ms
[1596047400] CURRENT HOST STATE: sig2-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.47 ms
[1596047400] CURRENT HOST STATE: sig3-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.56 ms
[1596047400] CURRENT HOST STATE: sig4-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.60 ms
[1596047400] CURRENT HOST STATE: sig5-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.45 ms
[1596047400] CURRENT HOST STATE: sig6-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.36 ms
[1596047400] CURRENT HOST STATE: sigqscluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.46 ms
[1596047400] CURRENT HOST STATE: sigqscluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.46 ms
[1596047400] CURRENT HOST STATE: smscapp1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.33 ms
[1596047400] CURRENT HOST STATE: smscapp2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.32 ms
[1596047400] CURRENT HOST STATE: sservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.40 ms
[1596047400] CURRENT HOST STATE: sservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.43 ms
[1596047400] CURRENT HOST STATE: webserver1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.42 ms
[1596047400] CURRENT HOST STATE: webserver2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.08 ms
[1596047400] CURRENT HOST STATE: webservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.43 ms
[1596047400] CURRENT HOST STATE: webservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.40 ms
[1596047400] CURRENT SERVICE STATE: TempHP1;CPU Load;OK;HARD;1;OK - load average: 18.43, 18.38, 18.34
[1596047400] CURRENT SERVICE STATE: TempHP1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=66.81% system=29.69% iowait=0.00% idle=3.49%
[1596047400] CURRENT SERVICE STATE: TempHP1;Chrony;OK;HARD;1;PROCS OK: 1 process with command name 'chronyd'
[1596047400] CURRENT SERVICE STATE: TempHP1;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: TempHP1;Home;OK;HARD;1;DISK OK - free space: /home 511706 MB (99% inode=99%):
[1596047400] CURRENT SERVICE STATE: TempHP1;Memory;OK;HARD;1;OK - 89.3% (117605240 kB) free.
[1596047400] CURRENT SERVICE STATE: TempHP1;Open-Files;OK;HARD;1;OK: 11232 open files (0% of max 13142776)
[1596047400] CURRENT SERVICE STATE: TempHP1;Root;OK;HARD;1;DISK OK - free space: /var/tmp 43427 MB (84% inode=99%):
[1596047400] CURRENT SERVICE STATE: TempHP1;Total Processes;OK;HARD;1;PROCS OK: 353 processes
[1596047400] CURRENT SERVICE STATE: TempHP1;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596047400] CURRENT SERVICE STATE: TempHP2;CPU Load;OK;HARD;1;OK - load average: 18.13, 17.81, 17.78
[1596047400] CURRENT SERVICE STATE: TempHP2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=68.50% system=29.67% iowait=0.00% idle=1.82%
[1596047400] CURRENT SERVICE STATE: TempHP2;Chrony;OK;HARD;1;PROCS OK: 1 process with command name 'chronyd'
[1596047400] CURRENT SERVICE STATE: TempHP2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: TempHP2;Home;OK;HARD;1;DISK OK - free space: /home 511585 MB (99% inode=99%):
[1596047400] CURRENT SERVICE STATE: TempHP2;Memory;OK;HARD;1;OK - 89.6% (117911720 kB) free.
[1596047400] CURRENT SERVICE STATE: TempHP2;Open-Files;OK;HARD;1;OK: 11360 open files (0% of max 13142787)
[1596047400] CURRENT SERVICE STATE: TempHP2;Root;OK;HARD;1;DISK OK - free space: /var/tmp 35600 MB (69% inode=99%):
[1596047400] CURRENT SERVICE STATE: TempHP2;Total Processes;OK;HARD;1;PROCS OK: 329 processes
[1596047400] CURRENT SERVICE STATE: TempHP2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596047400] CURRENT SERVICE STATE: TempHP3;CPU Load;OK;HARD;1;OK - load average: 17.57, 17.52, 17.44
[1596047400] CURRENT SERVICE STATE: TempHP3;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=68.62% system=29.45% iowait=0.00% idle=1.93%
[1596047400] CURRENT SERVICE STATE: TempHP3;Chrony;OK;HARD;1;PROCS OK: 1 process with command name 'chronyd'
[1596047400] CURRENT SERVICE STATE: TempHP3;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: TempHP3;Home;OK;HARD;1;DISK OK - free space: /home 511671 MB (99% inode=99%):
[1596047400] CURRENT SERVICE STATE: TempHP3;Memory;OK;HARD;1;OK - 94.9% (124956556 kB) free.
[1596047400] CURRENT SERVICE STATE: TempHP3;Open-Files;OK;HARD;1;OK: 9792 open files (0% of max 13142787)
[1596047400] CURRENT SERVICE STATE: TempHP3;Root;OK;HARD;1;DISK OK - free space: /var/tmp 43304 MB (84% inode=99%):
[1596047400] CURRENT SERVICE STATE: TempHP3;Total Processes;OK;HARD;1;PROCS OK: 330 processes
[1596047400] CURRENT SERVICE STATE: TempHP3;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596047400] CURRENT SERVICE STATE: TempHP4;CPU Load;OK;HARD;1;OK - load average: 17.55, 17.65, 17.72
[1596047400] CURRENT SERVICE STATE: TempHP4;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=68.00% system=29.51% iowait=0.00% idle=2.49%
[1596047400] CURRENT SERVICE STATE: TempHP4;Chrony;OK;HARD;1;PROCS OK: 1 process with command name 'chronyd'
[1596047400] CURRENT SERVICE STATE: TempHP4;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: TempHP4;Home;OK;HARD;1;DISK OK - free space: /home 511023 MB (99% inode=99%):
[1596047400] CURRENT SERVICE STATE: TempHP4;Memory;OK;HARD;1;OK - 94.9% (124958760 kB) free.
[1596047400] CURRENT SERVICE STATE: TempHP4;Open-Files;OK;HARD;1;OK: 9920 open files (15% of max 64000)
[1596047400] CURRENT SERVICE STATE: TempHP4;Root;OK;HARD;1;DISK OK - free space: /var/tmp 42837 MB (83% inode=99%):
[1596047400] CURRENT SERVICE STATE: TempHP4;Total Processes;OK;HARD;1;PROCS OK: 333 processes
[1596047400] CURRENT SERVICE STATE: TempHP4;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596047400] CURRENT SERVICE STATE: db1-vm2;CPU Load;OK;HARD;1;OK - load average: 5.02, 4.80, 4.92
[1596047400] CURRENT SERVICE STATE: db1-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=3.38% system=14.17% iowait=0.00% idle=80.90%
[1596047400] CURRENT SERVICE STATE: db1-vm2;CPU_Procs;OK;HARD;1;CPU OK: 389 processes
[1596047400] CURRENT SERVICE STATE: db1-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: db1-vm2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 26972 MB (67% inode=99%):
[1596047400] CURRENT SERVICE STATE: db1-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44898 MB (87% inode=99%):
[1596047400] CURRENT SERVICE STATE: db1-vm2;Memory;OK;HARD;1;OK - 92.5% (22837228 kB) free.
[1596047400] CURRENT SERVICE STATE: db1-vm2;Open-Files;OK;HARD;1;OK: 11648 open files (0% of max 2441815)
[1596047400] CURRENT SERVICE STATE: db1-vm2;OutOfMemory-killer--oom-killer;OK;HARD;1;Log check ok - 0 pattern matches found
[1596047400] CURRENT SERVICE STATE: db1-vm2;PING;OK;HARD;1;PING OK - Packet loss = 0%, RTA = 0.06 ms
[1596047400] CURRENT SERVICE STATE: db1-vm2;Total Processes;OK;HARD;1;PROCS OK: 390 processes
[1596047400] CURRENT SERVICE STATE: db1-vm2;zombie_procs;OK;HARD;1;PROCS OK: 1 process with STATE = Z
[1596047400] CURRENT SERVICE STATE: db2;CPU Load;OK;HARD;1;OK - load average: 0.01, 0.03, 0.05
[1596047400] CURRENT SERVICE STATE: db2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.34% system=0.36% iowait=0.00% idle=99.30%
[1596047400] CURRENT SERVICE STATE: db2;CPU_Procs;OK;HARD;1;CPU OK: 292 processes
[1596047400] CURRENT SERVICE STATE: db2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: db2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 69276 MB (30% inode=99%):
[1596047400] CURRENT SERVICE STATE: db2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44497 MB (86% inode=99%):
[1596047400] CURRENT SERVICE STATE: db2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: db2;Mariadb status;OK;HARD;1;PROCS OK: 1 process with command name 'mysqld'
[1596047400] CURRENT SERVICE STATE: db2;Memory;CRITICAL;HARD;3;CRITICAL - 5.6% (2736864 kB) free!
[1596047400] CURRENT SERVICE STATE: db2;Open-Files;OK;HARD;1;OK: 6624 open files (0% of max 4878253)
[1596047400] CURRENT SERVICE STATE: db2;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: db2;Total Processes;OK;HARD;1;PROCS OK: 292 processes
[1596047400] CURRENT SERVICE STATE: db2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596047400] CURRENT SERVICE STATE: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 34.37, 35.07, 38.40
[1596047400] CURRENT SERVICE STATE: mrq4;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=13.49% system=42.41% iowait=0.00% idle=44.10%
[1596047400] CURRENT SERVICE STATE: mrq4;CPU_Procs;OK;HARD;1;CPU OK: 1438 processes
[1596047400] CURRENT SERVICE STATE: mrq4;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: mrq4;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 211112 MB (95% inode=99%):
[1596047400] CURRENT SERVICE STATE: mrq4;HDD_Root status;OK;HARD;1;DISK OK - free space: / 45380 MB (88% inode=99%):
[1596047400] CURRENT SERVICE STATE: mrq4;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: mrq4;Memory;OK;HARD;1;OK - 44.3% (14508796 kB) free.
[1596047400] CURRENT SERVICE STATE: mrq4;Open-Files;OK;HARD;1;OK: 71040 open files (2% of max 3240801)
[1596047400] CURRENT SERVICE STATE: mrq4;Total Processes;CRITICAL;HARD;3;PROCS CRITICAL: 1437 processes
[1596047400] CURRENT SERVICE STATE: mrq4;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596047400] CURRENT SERVICE STATE: primary-server;CPU Load;OK;HARD;1;OK - load average: 0.02, 0.04, 0.05
[1596047400] CURRENT SERVICE STATE: primary-server;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.03% system=0.13% iowait=0.00% idle=99.85%
[1596047400] CURRENT SERVICE STATE: primary-server;CPU_Procs;OK;HARD;1;CPU OK: 306 processes
[1596047400] CURRENT SERVICE STATE: primary-server;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1596047400] CURRENT SERVICE STATE: primary-server;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 201766 MB (89% inode=99%):
[1596047400] CURRENT SERVICE STATE: primary-server;HDD_Root status;OK;HARD;1;DISK OK - free space: / 13856 MB (27% inode=99%):
[1596047400] CURRENT SERVICE STATE: primary-server;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: primary-server;Memory;OK;HARD;1;OK - 76.9% (18837356 kB) free.
[1596047400] CURRENT SERVICE STATE: primary-server;Nginx Access Log Status;CRITICAL;HARD;3;(691) < 182.18.184.244 [29/Jul/2020:23:52:09 +0530] TCP 502 0 0 0.000 "backend_5002" "0" "0" "0.000"
[1596047400] CURRENT SERVICE STATE: primary-server;Nginx Error Log Status;CRITICAL;HARD;3;(1869) < 2020/07/29 23:52:54 [error] 1785#0: *5508393 access forbidden by rule while initializing session, client: 103.209.99.7, server: 0.0.0.0:13000
[1596047400] CURRENT SERVICE STATE: primary-server;Nginx Status;OK;HARD;1;NGINX OK -  0.086 sec. response time, Active: 0 (Writing: 0 Reading: 0 Waiting: 0) ReqPerSec: 0.000 ConnPerSec: 0.000 ReqPerConn: 0.000
[1596047400] CURRENT SERVICE STATE: primary-server;Open-Files;OK;HARD;1;OK: 7008 open files (0% of max 2423416)
[1596047400] CURRENT SERVICE STATE: primary-server;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: primary-server;Total Processes;OK;HARD;1;PROCS OK: 309 processes
[1596047400] CURRENT SERVICE STATE: primary-server;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596047400] CURRENT SERVICE STATE: pservercluster1;CPU Load;OK;HARD;1;OK - load average: 1.13, 1.28, 1.14
[1596047400] CURRENT SERVICE STATE: pservercluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.54% system=6.53% iowait=0.00% idle=91.93%
[1596047400] CURRENT SERVICE STATE: pservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 316 processes
[1596047400] CURRENT SERVICE STATE: pservercluster1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1596047400] CURRENT SERVICE STATE: pservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 168678 MB (76% inode=99%):
[1596047400] CURRENT SERVICE STATE: pservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39510 MB (77% inode=99%):
[1596047400] CURRENT SERVICE STATE: pservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: pservercluster1;Memory;OK;HARD;1;OK - 91.7% (22637516 kB) free.
[1596047400] CURRENT SERVICE STATE: pservercluster1;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1596047400] CURRENT SERVICE STATE: pservercluster1;Open-Files;OK;HARD;1;OK: 6560 open files (0% of max 2440681)
[1596047400] CURRENT SERVICE STATE: pservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: pservercluster1;Total Processes;OK;HARD;1;PROCS OK: 314 processes
[1596047400] CURRENT SERVICE STATE: pservercluster1;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596047400] CURRENT SERVICE STATE: pservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.71, 0.65, 0.78
[1596047400] CURRENT SERVICE STATE: pservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.23% system=3.97% iowait=0.00% idle=94.81%
[1596047400] CURRENT SERVICE STATE: pservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 332 processes
[1596047400] CURRENT SERVICE STATE: pservercluster2;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1596047400] CURRENT SERVICE STATE: pservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 169749 MB (75% inode=99%):
[1596047400] CURRENT SERVICE STATE: pservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 38285 MB (74% inode=98%):
[1596047400] CURRENT SERVICE STATE: pservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: pservercluster2;Memory;OK;HARD;1;OK - 91.2% (22343456 kB) free.
[1596047400] CURRENT SERVICE STATE: pservercluster2;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1596047400] CURRENT SERVICE STATE: pservercluster2;Open-Files;OK;HARD;1;OK: 8192 open files (0% of max 2424156)
[1596047400] CURRENT SERVICE STATE: pservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: pservercluster2;Total Processes;OK;HARD;1;PROCS OK: 332 processes
[1596047400] CURRENT SERVICE STATE: pservercluster2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596047400] CURRENT SERVICE STATE: qservercluster1;CPU Load;OK;HARD;1;OK - load average: 5.71, 6.65, 6.77
[1596047400] CURRENT SERVICE STATE: qservercluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=27.99% system=13.80% iowait=0.00% idle=58.22%
[1596047400] CURRENT SERVICE STATE: qservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 298 processes
[1596047400] CURRENT SERVICE STATE: qservercluster1;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: qservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 224641 MB (99% inode=99%):
[1596047400] CURRENT SERVICE STATE: qservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 43071 MB (84% inode=99%):
[1596047400] CURRENT SERVICE STATE: qservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: qservercluster1;Memory;OK;HARD;1;OK - 89.3% (43956616 kB) free.
[1596047400] CURRENT SERVICE STATE: qservercluster1;Open-Files;OK;HARD;1;OK: 8032 open files (0% of max 4874250)
[1596047400] CURRENT SERVICE STATE: qservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: qservercluster1;Total Processes;OK;HARD;1;PROCS OK: 298 processes
[1596047400] CURRENT SERVICE STATE: qservercluster1;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596047400] CURRENT SERVICE STATE: qservercluster2;CPU Load;OK;HARD;1;OK - load average: 5.91, 5.92, 6.00
[1596047400] CURRENT SERVICE STATE: qservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=7.97% system=22.95% iowait=0.00% idle=69.08%
[1596047400] CURRENT SERVICE STATE: qservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 772 processes
[1596047400] CURRENT SERVICE STATE: qservercluster2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: qservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 151670 MB (67% inode=99%):
[1596047400] CURRENT SERVICE STATE: qservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 26997 MB (52% inode=98%):
[1596047400] CURRENT SERVICE STATE: qservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: qservercluster2;Memory;WARNING;HARD;3;WARNING - 11.2% (5519388 kB) free!
[1596047400] CURRENT SERVICE STATE: qservercluster2;Open-Files;OK;HARD;1;OK: 22624 open files (0% of max 4878254)
[1596047400] CURRENT SERVICE STATE: qservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: qservercluster2;Total Processes;WARNING;HARD;3;PROCS WARNING: 774 processes
[1596047400] CURRENT SERVICE STATE: qservercluster2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596047400] CURRENT SERVICE STATE: redis-1;CPU Load;OK;HARD;1;OK - load average: 0.04, 0.05, 0.10
[1596047400] CURRENT SERVICE STATE: redis-1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.69% system=1.00% iowait=0.01% idle=98.30%
[1596047400] CURRENT SERVICE STATE: redis-1;CPU_Procs;OK;HARD;1;CPU OK: 407 processes
[1596047400] CURRENT SERVICE STATE: redis-1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1596047400] CURRENT SERVICE STATE: redis-1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 348653 MB (93% inode=99%):
[1596047400] CURRENT SERVICE STATE: redis-1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44019 MB (86% inode=99%):
[1596047400] CURRENT SERVICE STATE: redis-1;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /vns1 533190 MB (49% inode=99%):
[1596047400] CURRENT SERVICE STATE: redis-1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: redis-1;Memory;OK;HARD;1;OK - 34.3% (45194340 kB) free.
[1596047400] CURRENT SERVICE STATE: redis-1;Open-Files;OK;HARD;1;OK: 25248 open files (0% of max 13066864)
[1596047400] CURRENT SERVICE STATE: redis-1;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: redis-1;Total Processes;OK;HARD;1;PROCS OK: 407 processes
[1596047400] CURRENT SERVICE STATE: redis-2;CPU Load;OK;HARD;1;OK - load average: 0.02, 0.07, 0.12
[1596047400] CURRENT SERVICE STATE: redis-2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.34% system=0.45% iowait=0.01% idle=99.20%
[1596047400] CURRENT SERVICE STATE: redis-2;CPU_Procs;OK;HARD;1;CPU OK: 344 processes
[1596047400] CURRENT SERVICE STATE: redis-2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: redis-2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 234412 MB (62% inode=99%):
[1596047400] CURRENT SERVICE STATE: redis-2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44179 MB (86% inode=99%):
[1596047400] CURRENT SERVICE STATE: redis-2;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /vns1 1069171 MB (99% inode=99%):
[1596047400] CURRENT SERVICE STATE: redis-2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: redis-2;Memory;OK;HARD;1;OK - 55.9% (73685476 kB) free.
[1596047400] CURRENT SERVICE STATE: redis-2;Open-Files;OK;HARD;1;OK: 13104 open files (19% of max 65536)
[1596047400] CURRENT SERVICE STATE: redis-2;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: redis-2;Total Processes;OK;HARD;1;PROCS OK: 346 processes
[1596047400] CURRENT SERVICE STATE: rq-1;CPU Load;OK;HARD;1;OK - load average: 17.84, 16.86, 17.20
[1596047400] CURRENT SERVICE STATE: rq-1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=52.77% system=19.80% iowait=0.00% idle=27.43%
[1596047400] CURRENT SERVICE STATE: rq-1;CPU_Procs;WARNING;HARD;3;CPU WARNING: 1 warn out of 351 processes
[1596047400] CURRENT SERVICE STATE: rq-1;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: rq-1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 400998 MB (99% inode=99%):
[1596047400] CURRENT SERVICE STATE: rq-1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40317 MB (78% inode=99%):
[1596047400] CURRENT SERVICE STATE: rq-1;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /rq1vns1 1068147 MB (99% inode=99%):
[1596047400] CURRENT SERVICE STATE: rq-1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: rq-1;Memory;OK;HARD;1;OK - 77.0% (101549444 kB) free.
[1596047400] CURRENT SERVICE STATE: rq-1;Open-Files;OK;HARD;1;OK: 10080 open files (0% of max 13066902)
[1596047400] CURRENT SERVICE STATE: rq-1;Total Processes;OK;HARD;1;PROCS OK: 352 processes
[1596047400] CURRENT SERVICE STATE: rq-1;rq1-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1596047400] CURRENT SERVICE STATE: rq-2;CPU Load;OK;HARD;1;OK - load average: 17.63, 15.93, 15.55
[1596047400] CURRENT SERVICE STATE: rq-2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=48.95% system=17.11% iowait=0.01% idle=33.93%
[1596047400] CURRENT SERVICE STATE: rq-2;CPU_Procs;OK;HARD;1;CPU OK: 344 processes
[1596047400] CURRENT SERVICE STATE: rq-2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: rq-2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 401126 MB (99% inode=99%):
[1596047400] CURRENT SERVICE STATE: rq-2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 45538 MB (88% inode=99%):
[1596047400] CURRENT SERVICE STATE: rq-2;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /dev 64349 MB (100% inode=99%):
[1596047400] CURRENT SERVICE STATE: rq-2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: rq-2;Memory;OK;HARD;1;OK - 94.5% (124619668 kB) free.
[1596047400] CURRENT SERVICE STATE: rq-2;Open-Files;OK;HARD;1;OK: 10416 open files (0% of max 13066939)
[1596047400] CURRENT SERVICE STATE: rq-2;Total Processes;OK;HARD;1;PROCS OK: 346 processes
[1596047400] CURRENT SERVICE STATE: rq-2;rq2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1596047400] CURRENT SERVICE STATE: secondary-server;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.01, 0.05
[1596047400] CURRENT SERVICE STATE: secondary-server;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.06% system=0.15% iowait=0.00% idle=99.79%
[1596047400] CURRENT SERVICE STATE: secondary-server;CPU_Procs;OK;HARD;1;CPU OK: 304 processes
[1596047400] CURRENT SERVICE STATE: secondary-server;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1596047400] CURRENT SERVICE STATE: secondary-server;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 71499 MB (31% inode=99%):
[1596047400] CURRENT SERVICE STATE: secondary-server;HDD_Root status;OK;HARD;1;DISK OK - free space: / 36659 MB (71% inode=99%):
[1596047400] CURRENT SERVICE STATE: secondary-server;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: secondary-server;Memory Status;CRITICAL;HARD;3;CRITICAL - 0.9% (212452 kB) free!
[1596047400] CURRENT SERVICE STATE: secondary-server;Nginx Access Log Status;CRITICAL;HARD;3;(4) < 15.206.135.98 [29/Jul/2020:23:50:07 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1596047400] CURRENT SERVICE STATE: secondary-server;Nginx Error Log Status;CRITICAL;HARD;3;(4) < 2020/07/29 23:52:37 [error] 1822#0: *1801508 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596047400] CURRENT SERVICE STATE: secondary-server;Nginx Status;OK;HARD;1;NGINX OK -  0.088 sec. response time, Active: 0 (Writing: 0 Reading: 0 Waiting: 0) ReqPerSec: 0.000 ConnPerSec: 0.000 ReqPerConn: 0.000
[1596047400] CURRENT SERVICE STATE: secondary-server;Open-Files;OK;HARD;1;OK: 6240 open files (0% of max 2423397)
[1596047400] CURRENT SERVICE STATE: secondary-server;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: secondary-server;Total Processes;OK;HARD;1;PROCS OK: 311 processes
[1596047400] CURRENT SERVICE STATE: sig1-vm2;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.00, 0.00
[1596047400] CURRENT SERVICE STATE: sig1-vm2;CPU_Procs;OK;HARD;1;CPU OK: 287 processes
[1596047400] CURRENT SERVICE STATE: sig1-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: sig1-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: sig1-vm2;Memory;OK;HARD;1;OK - 44.7% (7301796 kB) free.
[1596047400] CURRENT SERVICE STATE: sig1-vm2;Open-Files;OK;HARD;1;OK: 2720 open files (0% of max 1620608)
[1596047400] CURRENT SERVICE STATE: sig1-vm2;Root status;OK;HARD;1;DISK OK - free space: / 117798 MB (87% inode=96%):
[1596047400] CURRENT SERVICE STATE: sig1-vm2;Total Processes;OK;HARD;1;PROCS OK: 287 processes
[1596047400] CURRENT SERVICE STATE: sig2-vm2;CPU Load;OK;HARD;1;OK - load average: 2.55, 3.71, 4.44
[1596047400] CURRENT SERVICE STATE: sig2-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=3.35% system=14.66% iowait=0.00% idle=80.43%
[1596047400] CURRENT SERVICE STATE: sig2-vm2;CPU_Procs;OK;HARD;1;CPU OK: 384 processes
[1596047400] CURRENT SERVICE STATE: sig2-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: sig2-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 124184 MB (89% inode=99%):
[1596047400] CURRENT SERVICE STATE: sig2-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: sig2-vm2;Memory;OK;HARD;1;OK - 94.9% (33051920 kB) free.
[1596047400] CURRENT SERVICE STATE: sig2-vm2;Open-Files;OK;HARD;1;OK: 11904 open files (0% of max 3443846)
[1596047400] CURRENT SERVICE STATE: sig2-vm2;Total Processes;OK;HARD;1;PROCS OK: 384 processes
[1596047400] CURRENT SERVICE STATE: sig3-vm2;CPU Load;OK;HARD;1;OK - load average: 7.44, 5.55, 5.31
[1596047400] CURRENT SERVICE STATE: sig3-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=3.04% system=15.77% iowait=0.19% idle=81.00%
[1596047400] CURRENT SERVICE STATE: sig3-vm2;CPU_Procs;OK;HARD;1;CPU OK: 467 processes
[1596047400] CURRENT SERVICE STATE: sig3-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: sig3-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 90214 MB (75% inode=96%):
[1596047400] CURRENT SERVICE STATE: sig3-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 2 processes with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: sig3-vm2;Memory;OK;HARD;1;OK - 96.5% (22733084 kB) free.
[1596047400] CURRENT SERVICE STATE: sig3-vm2;Open-Files;OK;HARD;1;OK: 9472 open files (0% of max 2339574)
[1596047400] CURRENT SERVICE STATE: sig3-vm2;Total Processes;OK;HARD;1;PROCS OK: 467 processes
[1596047400] CURRENT SERVICE STATE: sig4-vm2;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.01, 0.05
[1596047400] CURRENT SERVICE STATE: sig4-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.03% system=0.03% iowait=0.00% idle=99.91%
[1596047400] CURRENT SERVICE STATE: sig4-vm2;CPU_Procs;OK;HARD;1;CPU OK: 220 processes
[1596047400] CURRENT SERVICE STATE: sig4-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: sig4-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 87086 MB (67% inode=99%):
[1596047400] CURRENT SERVICE STATE: sig4-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: sig4-vm2;Memory;OK;HARD;1;OK - 96.3% (33535432 kB) free.
[1596047400] CURRENT SERVICE STATE: sig4-vm2;Open-Files;OK;HARD;1;OK: 5792 open files (0% of max 3443901)
[1596047400] CURRENT SERVICE STATE: sig4-vm2;Total Processes;OK;HARD;1;PROCS OK: 225 processes
[1596047400] CURRENT SERVICE STATE: sig5-vm2;CPU Load;OK;HARD;1;OK - load average: 6.65, 6.08, 5.90
[1596047400] CURRENT SERVICE STATE: sig5-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=3.47% system=15.53% iowait=0.00% idle=79.42%
[1596047400] CURRENT SERVICE STATE: sig5-vm2;CPU_Procs;OK;HARD;1;CPU OK: 383 processes
[1596047400] CURRENT SERVICE STATE: sig5-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: sig5-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 231091 MB (92% inode=99%):
[1596047400] CURRENT SERVICE STATE: sig5-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: sig5-vm2;Memory;OK;HARD;1;OK - 93.3% (32676028 kB) free.
[1596047400] CURRENT SERVICE STATE: sig5-vm2;Open-Files;OK;HARD;1;OK: 11904 open files (0% of max 3462151)
[1596047400] CURRENT SERVICE STATE: sig5-vm2;Total Processes;OK;HARD;1;PROCS OK: 383 processes
[1596047400] CURRENT SERVICE STATE: sig6-vm2;CPU Load;OK;HARD;1;OK - load average: 6.19, 5.28, 5.26
[1596047400] CURRENT SERVICE STATE: sig6-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.47% system=5.63% iowait=0.00% idle=91.76%
[1596047400] CURRENT SERVICE STATE: sig6-vm2;CPU_Procs;OK;HARD;1;CPU OK: 381 processes
[1596047400] CURRENT SERVICE STATE: sig6-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: sig6-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 179511 MB (91% inode=99%):
[1596047400] CURRENT SERVICE STATE: sig6-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: sig6-vm2;Memory;OK;HARD;1;OK - 89.1% (20000352 kB) free.
[1596047400] CURRENT SERVICE STATE: sig6-vm2;Open-Files;OK;HARD;1;OK: 11968 open files (0% of max 2220276)
[1596047400] CURRENT SERVICE STATE: sig6-vm2;OutOfMemory-killer--oom-killer;OK;HARD;1;Log check ok - 0 pattern matches found
[1596047400] CURRENT SERVICE STATE: sig6-vm2;Total Processes;OK;HARD;1;PROCS OK: 381 processes
[1596047400] CURRENT SERVICE STATE: sigqscluster1;CPU Load;OK;HARD;1;OK - load average: 0.07, 0.12, 0.24
[1596047400] CURRENT SERVICE STATE: sigqscluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.63% system=0.69% iowait=0.00% idle=98.68%
[1596047400] CURRENT SERVICE STATE: sigqscluster1;CPU_Procs;OK;HARD;1;CPU OK: 1423 processes
[1596047400] CURRENT SERVICE STATE: sigqscluster1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1596047400] CURRENT SERVICE STATE: sigqscluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 82801 MB (36% inode=99%):
[1596047400] CURRENT SERVICE STATE: sigqscluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39933 MB (78% inode=99%):
[1596047400] CURRENT SERVICE STATE: sigqscluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: sigqscluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.5% (249228 kB) free!
[1596047400] CURRENT SERVICE STATE: sigqscluster1;Open-Files;OK;HARD;1;OK: 64896 open files (1% of max 4878272)
[1596047400] CURRENT SERVICE STATE: sigqscluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: sigqscluster1;Total Processes;OK;HARD;1;PROCS OK: 1421 processes
[1596047400] CURRENT SERVICE STATE: sigqscluster2;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.02, 0.05
[1596047400] CURRENT SERVICE STATE: sigqscluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.19% system=0.14% iowait=0.00% idle=99.67%
[1596047400] CURRENT SERVICE STATE: sigqscluster2;CPU_Procs;OK;HARD;1;CPU OK: 291 processes
[1596047400] CURRENT SERVICE STATE: sigqscluster2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: sigqscluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 208151 MB (99% inode=99%):
[1596047400] CURRENT SERVICE STATE: sigqscluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44718 MB (87% inode=99%):
[1596047400] CURRENT SERVICE STATE: sigqscluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: sigqscluster2;Memory;OK;HARD;1;OK - 97.8% (48210832 kB) free.
[1596047400] CURRENT SERVICE STATE: sigqscluster2;Open-Files;OK;HARD;1;OK: 5696 open files (0% of max 4878254)
[1596047400] CURRENT SERVICE STATE: sigqscluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: sigqscluster2;Total Processes;OK;HARD;1;PROCS OK: 292 processes
[1596047400] CURRENT SERVICE STATE: sigqscluster2;sigqscluster2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1596047400] CURRENT SERVICE STATE: smscapp1;CPU Load;OK;HARD;1;OK - load average: 8.96, 8.40, 8.51
[1596047400] CURRENT SERVICE STATE: smscapp1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=10.37% system=27.91% iowait=0.13% idle=61.50%
[1596047400] CURRENT SERVICE STATE: smscapp1;CPU_Procs;OK;HARD;1;CPU OK: 1021 processes
[1596047400] CURRENT SERVICE STATE: smscapp1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1596047400] CURRENT SERVICE STATE: smscapp1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 158483 MB (70% inode=99%):
[1596047400] CURRENT SERVICE STATE: smscapp1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39105 MB (76% inode=98%):
[1596047400] CURRENT SERVICE STATE: smscapp1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: smscapp1;Memory;CRITICAL;HARD;3;CRITICAL - 0.5% (227232 kB) free!
[1596047400] CURRENT SERVICE STATE: smscapp1;Open-Files;OK;HARD;1;OK: 33120 open files (0% of max 4878253)
[1596047400] CURRENT SERVICE STATE: smscapp1;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: smscapp1;Total Processes;CRITICAL;HARD;3;PROCS CRITICAL: 1020 processes
[1596047400] CURRENT SERVICE STATE: smscapp2;CPU Load;OK;HARD;1;OK - load average: 9.84, 10.07, 9.84
[1596047400] CURRENT SERVICE STATE: smscapp2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=9.19% system=31.38% iowait=0.00% idle=59.43%
[1596047400] CURRENT SERVICE STATE: smscapp2;CPU_Procs;OK;HARD;1;CPU OK: 1784 processes
[1596047400] CURRENT SERVICE STATE: smscapp2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: smscapp2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 107122 MB (47% inode=99%):
[1596047400] CURRENT SERVICE STATE: smscapp2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 38770 MB (75% inode=98%):
[1596047400] CURRENT SERVICE STATE: smscapp2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: smscapp2;Memory;OK;HARD;1;OK - 84.8% (41793684 kB) free.
[1596047400] CURRENT SERVICE STATE: smscapp2;Open-Files;OK;HARD;1;OK: 89408 open files (1% of max 4878254)
[1596047400] CURRENT SERVICE STATE: smscapp2;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: smscapp2;Total Processes;OK;HARD;1;PROCS OK: 1784 processes
[1596047400] CURRENT SERVICE STATE: sservercluster1;CPU Load;OK;HARD;1;OK - load average: 0.99, 1.17, 1.32
[1596047400] CURRENT SERVICE STATE: sservercluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.41% system=5.78% iowait=0.00% idle=92.81%
[1596047400] CURRENT SERVICE STATE: sservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 323 processes
[1596047400] CURRENT SERVICE STATE: sservercluster1;Current Users;OK;HARD;1;USERS OK - 5 users currently logged in
[1596047400] CURRENT SERVICE STATE: sservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 175409 MB (79% inode=99%):
[1596047400] CURRENT SERVICE STATE: sservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40502 MB (79% inode=99%):
[1596047400] CURRENT SERVICE STATE: sservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: sservercluster1;Memory;OK;HARD;1;OK - 91.4% (22415004 kB) free.
[1596047400] CURRENT SERVICE STATE: sservercluster1;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1596047400] CURRENT SERVICE STATE: sservercluster1;Open-Files;OK;HARD;1;OK: 6560 open files (0% of max 2424092)
[1596047400] CURRENT SERVICE STATE: sservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: sservercluster1;Total Processes;OK;HARD;1;PROCS OK: 323 processes
[1596047400] CURRENT SERVICE STATE: sservercluster1;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596047400] CURRENT SERVICE STATE: sservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.46, 0.68, 0.79
[1596047400] CURRENT SERVICE STATE: sservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.11% system=5.10% iowait=0.00% idle=93.78%
[1596047400] CURRENT SERVICE STATE: sservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 323 processes
[1596047400] CURRENT SERVICE STATE: sservercluster2;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1596047400] CURRENT SERVICE STATE: sservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 190974 MB (86% inode=99%):
[1596047400] CURRENT SERVICE STATE: sservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 33083 MB (64% inode=98%):
[1596047400] CURRENT SERVICE STATE: sservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: sservercluster2;Memory;OK;HARD;1;OK - 89.1% (21830524 kB) free.
[1596047400] CURRENT SERVICE STATE: sservercluster2;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1596047400] CURRENT SERVICE STATE: sservercluster2;Open-Files;OK;HARD;1;OK: 6624 open files (0% of max 2424092)
[1596047400] CURRENT SERVICE STATE: sservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: sservercluster2;Total Processes;OK;HARD;1;PROCS OK: 320 processes
[1596047400] CURRENT SERVICE STATE: sservercluster2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596047400] CURRENT SERVICE STATE: webserver1;CPU Load;OK;HARD;1;OK - load average: 0.01, 0.03, 0.05
[1596047400] CURRENT SERVICE STATE: webserver1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.08% system=0.01% iowait=0.00% idle=99.91%
[1596047400] CURRENT SERVICE STATE: webserver1;CPU_Procs;OK;HARD;1;CPU OK: 325 processes
[1596047400] CURRENT SERVICE STATE: webserver1;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1596047400] CURRENT SERVICE STATE: webserver1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 224773 MB (99% inode=99%):
[1596047400] CURRENT SERVICE STATE: webserver1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40141 MB (78% inode=99%):
[1596047400] CURRENT SERVICE STATE: webserver1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: webserver1;Memory;OK;HARD;1;OK - 93.6% (22909240 kB) free.
[1596047400] CURRENT SERVICE STATE: webserver1;Nginx_status;OK;HARD;1;NGINX OK -  0.092 sec. response time, Active: 1 (Writing: 1 Reading: 0 Waiting: 0) ReqPerSec: 2.037 ConnPerSec: 2.043 ReqPerConn: 0.996
[1596047400] CURRENT SERVICE STATE: webserver1;Open-Files;OK;HARD;1;OK: 6176 open files (0% of max 2419418)
[1596047400] CURRENT SERVICE STATE: webserver1;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: webserver1;Total Processes;OK;HARD;1;PROCS OK: 328 processes
[1596047400] CURRENT SERVICE STATE: webserver2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.05% system=0.04% iowait=0.00% idle=99.91%
[1596047400] CURRENT SERVICE STATE: webserver2;CPU_Procs;OK;HARD;1;CPU OK: 377 processes
[1596047400] CURRENT SERVICE STATE: webserver2;Current Load;OK;HARD;1;OK - load average: 0.00, 0.01, 0.05
[1596047400] CURRENT SERVICE STATE: webserver2;Current Users;OK;HARD;1;USERS OK - 13 users currently logged in
[1596047400] CURRENT SERVICE STATE: webserver2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 107561 MB (47.85% inode=100%):
[1596047400] CURRENT SERVICE STATE: webserver2;HTTP;OK;HARD;1;HTTP OK: HTTP/1.1 200 OK - 355 bytes in 0.001 second response time
[1596047400] CURRENT SERVICE STATE: webserver2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: webserver2;Memory;OK;HARD;1;OK - 52.7% (12917288 kB) free.
[1596047400] CURRENT SERVICE STATE: webserver2;Open-Files;OK;HARD;1;OK: 7680 open files (0% of max 2423406)
[1596047400] CURRENT SERVICE STATE: webserver2;PING;OK;HARD;1;PING OK - Packet loss = 0%, RTA = 0.10 ms
[1596047400] CURRENT SERVICE STATE: webserver2;Root Partition;OK;HARD;1;DISK OK - free space: / 14828 MB (28.97% inode=99%):
[1596047400] CURRENT SERVICE STATE: webserver2;SSH;OK;HARD;1;SSH OK - OpenSSH_7.4 (protocol 2.0)
[1596047400] CURRENT SERVICE STATE: webserver2;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: webserver2;Total Processes;OK;HARD;1;PROCS OK: 163 processes with STATE = RSZDT
[1596047400] CURRENT SERVICE STATE: webservercluster1;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.01, 0.05
[1596047400] CURRENT SERVICE STATE: webservercluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.66% system=0.06% iowait=0.00% idle=99.27%
[1596047400] CURRENT SERVICE STATE: webservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 318 processes
[1596047400] CURRENT SERVICE STATE: webservercluster1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1596047400] CURRENT SERVICE STATE: webservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: / 20061 MB (39% inode=99%):
[1596047400] CURRENT SERVICE STATE: webservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: /home 74881 MB (33% inode=99%):
[1596047400] CURRENT SERVICE STATE: webservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: webservercluster1;Memory;OK;HARD;1;OK - 42.8% (6956996 kB) free.
[1596047400] CURRENT SERVICE STATE: webservercluster1;Open-Files;OK;HARD;1;OK: 4544 open files (0% of max 1607067)
[1596047400] CURRENT SERVICE STATE: webservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: webservercluster1;Total Processes;OK;HARD;1;PROCS OK: 317 processes
[1596047400] CURRENT SERVICE STATE: webservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.35, 0.35, 0.41
[1596047400] CURRENT SERVICE STATE: webservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.28% system=0.40% iowait=0.39% idle=98.93%
[1596047400] CURRENT SERVICE STATE: webservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 286 processes
[1596047400] CURRENT SERVICE STATE: webservercluster2;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1596047400] CURRENT SERVICE STATE: webservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 223908 MB (99% inode=99%):
[1596047400] CURRENT SERVICE STATE: webservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39433 MB (77% inode=99%):
[1596047400] CURRENT SERVICE STATE: webservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596047400] CURRENT SERVICE STATE: webservercluster2;Memory;OK;HARD;1;OK - 66.7% (10842624 kB) free.
[1596047400] CURRENT SERVICE STATE: webservercluster2;Open-Files;OK;HARD;1;OK: 6816 open files (0% of max 1607066)
[1596047400] CURRENT SERVICE STATE: webservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1596047400] CURRENT SERVICE STATE: webservercluster2;Total Processes;OK;HARD;1;PROCS OK: 292 processes
[1596047530] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(715) < 182.18.184.244 [30/Jul/2020:00:02:09 +0530] TCP 502 0 0 0.002 "10.147.212.61:5500, 10.147.212.37:5500, 10.147.212.49:5500, 10.147.212.38:5500" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.001, 0.000"
[1596047531] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 55.73, 47.05, 42.09
[1596047531] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 55.73, 47.05, 42.09
[1596047926] SERVICE ALERT: sservercluster2;Memory;CRITICAL;SOFT;1;CRITICAL - 5.6% (1371004 kB) free!
[1596047980] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.8% (190644 kB) free!
[1596048046] SERVICE ALERT: sservercluster2;Memory;CRITICAL;SOFT;2;CRITICAL - 5.6% (1365084 kB) free!
[1596048101] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (192684 kB) free!
[1596048108] SERVICE ALERT: pservercluster2;Memory;CRITICAL;SOFT;1;CRITICAL - 2.9% (718020 kB) free!
[1596048131] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;WARNING;notify-service-by-email;WARNING - load average: 7.89, 30.17, 37.67
[1596048131] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 7.89, 30.17, 37.67
[1596048140] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:00:10:08 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1596048166] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.5% (1348548 kB) free!
[1596048166] SERVICE ALERT: sservercluster2;Memory;CRITICAL;HARD;3;CRITICAL - 5.5% (1348548 kB) free!
[1596048190] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/30 00:12:37 [error] 1820#0: *1806048 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596048221] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (182104 kB) free!
[1596048221] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.7% (182104 kB) free!
[1596048228] SERVICE ALERT: pservercluster2;Memory;CRITICAL;SOFT;2;CRITICAL - 2.9% (701804 kB) free!
[1596048348] SERVICE ALERT: pservercluster2;Memory;OK;HARD;1;OK - 90.2% (22118360 kB) free.
[1596048606] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (196600 kB) free!
[1596048766] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;OK;notify-service-by-email;OK - 88.1% (21592924 kB) free.
[1596048766] SERVICE ALERT: sservercluster2;Memory;OK;HARD;1;OK - 88.1% (21592924 kB) free.
[1596048877] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1435 processes
[1596049123] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 352 processes
[1596049124] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 774 processes
[1596049225] Auto-save of retention data completed successfully.
[1596049421] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;OK;notify-service-by-email;OK - 90.0% (22217948 kB) free.
[1596049421] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 90.0% (22217948 kB) free.
[1596049449] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 11.0% (5424520 kB) free!
[1596049609] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (215944 kB) free!
[1596049943] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2738276 kB) free!
[1596049991] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1596050531] SERVICE FLAPPING ALERT: mrq4;CPU Load;STARTED; Service appears to have started flapping (22.6% change >= 20.0% threshold)
[1596050531] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 61.07, 43.16, 39.05
[1596050633] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (226564 kB) free!
[1596051131] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 36.17, 40.33, 39.94
[1596051178] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(1868) < 2020/07/30 01:02:57 [error] 1786#0: *5553997 access forbidden by rule while initializing session, client: 103.209.99.7, server: 0.0.0.0:13000
[1596051368] SERVICE ALERT: webserver2;Memory;CRITICAL;SOFT;1;CRITICAL - 0.7% (171548 kB) free!
[1596051428] SERVICE ALERT: webserver2;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (184000 kB) free!
[1596051488] SERVICE ALERT: webserver2;Memory;OK;HARD;1;OK - 73.2% (17937152 kB) free.
[1596051730] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(715) < 182.18.184.244 [30/Jul/2020:01:12:09 +0530] TCP 502 0 0 0.002 "10.147.212.61:5501, 10.147.212.38:5501, 10.147.212.37:5501, 10.147.212.49:5501" "0, 0, 0, 0" "0, 0, 0, 0" "0.000, 0.001, 0.000, 0.001"
[1596051740] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:01:10:07 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1596051790] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/30 01:12:37 [error] 1822#0: *1819634 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596052206] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.9% (223684 kB) free!
[1596052331] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 47.28, 51.05, 46.60
[1596052477] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1436 processes
[1596052506] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 5.5% (1351016 kB) free!
[1596052626] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (184328 kB) free!
[1596052692] SERVICE ALERT: redis-1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.3% (397612 kB) free!
[1596052723] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 357 processes
[1596052747] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (175384 kB) free!
[1596052747] SERVICE ALERT: sservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.7% (175384 kB) free!
[1596052812] SERVICE ALERT: redis-1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.3% (458164 kB) free!
[1596052825] Auto-save of retention data completed successfully.
[1596052918] SERVICE ALERT: smscapp2;Memory;CRITICAL;SOFT;1;CRITICAL - 0.5% (236596 kB) free!
[1596052931] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 44.62, 41.96, 43.17
[1596052932] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.3% (401880 kB) free!
[1596052932] SERVICE ALERT: redis-1;Memory;CRITICAL;HARD;3;CRITICAL - 0.3% (401880 kB) free!
[1596053038] SERVICE ALERT: smscapp2;Memory;CRITICAL;SOFT;2;CRITICAL - 0.4% (221052 kB) free!
[1596053050] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 10.7% (5294312 kB) free!
[1596053158] SERVICE NOTIFICATION: nagiosadmin;smscapp2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (244940 kB) free!
[1596053158] SERVICE ALERT: smscapp2;Memory;CRITICAL;HARD;3;CRITICAL - 0.5% (244940 kB) free!
[1596053209] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (215360 kB) free!
[1596053323] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 769 processes
[1596053347] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;OK;notify-service-by-email;OK - 23.8% (5830020 kB) free.
[1596053347] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 23.8% (5830020 kB) free.
[1596053531] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 43.59, 46.05, 45.49
[1596053543] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2737632 kB) free!
[1596053592] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1020 processes
[1596054547] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.7% (169460 kB) free!
[1596054667] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 9.6% (2362780 kB) free!
[1596054778] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(1866) < 2020/07/30 02:02:55 [error] 1786#0: *5593074 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "backend_5002", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596054787] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (184000 kB) free!
[1596054787] SERVICE ALERT: sservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (184000 kB) free!
[1596054832] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (221920 kB) free!
[1596054958] SERVICE NOTIFICATION: nagiosadmin;smscapp2;Memory;OK;notify-service-by-email;OK - 35.6% (17563108 kB) free.
[1596054958] SERVICE ALERT: smscapp2;Memory;OK;HARD;1;OK - 35.6% (17563108 kB) free.
[1596055340] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:02:10:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596055390] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/30 02:12:37 [error] 1811#0: *1833204 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596055806] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (193584 kB) free!
[1596055929] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(715) < 182.18.184.244 [30/Jul/2020:02:22:08 +0530] TCP 502 0 0 0.004 "10.147.212.61:5501, 10.147.212.38:5501, 10.147.212.37:5501, 10.147.212.49:5501" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.001, 0.002"
[1596056077] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1435 processes
[1596056323] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 352 processes
[1596056425] Auto-save of retention data completed successfully.
[1596056532] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (633728 kB) free!
[1596056588] SERVICE FLAPPING ALERT: sservercluster1;Memory;STARTED; Service appears to have started flapping (23.2% change >= 20.0% threshold)
[1596056588] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 60.4% (14793732 kB) free.
[1596056649] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;OK;notify-service-by-email;OK - 72.5% (35711788 kB) free.
[1596056649] SERVICE ALERT: qservercluster2;Memory;OK;HARD;1;OK - 72.5% (35711788 kB) free.
[1596056809] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (220152 kB) free!
[1596056923] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 769 processes
[1596057143] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2738892 kB) free!
[1596057188] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 1.3% (312852 kB) free!
[1596057193] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1033 processes
[1596057233] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;OK;notify-service-by-email;OK - 82.5% (40642448 kB) free.
[1596057233] SERVICE ALERT: smscapp1;Memory;OK;HARD;1;OK - 82.5% (40642448 kB) free.
[1596057308] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 87.0% (21314716 kB) free.
[1596058331] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 30.10, 35.66, 41.56
[1596058378] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(1894) < 2020/07/30 03:02:56 [error] 1785#0: *5632541 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "backend_5002", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596058931] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 49.13, 57.87, 52.31
[1596058941] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:03:10:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596058991] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/30 03:12:37 [error] 1813#0: *1846806 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596059406] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (205612 kB) free!
[1596059529] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(714) < 182.18.184.244 [30/Jul/2020:03:22:08 +0530] TCP 502 0 0 0.002 "10.147.212.37:5500, 10.147.212.61:5500, 10.147.212.49:5500, 10.147.212.38:5500" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.001, 0.000"
[1596059678] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1436 processes
[1596059923] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 354 processes
[1596060025] Auto-save of retention data completed successfully.
[1596060131] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 36.45, 38.65, 43.54
[1596060132] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (694152 kB) free!
[1596060409] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (235116 kB) free!
[1596060523] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 769 processes
[1596060731] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 54.41, 49.67, 45.96
[1596060743] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2735628 kB) free!
[1596060752] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;SOFT;1;CRITICAL - load average: 16221.47, 13332.50, 6909.18
[1596060790] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1596060790] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1596060872] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;SOFT;2;CRITICAL - load average: 16223.75, 14289.26, 8038.60
[1596060992] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 16224.29, 14929.51, 9031.11
[1596060992] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 16224.29, 14929.51, 9031.11
[1596061390] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(4) < 2020/07/30 03:52:37 [error] 1811#0: *1855874 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596061392] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1020 processes
[1596061510] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(1) < 2020/07/30 03:55:07 [error] 1824#0: *1856449 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596061630] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1596062231] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(4) < 2020/07/30 04:05:07 [error] 1824#0: *1858712 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596062351] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(1) < 2020/07/30 04:07:37 [error] 1824#0: *1859276 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596062471] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(1) < 2020/07/30 04:10:07 [error] 1824#0: *1859857 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596062471] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;HARD;3;(1) < 2020/07/30 04:10:07 [error] 1824#0: *1859857 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596062578] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(1866) < 2020/07/30 04:12:56 [error] 1786#0: *5668058 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "backend_5002", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596063006] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.9% (230076 kB) free!
[1596063129] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(713) < 182.18.184.244 [30/Jul/2020:04:22:09 +0530] TCP 502 0 0 0.000 "backend_5000" "0" "0" "0.000"
[1596063140] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:04:20:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596063523] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 352 processes
[1596063625] Auto-save of retention data completed successfully.
[1596063731] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 33.88, 41.28, 43.40
[1596063732] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.6% (815172 kB) free!
[1596063877] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1437 processes
[1596063992] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU Load;OK;notify-service-by-email;OK - load average: 1.12, 2.31, 464.49
[1596063992] SERVICE ALERT: sservercluster1;CPU Load;OK;HARD;1;OK - load average: 1.12, 2.31, 464.49
[1596064009] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (252608 kB) free!
[1596064124] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 769 processes
[1596064331] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 46.66, 52.32, 47.84
[1596064343] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2738076 kB) free!
[1596064931] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 29.81, 36.69, 42.29
[1596064992] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1596065108] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.8% (194240 kB) free!
[1596065228] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.7% (168096 kB) free!
[1596065348] SERVICE ALERT: sservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (207944 kB) free!
[1596065949] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 87.9% (21535480 kB) free.
[1596066072] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/30 05:10:07 [error] 1824#0: *1873471 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596066131] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 36.11, 46.28, 46.68
[1596066606] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (195052 kB) free!
[1596066729] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(716) < 182.18.184.244 [30/Jul/2020:05:22:09 +0530] TCP 502 0 0 0.002 "10.147.212.61:5501, 10.147.212.38:5501, 10.147.212.49:5501, 10.147.212.37:5501" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.001, 0.000"
[1596066740] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:05:20:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596066777] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(1933) < 2020/07/30 05:22:56 [error] 1787#0: *5714263 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "10.147.212.49:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596067123] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 356 processes
[1596067225] Auto-save of retention data completed successfully.
[1596067332] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (857820 kB) free!
[1596067477] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1436 processes
[1596067609] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (218172 kB) free!
[1596067943] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2736932 kB) free!
[1596068323] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 769 processes
[1596068592] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1023 processes
[1596069640] SERVICE ALERT: webservercluster1;CPU_Procs;CRITICAL;SOFT;1;CPU CRITICAL: 1 crit, 0 warn out of 324 processes
[1596069760] SERVICE ALERT: webservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 321 processes
[1596070206] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (182180 kB) free!
[1596070271] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/30 06:20:07 [error] 1824#0: *1889336 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596070329] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(714) < 182.18.184.244 [30/Jul/2020:06:22:06 +0530] TCP 502 0 0 0.000 "backend_5002" "0" "0" "0.000"
[1596070340] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:06:20:07 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1596070377] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(1817) < 2020/07/30 06:22:57 [error] 1786#0: *5753409 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "backend_5002", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596070723] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 355 processes
[1596070825] Auto-save of retention data completed successfully.
[1596070932] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.3% (442416 kB) free!
[1596070961] SERVICE ALERT: webservercluster1;CPU_Procs;CRITICAL;SOFT;1;CPU CRITICAL: 1 crit, 0 warn out of 321 processes
[1596071077] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1437 processes
[1596071081] SERVICE ALERT: webservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 319 processes
[1596071175] SERVICE ALERT: webservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 1.2% (188140 kB) free!
[1596071209] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (220532 kB) free!
[1596071296] SERVICE ALERT: webservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 1.1% (185676 kB) free!
[1596071349] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.7% (175644 kB) free!
[1596071416] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.1% (182380 kB) free!
[1596071416] SERVICE ALERT: webservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 1.1% (182380 kB) free!
[1596071469] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (203624 kB) free!
[1596071544] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2736476 kB) free!
[1596071589] SERVICE ALERT: sservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (186176 kB) free!
[1596071923] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 771 processes
[1596072016] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Memory;OK;notify-service-by-email;OK - 60.6% (9848504 kB) free.
[1596072016] SERVICE ALERT: webservercluster1;Memory;OK;HARD;1;OK - 60.6% (9848504 kB) free.
[1596072189] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 85.5% (20960988 kB) free.
[1596072192] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1023 processes
[1596072732] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;OK;notify-service-by-email;OK - 50.2% (66176964 kB) free.
[1596072732] SERVICE ALERT: redis-1;Memory;OK;HARD;1;OK - 50.2% (66176964 kB) free.
[1596073806] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (186780 kB) free!
[1596073871] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/30 07:20:07 [error] 1824#0: *1903040 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596073930] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(715) < 182.18.184.244 [30/Jul/2020:07:22:09 +0530] TCP 502 0 0 0.000 "backend_5001" "0" "0" "0.000"
[1596073940] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:07:20:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596073977] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(1885) < 2020/07/30 07:22:56 [error] 1789#0: *5792575 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "10.147.212.37:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596074081] SERVICE ALERT: webservercluster1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 320 processes
[1596074201] SERVICE ALERT: webservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 318 processes
[1596074323] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 352 processes
[1596074425] Auto-save of retention data completed successfully.
[1596074677] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1637 processes
[1596074809] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (217120 kB) free!
[1596075523] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 768 processes
[1596075743] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.5% (2733740 kB) free!
[1596075792] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1596076931] SERVICE FLAPPING ALERT: mrq4;CPU Load;STOPPED; Service appears to have stopped flapping (3.9% change < 5.0% threshold)
[1596076931] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 68.58, 71.94, 68.60
[1596077406] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (184608 kB) free!
[1596077471] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(41) < 2020/07/30 08:20:07 [error] 1821#0: *1911642 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596077540] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:08:20:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596077577] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(1852) < 2020/07/30 08:22:57 [error] 1786#0: *5831495 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "10.147.212.37:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596077923] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 351 processes
[1596078025] Auto-save of retention data completed successfully.
[1596078129] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(241) < 182.18.184.244 [30/Jul/2020:08:25:31 +0530] TCP 502 0 0 0.002 "10.147.212.61:5500, 10.147.212.49:5500, 10.147.212.38:5500, 10.147.212.37:5500" "0, 0, 0, 0" "0, 0, 0, 0" "0.000, 0.001, 0.000, 0.001"
[1596078277] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1644 processes
[1596078409] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (246920 kB) free!
[1596079124] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 773 processes
[1596079343] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2744348 kB) free!
[1596079393] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1023 processes
[1596080097] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;SOFT;1;CRITICAL - load average: 10736.72, 3172.07, 1097.48
[1596080217] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;SOFT;2;CRITICAL - load average: 15475.47, 7487.49, 2930.41
[1596080337] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 16112.60, 10374.15, 4540.77
[1596080337] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 16112.60, 10374.15, 4540.77
[1596080531] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 73.02, 76.73, 79.77
[1596081006] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (187392 kB) free!
[1596081071] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/30 09:20:07 [error] 1819#0: *1926358 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596081140] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:09:20:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596081177] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(5299) < 2020/07/30 09:22:55 [error] 1785#0: *5874492 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "backend_5003", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596081523] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 356 processes
[1596081625] Auto-save of retention data completed successfully.
[1596081730] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(2499) < 182.18.184.244 [30/Jul/2020:09:32:08 +0530] TCP 502 0 0 0.000 "backend_5003" "0" "0" "0.000"
[1596081877] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1636 processes
[1596082009] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (219396 kB) free!
[1596082724] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 769 processes
[1596082943] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2746260 kB) free!
[1596083337] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU Load;WARNING;notify-service-by-email;WARNING - load average: 1.16, 4.51, 630.98
[1596083337] SERVICE ALERT: sservercluster2;CPU Load;WARNING;HARD;3;WARNING - load average: 1.16, 4.51, 630.98
[1596083589] SERVICE FLAPPING ALERT: sservercluster1;Memory;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1596083592] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1022 processes
[1596083937] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU Load;OK;notify-service-by-email;OK - load average: 0.54, 1.28, 331.04
[1596083937] SERVICE ALERT: sservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.54, 1.28, 331.04
[1596084131] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 116.78, 88.67, 82.85
[1596084606] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (186424 kB) free!
[1596084671] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/30 10:20:07 [error] 1824#0: *1943930 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596084740] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:10:20:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596084778] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(5440) < 2020/07/30 10:22:57 [error] 1785#0: *5938604 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "backend_5002", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596085123] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 354 processes
[1596085225] Auto-save of retention data completed successfully.
[1596085478] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1637 processes
[1596085609] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (240932 kB) free!
[1596085930] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(2505) < 182.18.184.244 [30/Jul/2020:10:42:10 +0530] TCP 502 0 0 0.002 "10.147.212.61:5500, 10.147.212.49:5500, 10.147.212.38:5500, 10.147.212.37:5500" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.001, 0.000"
[1596086324] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 770 processes
[1596086543] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2747088 kB) free!
[1596087192] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1025 processes
[1596087731] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 75.47, 88.70, 89.76
[1596088206] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (189028 kB) free!
[1596088271] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/30 11:20:08 [error] 1823#0: *1961438 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596088340] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:11:20:08 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596088723] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 353 processes
[1596088825] Auto-save of retention data completed successfully.
[1596088978] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(5574) < 2020/07/30 11:32:57 [error] 1790#0: *6012904 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "backend_5002", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596089209] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (234832 kB) free!
[1596089530] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(2493) < 182.18.184.244 [30/Jul/2020:11:42:09 +0530] TCP 502 0 0 0.000 "backend_5000" "0" "0" "0.000"
[1596089677] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1636 processes
[1596089924] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 769 processes
[1596090143] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.5% (2726620 kB) free!
[1596090793] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1596091331] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 82.92, 83.21, 86.07
[1596091806] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (198264 kB) free!
[1596091871] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/30 12:20:07 [error] 1822#0: *1978864 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596091940] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:12:20:07 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1596092323] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 352 processes
[1596092425] Auto-save of retention data completed successfully.
[1596092578] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(5257) < 2020/07/30 12:32:56 [error] 1785#0: *6075973 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "backend_5003", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596092809] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (242776 kB) free!
[1596093130] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(2379) < 182.18.184.244 [30/Jul/2020:12:42:09 +0530] TCP 502 0 0 0.000 "backend_5000" "0" "0" "0.000"
[1596093277] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1637 processes
[1596093522] SERVICE ALERT: sservercluster2;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 326 processes
[1596093643] SERVICE ALERT: sservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 323 processes
[1596093743] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.5% (2731640 kB) free!
[1596094001] SERVICE ALERT: webservercluster1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 2 warn out of 322 processes
[1596094121] SERVICE ALERT: webservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 323 processes
[1596094123] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 774 processes
[1596094931] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 129.65, 101.36, 95.35
[1596094992] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1027 processes
[1596095406] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.9% (217884 kB) free!
[1596095471] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(247) < 2020/07/30 13:21:09 [error] 1824#0: *2000757 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596095540] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:13:20:07 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1596095923] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 355 processes
[1596096025] Auto-save of retention data completed successfully.
[1596096178] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(5198) < 2020/07/30 13:32:56 [error] 1786#0: *6135002 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "backend_5003", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596096409] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (220448 kB) free!
[1596096730] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(2450) < 182.18.184.244 [30/Jul/2020:13:42:09 +0530] TCP 502 0 0 0.002 "10.147.212.61:5500, 10.147.212.38:5500, 10.147.212.37:5500, 10.147.212.49:5500" "0, 0, 0, 0" "0, 0, 0, 0" "0.000, 0.001, 0.000, 0.001"
[1596096877] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1641 processes
[1596097343] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.5% (2733392 kB) free!
[1596097723] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 775 processes
[1596098531] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 97.41, 91.33, 93.50
[1596098592] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1596099006] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (187516 kB) free!
[1596099069] SERVICE ALERT: pservercluster2;Total Processes;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099071] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(224) < 2020/07/30 14:20:50 [error] 1812#0: *2022356 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596099117] SERVICE ALERT: pservercluster2;zombie_procs;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1596099140] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:14:20:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596099149] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099161] SERVICE ALERT: pservercluster2;HDD_Home status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099199] SERVICE ALERT: pservercluster2;Total Processes;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099199] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099247] SERVICE ALERT: pservercluster2;zombie_procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099279] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099291] SERVICE ALERT: pservercluster2;HDD_Home status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099302] SERVICE ALERT: pservercluster2;Current Users;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099308] SERVICE ALERT: pservercluster2;CPU_Procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099318] SERVICE ALERT: pservercluster1;CPU Load;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099329] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Total Processes;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099329] SERVICE ALERT: pservercluster2;Total Processes;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099329] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;SOFT;2;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099329] SERVICE ALERT: pservercluster2;Open-Files;CRITICAL;SOFT;1;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099334] SERVICE ALERT: pservercluster2;Sensors Status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099338] SERVICE ALERT: pservercluster2;HDD_Root status;CRITICAL;SOFT;1;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099344] SERVICE ALERT: pservercluster2;CPU-STATISTICS;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099366] SERVICE ALERT: pservercluster1;HDD_Root status;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1596099367] SERVICE ALERT: pservercluster2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596099370] SERVICE ALERT: pservercluster1;HDD_Home status;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1596099371] SERVICE ALERT: pservercluster1;Messages Log Status;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1596099384] SERVICE ALERT: pservercluster2;Messages Log Status;CRITICAL;SOFT;1;(81) < Jul 30 14:25:44 pservercluster2 xinetd[1483]: nrpe: fork failed: Cannot allocate memory (errno = 12)
[1596099399] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596099411] SERVICE ALERT: pservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 178568 MB (79% inode=99%):
[1596099422] SERVICE ALERT: pservercluster2;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1596099428] SERVICE ALERT: pservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 332 processes
[1596099433] SERVICE ALERT: pservercluster1;CPU-STATISTICS;CRITICAL;SOFT;1;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099443] SERVICE ALERT: pservercluster1;CPU Load;CRITICAL;SOFT;2;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099449] SERVICE ALERT: pservercluster1;Open-Files;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1596099449] SERVICE ALERT: pservercluster2;CPU Load;OK;HARD;1;OK - load average: 87.96, 69.40, 29.05
[1596099449] SERVICE ALERT: pservercluster2;Open-Files;OK;HARD;1;OK: 9440 open files (0% of max 2424156)
[1596099453] SERVICE ALERT: pservercluster1;Sensors Status;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1596099454] SERVICE ALERT: pservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1596099455] SERVICE ALERT: pservercluster1;CPU_Procs;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1596099458] SERVICE ALERT: pservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 38285 MB (74% inode=98%):
[1596099469] SERVICE ALERT: pservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=2.46% system=6.27% iowait=0.00% idle=91.27%
[1596099490] SERVICE ALERT: pservercluster1;HDD_Home status;CRITICAL;SOFT;2;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099491] SERVICE ALERT: pservercluster1;HDD_Root status;CRITICAL;SOFT;2;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099491] SERVICE ALERT: pservercluster1;Messages Log Status;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1596099504] SERVICE ALERT: pservercluster2;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1596099524] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 356 processes
[1596099558] SERVICE ALERT: pservercluster1;CPU-STATISTICS;CRITICAL;SOFT;2;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099568] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU Load;CRITICAL;notify-service-by-email;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099568] SERVICE ALERT: pservercluster1;CPU Load;CRITICAL;HARD;3;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099573] SERVICE ALERT: pservercluster1;Sensors Status;CRITICAL;SOFT;2;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099574] SERVICE ALERT: pservercluster1;Open-Files;CRITICAL;SOFT;2;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099580] SERVICE ALERT: pservercluster1;CPU_Procs;CRITICAL;SOFT;2;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099611] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;HDD_Root status;CRITICAL;notify-service-by-email;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099611] SERVICE ALERT: pservercluster1;HDD_Root status;CRITICAL;HARD;3;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099611] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Messages Log Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099611] SERVICE ALERT: pservercluster1;Messages Log Status;CRITICAL;HARD;3;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099615] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;HDD_Home status;CRITICAL;notify-service-by-email;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099615] SERVICE ALERT: pservercluster1;HDD_Home status;CRITICAL;HARD;3;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099625] Auto-save of retention data completed successfully.
[1596099652] SERVICE ALERT: pservercluster1;Total Processes;CRITICAL;SOFT;1;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099653] SERVICE ALERT: sservercluster2;Sensors Status;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1596099669] SERVICE ALERT: pservercluster1;Current Users;CRITICAL;SOFT;1;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099683] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU-STATISTICS;CRITICAL;notify-service-by-email;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099683] SERVICE ALERT: pservercluster1;CPU-STATISTICS;CRITICAL;HARD;3;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099689] SERVICE ALERT: pservercluster1;LocalService-NTPD SERVICE;CRITICAL;SOFT;1;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099693] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Sensors Status;WARNING;notify-service-by-email;NRPE: Unable to read output
[1596099693] SERVICE ALERT: pservercluster1;Sensors Status;WARNING;HARD;3;NRPE: Unable to read output
[1596099694] SERVICE ALERT: pservercluster1;Open-Files;OK;HARD;1;OK: 8672 open files (0% of max 2440681)
[1596099700] SERVICE ALERT: pservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 329 processes
[1596099720] SERVICE ALERT: sservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099727] SERVICE ALERT: sservercluster2;Open-Files;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099727] SERVICE ALERT: sservercluster2;Total Processes;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099766] SERVICE ALERT: sservercluster2;Memory;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1596099777] SERVICE ALERT: pservercluster1;Total Processes;CRITICAL;SOFT;2;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099778] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(5680) < 2020/07/30 14:32:57 [error] 1786#0: *6190464 access forbidden by rule while initializing session, client: 103.209.99.7, server: 0.0.0.0:13000
[1596099783] SERVICE ALERT: sservercluster2;Sensors Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099789] SERVICE ALERT: pservercluster1;Current Users;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1596099810] SERVICE ALERT: pservercluster1;LocalService-NTPD SERVICE;CRITICAL;SOFT;2;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099812] SERVICE ALERT: pservercluster1;zombie_procs;CRITICAL;SOFT;1;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099827] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;1;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099850] SERVICE ALERT: sservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099857] SERVICE ALERT: sservercluster2;Open-Files;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099857] SERVICE ALERT: sservercluster2;Total Processes;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099896] SERVICE ALERT: sservercluster2;Memory;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099897] SERVICE ALERT: pservercluster1;Total Processes;OK;HARD;1;PROCS OK: 329 processes
[1596099902] SERVICE ALERT: sservercluster2;Messages Log Status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099903] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Sensors Status;UNKNOWN;notify-service-by-email;NRPE: Call to fork() failed
[1596099903] SERVICE ALERT: sservercluster2;Sensors Status;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1596099909] SERVICE ALERT: pservercluster1;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1596099929] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Total Processes;OK;notify-service-by-email;PROCS OK: 331 processes
[1596099929] SERVICE ALERT: pservercluster2;Total Processes;OK;HARD;1;PROCS OK: 331 processes
[1596099930] SERVICE ALERT: pservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596099932] SERVICE ALERT: pservercluster1;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596099933] SERVICE ALERT: sservercluster2;Current Users;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099947] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 64.0% (15800980 kB) free.
[1596099973] SERVICE ALERT: sservercluster2;HDD_Home status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099978] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Open-Files;CRITICAL;notify-service-by-email;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099978] SERVICE ALERT: sservercluster2;Open-Files;CRITICAL;HARD;3;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099978] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;LocalService-NTPD SERVICE;CRITICAL;notify-service-by-email;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099978] SERVICE ALERT: sservercluster2;LocalService-NTPD SERVICE;CRITICAL;HARD;3;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596099987] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Total Processes;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596099987] SERVICE ALERT: sservercluster2;Total Processes;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100010] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (235816 kB) free!
[1596100022] SERVICE ALERT: sservercluster2;Messages Log Status;CRITICAL;SOFT;2;NRPE: Call to popen() failed
[1596100025] SERVICE ALERT: sservercluster2;HDD_Root status;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1596100026] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100026] SERVICE ALERT: sservercluster2;Memory;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100063] SERVICE ALERT: sservercluster2;Current Users;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100103] SERVICE ALERT: sservercluster2;HDD_Home status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100118] SERVICE ALERT: sservercluster2;CPU-STATISTICS;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100137] SERVICE ALERT: sservercluster2;zombie_procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100147] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100148] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Messages Log Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596100148] SERVICE ALERT: sservercluster2;Messages Log Status;CRITICAL;HARD;3;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596100155] SERVICE ALERT: sservercluster2;HDD_Root status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100193] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Current Users;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100193] SERVICE ALERT: sservercluster2;Current Users;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100211] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;HDD_Root status;OK;notify-service-by-email;DISK OK - free space: / 39508 MB (77% inode=99%):
[1596100211] SERVICE ALERT: pservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39508 MB (77% inode=99%):
[1596100215] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;HDD_Home status;OK;notify-service-by-email;DISK OK - free space: /home 186982 MB (84% inode=99%):
[1596100215] SERVICE ALERT: pservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 186982 MB (84% inode=99%):
[1596100233] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;HDD_Home status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100233] SERVICE ALERT: sservercluster2;HDD_Home status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100248] SERVICE ALERT: sservercluster2;CPU-STATISTICS;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100252] SERVICE ALERT: sservercluster2;CPU_Procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100257] SERVICE ALERT: sservercluster2;zombie_procs;CRITICAL;SOFT;2;NRPE: Call to popen() failed
[1596100277] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100285] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;HDD_Root status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100285] SERVICE ALERT: sservercluster2;HDD_Root status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100288] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU-STATISTICS;OK;notify-service-by-email;CPU STATISTICS OK: user=1.87% system=5.66% iowait=0.00% idle=92.47%
[1596100288] SERVICE ALERT: pservercluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.87% system=5.66% iowait=0.00% idle=92.47%
[1596100293] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Sensors Status;OK;notify-service-by-email;SENSORS OK
[1596100293] SERVICE ALERT: pservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1596100330] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(2503) < 182.18.184.244 [30/Jul/2020:14:42:09 +0530] TCP 502 0 0 0.000 "backend_5003" "0" "0" "0.000"
[1596100378] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU-STATISTICS;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100378] SERVICE ALERT: sservercluster2;CPU-STATISTICS;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100382] SERVICE ALERT: sservercluster2;CPU_Procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100388] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;zombie_procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100388] SERVICE ALERT: sservercluster2;zombie_procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100407] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU Load;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100407] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100477] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1637 processes
[1596100512] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100512] SERVICE ALERT: sservercluster2;CPU_Procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100513] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Sensors Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100513] SERVICE ALERT: sservercluster2;Sensors Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596100811] SERVICE ALERT: pservercluster1;HDD_Root status;CRITICAL;SOFT;1;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596100931] SERVICE ALERT: pservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39508 MB (77% inode=99%):
[1596100943] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2743856 kB) free!
[1596101322] SERVICE ALERT: webservercluster1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 321 processes
[1596101323] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 773 processes
[1596101333] SERVICE ALERT: mrq4;Memory;WARNING;SOFT;1;WARNING - 19.5% (6394872 kB) free!
[1596101412] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Messages Log Status;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1596101412] SERVICE ALERT: pservercluster1;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1596101442] SERVICE ALERT: webservercluster1;CPU_Procs;WARNING;SOFT;2;CPU WARNING: 1 warn out of 319 processes
[1596101453] SERVICE ALERT: mrq4;Memory;OK;HARD;1;OK - 21.9% (7155472 kB) free.
[1596101562] SERVICE ALERT: webservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 320 processes
[1596102090] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;HDD_Root status;OK;notify-service-by-email;DISK OK - free space: / 33080 MB (64% inode=98%):
[1596102090] SERVICE ALERT: sservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 33080 MB (64% inode=98%):
[1596102131] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 86.44, 89.67, 87.55
[1596102183] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU-STATISTICS;OK;notify-service-by-email;CPU STATISTICS OK: user=2.88% system=7.26% iowait=0.03% idle=89.83%
[1596102183] SERVICE ALERT: sservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=2.88% system=7.26% iowait=0.03% idle=89.83%
[1596102188] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;zombie_procs;OK;notify-service-by-email;PROCS OK: 0 processes with STATE = Z
[1596102188] SERVICE ALERT: sservercluster2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596102193] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1596102207] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU Load;OK;notify-service-by-email;OK - load average: 2.13, 2.18, 2.09
[1596102207] SERVICE ALERT: sservercluster2;CPU Load;OK;HARD;1;OK - load average: 2.13, 2.18, 2.09
[1596102312] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;OK;notify-service-by-email;CPU OK: 325 processes
[1596102312] SERVICE ALERT: sservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 325 processes
[1596102313] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Sensors Status;OK;notify-service-by-email;SENSORS OK
[1596102313] SERVICE ALERT: sservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1596102378] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;LocalService-NTPD SERVICE;OK;notify-service-by-email;PROCS OK: 1 process with command name 'ntpd'
[1596102378] SERVICE ALERT: sservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596102378] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Open-Files;OK;notify-service-by-email;OK: 9856 open files (0% of max 2424092)
[1596102378] SERVICE ALERT: sservercluster2;Open-Files;OK;HARD;1;OK: 9856 open files (0% of max 2424092)
[1596102387] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Total Processes;OK;notify-service-by-email;PROCS OK: 325 processes
[1596102387] SERVICE ALERT: sservercluster2;Total Processes;OK;HARD;1;PROCS OK: 325 processes
[1596102426] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;OK;notify-service-by-email;OK - 79.7% (19546264 kB) free.
[1596102426] SERVICE ALERT: sservercluster2;Memory;OK;HARD;1;OK - 79.7% (19546264 kB) free.
[1596102594] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Current Users;OK;notify-service-by-email;USERS OK - 2 users currently logged in
[1596102594] SERVICE ALERT: sservercluster2;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1596102606] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (180944 kB) free!
[1596102633] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;HDD_Home status;OK;notify-service-by-email;DISK OK - free space: /home 189592 MB (85% inode=99%):
[1596102633] SERVICE ALERT: sservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 189592 MB (85% inode=99%):
[1596102671] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(552) < 2020/07/30 15:21:06 [error] 1814#0: *2029169 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596102693] SERVICE ALERT: pservercluster1;Sensors Status;CRITICAL;SOFT;1;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596102740] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:15:20:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596102807] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;SOFT;1;CRITICAL - load average: 9177.61, 2500.49, 851.73
[1596102813] SERVICE ALERT: pservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1596102927] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;SOFT;2;CRITICAL - load average: 15266.30, 7038.52, 2714.61
[1596103048] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 28015.22, 14066.75, 5769.11
[1596103048] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 28015.22, 14066.75, 5769.11
[1596103148] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Messages Log Status;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1596103148] SERVICE ALERT: sservercluster2;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1596103168] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU Load;OK;notify-service-by-email;OK - load average: 1.08, 1.36, 273.02
[1596103168] SERVICE ALERT: pservercluster1;CPU Load;OK;HARD;1;OK - load average: 1.08, 1.36, 273.02
[1596103225] Auto-save of retention data completed successfully.
[1596103253] SERVICE ALERT: mrq4;Memory;WARNING;SOFT;1;WARNING - 19.5% (6381644 kB) free!
[1596103373] SERVICE ALERT: mrq4;Memory;WARNING;SOFT;2;WARNING - 19.2% (6300864 kB) free!
[1596103378] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(5289) < 2020/07/30 15:32:57 [error] 1788#0: *6231509 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5001, upstream: "10.147.212.37:5500", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596103493] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;WARNING;notify-service-by-email;WARNING - 19.1% (6244732 kB) free!
[1596103493] SERVICE ALERT: mrq4;Memory;WARNING;HARD;3;WARNING - 19.1% (6244732 kB) free!
[1596103610] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (247244 kB) free!
[1596103723] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 349 processes
[1596104077] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1640 processes
[1596104529] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(2162) < 182.18.184.244 [30/Jul/2020:15:52:09 +0530] TCP 502 0 0 0.000 "backend_5001" "0" "0" "0.000"
[1596104543] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2741572 kB) free!
[1596104923] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 774 processes
[1596105731] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 60.52, 70.58, 75.21
[1596106206] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (182404 kB) free!
[1596106271] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(234) < 2020/07/30 16:21:09 [error] 1817#0: *2049325 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596106340] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:16:20:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596106392] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1022 processes
[1596106648] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 1.73, 3.82, 903.34
[1596106825] Auto-save of retention data completed successfully.
[1596107094] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;WARNING;notify-service-by-email;WARNING - 16.7% (5460600 kB) free!
[1596107112] SERVICE ALERT: sservercluster2;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 327 processes
[1596107211] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (267124 kB) free!
[1596107232] SERVICE ALERT: sservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 327 processes
[1596107248] SERVICE FLAPPING ALERT: sservercluster2;CPU Load;STARTED; Service appears to have started flapping (21.6% change >= 20.0% threshold)
[1596107248] SERVICE ALERT: sservercluster2;CPU Load;OK;HARD;1;OK - load average: 1.64, 2.28, 474.33
[1596107323] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 349 processes
[1596107578] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4951) < 2020/07/30 16:42:58 [error] 1785#0: *6297817 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5000, upstream: "backend_5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596107677] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1637 processes
[1596108130] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(2151) < 182.18.184.244 [30/Jul/2020:16:52:09 +0530] TCP 502 0 0 0.002 "10.147.212.37:5501, 10.147.212.38:5501, 10.147.212.49:5501, 10.147.212.61:5501" "0, 0, 0, 0" "0, 0, 0, 0" "0.000, 0.000, 0.001, 0.001"
[1596108143] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2756432 kB) free!
[1596108523] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 774 processes
[1596109332] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 78.74, 77.12, 80.48
[1596109433] SERVICE ALERT: smscapp1;Memory;WARNING;SOFT;1;WARNING - 19.8% (9757676 kB) free!
[1596109553] SERVICE ALERT: smscapp1;Memory;WARNING;SOFT;2;WARNING - 19.7% (9687632 kB) free!
[1596109673] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;WARNING;notify-service-by-email;WARNING - 19.4% (9579960 kB) free!
[1596109673] SERVICE ALERT: smscapp1;Memory;WARNING;HARD;3;WARNING - 19.4% (9579960 kB) free!
[1596109806] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (185784 kB) free!
[1596109871] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(236) < 2020/07/30 17:21:07 [error] 1810#0: *2072538 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596109940] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:17:20:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596109992] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1024 processes
[1596110425] Auto-save of retention data completed successfully.
[1596110923] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 350 processes
[1596110999] SERVICE ALERT: sigqscluster2;sigqscluster2-rabbitmqerror;CRITICAL;SOFT;1;(1) < Channel error on connection <0.24959.112> (10.147.212.53:42864 -> 10.147.212.55:5672, vhost: '/', user: 'guest'), channel 1:
[1596111119] SERVICE ALERT: sigqscluster2;sigqscluster2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1596111178] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4924) < 2020/07/30 17:42:57 [error] 1784#0: *6354180 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "10.147.212.49:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596111277] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1639 processes
[1596111293] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;WARNING;notify-service-by-email;WARNING - 14.1% (4602532 kB) free!
[1596111410] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.6% (318344 kB) free!
[1596111743] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2759684 kB) free!
[1596112123] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 777 processes
[1596112330] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(2267) < 182.18.184.244 [30/Jul/2020:18:02:09 +0530] TCP 502 0 0 0.001 "10.147.212.61:5501, 10.147.212.49:5501, 10.147.212.38:5501, 10.147.212.37:5501" "0, 0, 0, 0" "0, 0, 0, 0" "0.000, 0.001, 0.000, 0.000"
[1596112632] SERVICE ALERT: sservercluster2;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 325 processes
[1596112753] SERVICE ALERT: sservercluster2;CPU_Procs;WARNING;SOFT;2;CPU WARNING: 1 warn out of 327 processes
[1596112873] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 327 processes
[1596112873] SERVICE ALERT: sservercluster2;CPU_Procs;WARNING;HARD;3;CPU WARNING: 1 warn out of 327 processes
[1596113273] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;WARNING;notify-service-by-email;WARNING - 13.6% (6717572 kB) free!
[1596113406] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (202664 kB) free!
[1596113471] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(234) < 2020/07/30 18:21:09 [error] 4361#0: *2095014 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596113531] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 80.00, 85.91, 86.80
[1596113540] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:18:20:08 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1596113593] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1022 processes
[1596114025] Auto-save of retention data completed successfully.
[1596114523] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 349 processes
[1596114778] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2556) < 2020/07/30 18:42:57 [error] 1847#0: *6407974 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5001, upstream: "10.147.212.49:5500", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596114877] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1636 processes
[1596114893] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;WARNING;notify-service-by-email;WARNING - 11.1% (3628504 kB) free!
[1596115010] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (242060 kB) free!
[1596115048] SERVICE FLAPPING ALERT: sservercluster2;CPU Load;STOPPED; Service appears to have stopped flapping (4.5% change < 5.0% threshold)
[1596115273] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;OK;notify-service-by-email;CPU OK: 325 processes
[1596115273] SERVICE ALERT: sservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 325 processes
[1596115343] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2758300 kB) free!
[1596115723] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 777 processes
[1596115873] SERVICE ALERT: sservercluster2;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 339 processes
[1596115993] SERVICE ALERT: sservercluster2;CPU_Procs;WARNING;SOFT;2;CPU WARNING: 1 warn out of 333 processes
[1596116113] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 326 processes
[1596116113] SERVICE ALERT: sservercluster2;CPU_Procs;WARNING;HARD;3;CPU WARNING: 1 warn out of 326 processes
[1596116273] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 9.8% (4819828 kB) free!
[1596116273] SERVICE ALERT: smscapp1;Memory;CRITICAL;HARD;3;CRITICAL - 9.8% (4819828 kB) free!
[1596116529] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(2262) < 182.18.184.244 [30/Jul/2020:19:12:09 +0530] TCP 502 0 0 0.000 "10.147.212.49:5500" "0" "0" "0.000"
[1596117006] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (200624 kB) free!
[1596117071] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(240) < 2020/07/30 19:21:09 [error] 4363#0: *2117490 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596117131] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 89.80, 76.47, 76.29
[1596117140] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:19:20:07 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1596117163] SERVICE ALERT: webservercluster1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 320 processes
[1596117283] SERVICE ALERT: webservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 321 processes
[1596117625] Auto-save of retention data completed successfully.
[1596117792] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1596118123] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 348 processes
[1596118378] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2529) < 2020/07/30 19:42:57 [error] 1848#0: *6458051 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "10.147.212.49:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596118477] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1636 processes
[1596118494] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;WARNING;notify-service-by-email;WARNING - 10.2% (3354360 kB) free!
[1596118610] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (233216 kB) free!
[1596118943] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.5% (2719960 kB) free!
[1596119093] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;CRITICAL;notify-service-by-email;CRITICAL - 9.9% (3248120 kB) free!
[1596119093] SERVICE ALERT: mrq4;Memory;CRITICAL;HARD;3;CRITICAL - 9.9% (3248120 kB) free!
[1596119323] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 779 processes
[1596119693] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;WARNING;notify-service-by-email;WARNING - 10.8% (3534388 kB) free!
[1596119693] SERVICE ALERT: mrq4;Memory;WARNING;HARD;3;WARNING - 10.8% (3534388 kB) free!
[1596119713] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 325 processes
[1596119873] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.7% (3302520 kB) free!
[1596120129] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(2254) < 182.18.184.244 [30/Jul/2020:20:12:08 +0530] TCP 502 0 0 0.000 "10.147.212.49:5500" "0" "0" "0.000"
[1596120606] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (190560 kB) free!
[1596120671] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(219) < 2020/07/30 20:21:09 [error] 4371#0: *2140378 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596120731] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 103.65, 77.48, 73.53
[1596120740] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:20:20:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596120893] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;CRITICAL;notify-service-by-email;CRITICAL - 10.0% (3287292 kB) free!
[1596120893] SERVICE ALERT: mrq4;Memory;CRITICAL;HARD;3;CRITICAL - 10.0% (3287292 kB) free!
[1596121225] Auto-save of retention data completed successfully.
[1596121392] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1022 processes
[1596121723] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 350 processes
[1596121978] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2530) < 2020/07/30 20:42:57 [error] 1846#0: *6507998 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "10.147.212.49:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596122078] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1643 processes
[1596122210] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (220732 kB) free!
[1596122543] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.5% (2721156 kB) free!
[1596122923] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 780 processes
[1596123293] SERVICE FLAPPING ALERT: mrq4;Memory;STARTED; Service appears to have started flapping (22.8% change >= 20.0% threshold)
[1596123293] SERVICE ALERT: mrq4;Memory;OK;HARD;1;OK - 44.6% (14609968 kB) free.
[1596123313] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 326 processes
[1596123473] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 3.7% (1800352 kB) free!
[1596123730] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(2263) < 182.18.184.244 [30/Jul/2020:21:12:09 +0530] TCP 502 0 0 0.000 "10.147.212.49:5501" "0" "0" "0.000"
[1596124206] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (200800 kB) free!
[1596124271] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(135) < 2020/07/30 21:21:08 [error] 4373#0: *2159011 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596124331] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 51.94, 50.71, 57.21
[1596124340] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:21:20:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596124514] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;OK;notify-service-by-email;CPU OK: 326 processes
[1596124514] SERVICE ALERT: sservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 326 processes
[1596124825] Auto-save of retention data completed successfully.
[1596124993] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1596125323] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 348 processes
[1596125810] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (231244 kB) free!
[1596126143] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.5% (2725344 kB) free!
[1596126178] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2416) < 2020/07/30 21:52:58 [error] 1848#0: *6561500 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5000, upstream: "10.147.212.49:5500", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596126277] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1437 processes
[1596126523] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 778 processes
[1596126605] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;SOFT;1;PROCS WARNING: 1505 processes
[1596126725] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;SOFT;2;PROCS WARNING: 1505 processes
[1596126845] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 1508 processes
[1596126845] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;HARD;3;PROCS WARNING: 1508 processes
[1596127073] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.7% (833620 kB) free!
[1596127449] SERVICE ALERT: qservercluster2;Memory;WARNING;SOFT;1;WARNING - 19.9% (9783620 kB) free!
[1596127569] SERVICE ALERT: qservercluster2;Memory;WARNING;SOFT;2;WARNING - 19.7% (9702620 kB) free!
[1596127689] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 19.6% (9634884 kB) free!
[1596127689] SERVICE ALERT: qservercluster2;Memory;WARNING;HARD;3;WARNING - 19.6% (9634884 kB) free!
[1596127806] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (192328 kB) free!
[1596127871] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(126) < 2020/07/30 22:21:07 [error] 4368#0: *2171120 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596127930] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(2205) < 182.18.184.244 [30/Jul/2020:22:22:08 +0530] TCP 502 0 0 0.001 "10.147.212.49:5500" "0" "0" "0.001"
[1596127931] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 53.28, 51.15, 51.54
[1596127941] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:22:20:07 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1596128425] Auto-save of retention data completed successfully.
[1596128923] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 351 processes
[1596129192] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1022 processes
[1596129410] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (258236 kB) free!
[1596129743] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.5% (2723028 kB) free!
[1596129778] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2497) < 2020/07/30 22:52:57 [error] 1840#0: *6610362 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "10.147.212.49:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596129877] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1440 processes
[1596130124] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 780 processes
[1596130331] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;WARNING;notify-service-by-email;WARNING - load average: 40.56, 43.06, 44.60
[1596130331] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 40.56, 43.06, 44.60
[1596130445] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 1518 processes
[1596130673] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (236004 kB) free!
[1596131289] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 18.3% (8995140 kB) free!
[1596131406] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (202520 kB) free!
[1596131471] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(129) < 2020/07/30 23:21:08 [error] 4373#0: *2183036 connect() failed (111: Connection refused) while connecting to upstream, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596131531] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 49.81, 59.48, 55.01
[1596131531] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 49.81, 59.48, 55.01
[1596132025] Auto-save of retention data completed successfully.
[1596132130] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(2195) < 182.18.184.244 [30/Jul/2020:23:32:09 +0530] TCP 502 0 0 0.001 "10.147.212.49:5501" "0" "0" "0.001"
[1596132140] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [30/Jul/2020:23:30:07 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1596132523] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 350 processes
[1596132792] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1596132893] SERVICE FLAPPING ALERT: mrq4;Memory;STOPPED; Service appears to have stopped flapping (4.1% change < 5.0% threshold)
[1596133010] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (231292 kB) free!
[1596133343] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.5% (2711072 kB) free!
[1596133478] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1437 processes
