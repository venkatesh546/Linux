[1595961000] LOG ROTATION: DAILY
[1595961000] LOG VERSION: 2.0
[1595961000] CURRENT HOST STATE: TempHP1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.30 ms
[1595961000] CURRENT HOST STATE: TempHP2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.29 ms
[1595961000] CURRENT HOST STATE: TempHP3;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.25 ms
[1595961000] CURRENT HOST STATE: TempHP4;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.30 ms
[1595961000] CURRENT HOST STATE: db1-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.41 ms
[1595961000] CURRENT HOST STATE: db2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.39 ms
[1595961000] CURRENT HOST STATE: mrq4;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.27 ms
[1595961000] CURRENT HOST STATE: primary-server;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.42 ms
[1595961000] CURRENT HOST STATE: pservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.31 ms
[1595961000] CURRENT HOST STATE: pservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.35 ms
[1595961000] CURRENT HOST STATE: qservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.32 ms
[1595961000] CURRENT HOST STATE: qservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.31 ms
[1595961000] CURRENT HOST STATE: redis-1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.37 ms
[1595961000] CURRENT HOST STATE: redis-2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.36 ms
[1595961000] CURRENT HOST STATE: rq-1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.30 ms
[1595961000] CURRENT HOST STATE: rq-2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.33 ms
[1595961000] CURRENT HOST STATE: secondary-server;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.41 ms
[1595961000] CURRENT HOST STATE: sig1-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.54 ms
[1595961000] CURRENT HOST STATE: sig2-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.54 ms
[1595961000] CURRENT HOST STATE: sig3-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.44 ms
[1595961000] CURRENT HOST STATE: sig4-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.45 ms
[1595961000] CURRENT HOST STATE: sig5-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.43 ms
[1595961000] CURRENT HOST STATE: sig6-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.37 ms
[1595961000] CURRENT HOST STATE: sigqscluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.45 ms
[1595961000] CURRENT HOST STATE: sigqscluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.43 ms
[1595961000] CURRENT HOST STATE: smscapp1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.39 ms
[1595961000] CURRENT HOST STATE: smscapp2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.32 ms
[1595961000] CURRENT HOST STATE: sservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.36 ms
[1595961000] CURRENT HOST STATE: sservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.43 ms
[1595961000] CURRENT HOST STATE: webserver1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.49 ms
[1595961000] CURRENT HOST STATE: webserver2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.08 ms
[1595961000] CURRENT HOST STATE: webservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.48 ms
[1595961000] CURRENT HOST STATE: webservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.37 ms
[1595961000] CURRENT SERVICE STATE: TempHP1;CPU Load;OK;HARD;1;OK - load average: 18.34, 18.37, 18.43
[1595961000] CURRENT SERVICE STATE: TempHP1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=68.01% system=29.66% iowait=0.00% idle=2.32%
[1595961000] CURRENT SERVICE STATE: TempHP1;Chrony;OK;HARD;1;PROCS OK: 1 process with command name 'chronyd'
[1595961000] CURRENT SERVICE STATE: TempHP1;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: TempHP1;Home;OK;HARD;1;DISK OK - free space: /home 511707 MB (99% inode=99%):
[1595961000] CURRENT SERVICE STATE: TempHP1;Memory;OK;HARD;1;OK - 89.4% (117703040 kB) free.
[1595961000] CURRENT SERVICE STATE: TempHP1;Open-Files;OK;HARD;1;OK: 11552 open files (0% of max 13142776)
[1595961000] CURRENT SERVICE STATE: TempHP1;Root;OK;HARD;1;DISK OK - free space: /var/tmp 43425 MB (84% inode=99%):
[1595961000] CURRENT SERVICE STATE: TempHP1;Total Processes;OK;HARD;1;PROCS OK: 352 processes
[1595961000] CURRENT SERVICE STATE: TempHP1;zombie_procs;OK;HARD;1;PROCS OK: 1 process with STATE = Z
[1595961000] CURRENT SERVICE STATE: TempHP2;CPU Load;OK;HARD;1;OK - load average: 17.45, 17.57, 17.60
[1595961000] CURRENT SERVICE STATE: TempHP2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=69.05% system=29.44% iowait=0.00% idle=1.51%
[1595961000] CURRENT SERVICE STATE: TempHP2;Chrony;OK;HARD;1;PROCS OK: 1 process with command name 'chronyd'
[1595961000] CURRENT SERVICE STATE: TempHP2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: TempHP2;Home;OK;HARD;1;DISK OK - free space: /home 511587 MB (99% inode=99%):
[1595961000] CURRENT SERVICE STATE: TempHP2;Memory;OK;HARD;1;OK - 89.5% (117795528 kB) free.
[1595961000] CURRENT SERVICE STATE: TempHP2;Open-Files;OK;HARD;1;OK: 11584 open files (0% of max 13142787)
[1595961000] CURRENT SERVICE STATE: TempHP2;Root;OK;HARD;1;DISK OK - free space: /var/tmp 35615 MB (69% inode=99%):
[1595961000] CURRENT SERVICE STATE: TempHP2;Total Processes;OK;HARD;1;PROCS OK: 329 processes
[1595961000] CURRENT SERVICE STATE: TempHP2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595961000] CURRENT SERVICE STATE: TempHP3;CPU Load;OK;HARD;1;OK - load average: 17.18, 17.28, 17.39
[1595961000] CURRENT SERVICE STATE: TempHP3;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=68.51% system=29.34% iowait=0.00% idle=2.15%
[1595961000] CURRENT SERVICE STATE: TempHP3;Chrony;OK;HARD;1;PROCS OK: 1 process with command name 'chronyd'
[1595961000] CURRENT SERVICE STATE: TempHP3;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: TempHP3;Home;OK;HARD;1;DISK OK - free space: /home 511673 MB (99% inode=99%):
[1595961000] CURRENT SERVICE STATE: TempHP3;Memory;OK;HARD;1;OK - 94.8% (124809976 kB) free.
[1595961000] CURRENT SERVICE STATE: TempHP3;Open-Files;OK;HARD;1;OK: 9792 open files (0% of max 13142787)
[1595961000] CURRENT SERVICE STATE: TempHP3;Root;OK;HARD;1;DISK OK - free space: /var/tmp 43230 MB (84% inode=99%):
[1595961000] CURRENT SERVICE STATE: TempHP3;Total Processes;OK;HARD;1;PROCS OK: 329 processes
[1595961000] CURRENT SERVICE STATE: TempHP3;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595961000] CURRENT SERVICE STATE: TempHP4;CPU Load;OK;HARD;1;OK - load average: 17.24, 17.61, 17.58
[1595961000] CURRENT SERVICE STATE: TempHP4;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=67.99% system=29.91% iowait=0.00% idle=2.10%
[1595961000] CURRENT SERVICE STATE: TempHP4;Chrony;OK;HARD;1;PROCS OK: 1 process with command name 'chronyd'
[1595961000] CURRENT SERVICE STATE: TempHP4;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: TempHP4;Home;OK;HARD;1;DISK OK - free space: /home 511024 MB (99% inode=99%):
[1595961000] CURRENT SERVICE STATE: TempHP4;Memory;OK;HARD;1;OK - 94.9% (124921372 kB) free.
[1595961000] CURRENT SERVICE STATE: TempHP4;Open-Files;OK;HARD;1;OK: 9984 open files (15% of max 64000)
[1595961000] CURRENT SERVICE STATE: TempHP4;Root;OK;HARD;1;DISK OK - free space: /var/tmp 42925 MB (83% inode=99%):
[1595961000] CURRENT SERVICE STATE: TempHP4;Total Processes;OK;HARD;1;PROCS OK: 332 processes
[1595961000] CURRENT SERVICE STATE: TempHP4;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595961000] CURRENT SERVICE STATE: db1-vm2;CPU Load;OK;HARD;1;OK - load average: 2.75, 4.44, 4.80
[1595961000] CURRENT SERVICE STATE: db1-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=3.04% system=13.21% iowait=0.00% idle=82.22%
[1595961000] CURRENT SERVICE STATE: db1-vm2;CPU_Procs;OK;HARD;1;CPU OK: 390 processes
[1595961000] CURRENT SERVICE STATE: db1-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: db1-vm2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 26956 MB (67% inode=99%):
[1595961000] CURRENT SERVICE STATE: db1-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44380 MB (86% inode=99%):
[1595961000] CURRENT SERVICE STATE: db1-vm2;Memory;OK;HARD;1;OK - 91.5% (22574416 kB) free.
[1595961000] CURRENT SERVICE STATE: db1-vm2;Open-Files;OK;HARD;1;OK: 11648 open files (0% of max 2441815)
[1595961000] CURRENT SERVICE STATE: db1-vm2;OutOfMemory-killer--oom-killer;OK;HARD;1;Log check ok - 0 pattern matches found
[1595961000] CURRENT SERVICE STATE: db1-vm2;PING;OK;HARD;1;PING OK - Packet loss = 0%, RTA = 0.06 ms
[1595961000] CURRENT SERVICE STATE: db1-vm2;Total Processes;OK;HARD;1;PROCS OK: 390 processes
[1595961000] CURRENT SERVICE STATE: db1-vm2;zombie_procs;OK;HARD;1;PROCS OK: 1 process with STATE = Z
[1595961000] CURRENT SERVICE STATE: db2;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.01, 0.05
[1595961000] CURRENT SERVICE STATE: db2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.34% system=0.38% iowait=0.00% idle=99.29%
[1595961000] CURRENT SERVICE STATE: db2;CPU_Procs;OK;HARD;1;CPU OK: 290 processes
[1595961000] CURRENT SERVICE STATE: db2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: db2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 69276 MB (30% inode=99%):
[1595961000] CURRENT SERVICE STATE: db2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44492 MB (86% inode=99%):
[1595961000] CURRENT SERVICE STATE: db2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: db2;Mariadb status;OK;HARD;1;PROCS OK: 1 process with command name 'mysqld'
[1595961000] CURRENT SERVICE STATE: db2;Memory;CRITICAL;HARD;3;CRITICAL - 5.6% (2776508 kB) free!
[1595961000] CURRENT SERVICE STATE: db2;Open-Files;OK;HARD;1;OK: 6624 open files (0% of max 4878253)
[1595961000] CURRENT SERVICE STATE: db2;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: db2;Total Processes;OK;HARD;1;PROCS OK: 290 processes
[1595961000] CURRENT SERVICE STATE: db2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595961000] CURRENT SERVICE STATE: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 59.95, 57.53, 52.75
[1595961000] CURRENT SERVICE STATE: mrq4;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=14.23% system=41.53% iowait=0.00% idle=44.24%
[1595961000] CURRENT SERVICE STATE: mrq4;CPU_Procs;OK;HARD;1;CPU OK: 1436 processes
[1595961000] CURRENT SERVICE STATE: mrq4;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: mrq4;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 211044 MB (95% inode=99%):
[1595961000] CURRENT SERVICE STATE: mrq4;HDD_Root status;OK;HARD;1;DISK OK - free space: / 45376 MB (88% inode=99%):
[1595961000] CURRENT SERVICE STATE: mrq4;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: mrq4;Memory;OK;HARD;1;OK - 44.8% (14672344 kB) free.
[1595961000] CURRENT SERVICE STATE: mrq4;Open-Files;OK;HARD;1;OK: 71072 open files (2% of max 3240801)
[1595961000] CURRENT SERVICE STATE: mrq4;Total Processes;CRITICAL;HARD;3;PROCS CRITICAL: 1438 processes
[1595961000] CURRENT SERVICE STATE: mrq4;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595961000] CURRENT SERVICE STATE: primary-server;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.01, 0.05
[1595961000] CURRENT SERVICE STATE: primary-server;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.03% system=0.14% iowait=0.00% idle=99.84%
[1595961000] CURRENT SERVICE STATE: primary-server;CPU_Procs;OK;HARD;1;CPU OK: 305 processes
[1595961000] CURRENT SERVICE STATE: primary-server;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595961000] CURRENT SERVICE STATE: primary-server;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 202744 MB (90% inode=99%):
[1595961000] CURRENT SERVICE STATE: primary-server;HDD_Root status;OK;HARD;1;DISK OK - free space: / 13882 MB (27% inode=99%):
[1595961000] CURRENT SERVICE STATE: primary-server;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: primary-server;Memory;OK;HARD;1;OK - 81.1% (19879440 kB) free.
[1595961000] CURRENT SERVICE STATE: primary-server;Nginx Access Log Status;CRITICAL;HARD;3;(1064) < 182.18.184.244 [28/Jul/2020:23:52:09 +0530] TCP 502 0 0 0.002 "10.147.212.61:5501, 10.147.212.38:5501, 10.147.212.37:5501, 10.147.212.49:5501" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.001, 0.000"
[1595961000] CURRENT SERVICE STATE: primary-server;Nginx Error Log Status;CRITICAL;HARD;3;(2692) < 2020/07/28 23:52:53 [error] 1786#0: *4602632 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "backend_5003", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595961000] CURRENT SERVICE STATE: primary-server;Nginx Status;OK;HARD;1;NGINX OK -  0.081 sec. response time, Active: 0 (Writing: 0 Reading: 0 Waiting: 0) ReqPerSec: 0.000 ConnPerSec: 0.000 ReqPerConn: 0.000
[1595961000] CURRENT SERVICE STATE: primary-server;Open-Files;OK;HARD;1;OK: 6976 open files (0% of max 2423416)
[1595961000] CURRENT SERVICE STATE: primary-server;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: primary-server;Total Processes;OK;HARD;1;PROCS OK: 306 processes
[1595961000] CURRENT SERVICE STATE: primary-server;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595961000] CURRENT SERVICE STATE: pservercluster1;CPU Load;OK;HARD;1;OK - load average: 1.23, 1.28, 1.37
[1595961000] CURRENT SERVICE STATE: pservercluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.96% system=7.33% iowait=0.00% idle=90.71%
[1595961000] CURRENT SERVICE STATE: pservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 320 processes
[1595961000] CURRENT SERVICE STATE: pservercluster1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595961000] CURRENT SERVICE STATE: pservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 162204 MB (73% inode=99%):
[1595961000] CURRENT SERVICE STATE: pservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39500 MB (77% inode=99%):
[1595961000] CURRENT SERVICE STATE: pservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: pservercluster1;Memory;OK;HARD;1;OK - 87.2% (21529448 kB) free.
[1595961000] CURRENT SERVICE STATE: pservercluster1;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1595961000] CURRENT SERVICE STATE: pservercluster1;Open-Files;OK;HARD;1;OK: 10176 open files (0% of max 2440681)
[1595961000] CURRENT SERVICE STATE: pservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: pservercluster1;Total Processes;OK;HARD;1;PROCS OK: 321 processes
[1595961000] CURRENT SERVICE STATE: pservercluster1;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595961000] CURRENT SERVICE STATE: pservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.81, 1.22, 41.46
[1595961000] CURRENT SERVICE STATE: pservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.66% system=6.88% iowait=0.05% idle=91.40%
[1595961000] CURRENT SERVICE STATE: pservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 332 processes
[1595961000] CURRENT SERVICE STATE: pservercluster2;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595961000] CURRENT SERVICE STATE: pservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 162848 MB (72% inode=99%):
[1595961000] CURRENT SERVICE STATE: pservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 38289 MB (74% inode=98%):
[1595961000] CURRENT SERVICE STATE: pservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: pservercluster2;Memory;OK;HARD;1;OK - 90.2% (22100340 kB) free.
[1595961000] CURRENT SERVICE STATE: pservercluster2;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1595961000] CURRENT SERVICE STATE: pservercluster2;Open-Files;OK;HARD;1;OK: 7904 open files (0% of max 2424156)
[1595961000] CURRENT SERVICE STATE: pservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: pservercluster2;Total Processes;OK;HARD;1;PROCS OK: 335 processes
[1595961000] CURRENT SERVICE STATE: pservercluster2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595961000] CURRENT SERVICE STATE: qservercluster1;CPU Load;OK;HARD;1;OK - load average: 6.87, 6.30, 6.46
[1595961000] CURRENT SERVICE STATE: qservercluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=30.43% system=14.46% iowait=0.00% idle=55.11%
[1595961000] CURRENT SERVICE STATE: qservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 299 processes
[1595961000] CURRENT SERVICE STATE: qservercluster1;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: qservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 224641 MB (99% inode=99%):
[1595961000] CURRENT SERVICE STATE: qservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 43232 MB (84% inode=99%):
[1595961000] CURRENT SERVICE STATE: qservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: qservercluster1;Memory;OK;HARD;1;OK - 87.3% (42999984 kB) free.
[1595961000] CURRENT SERVICE STATE: qservercluster1;Open-Files;OK;HARD;1;OK: 9152 open files (0% of max 4874250)
[1595961000] CURRENT SERVICE STATE: qservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: qservercluster1;Total Processes;OK;HARD;1;PROCS OK: 300 processes
[1595961000] CURRENT SERVICE STATE: qservercluster1;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595961000] CURRENT SERVICE STATE: qservercluster2;CPU Load;OK;HARD;1;OK - load average: 5.82, 5.53, 5.67
[1595961000] CURRENT SERVICE STATE: qservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=7.84% system=22.03% iowait=0.11% idle=70.02%
[1595961000] CURRENT SERVICE STATE: qservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 771 processes
[1595961000] CURRENT SERVICE STATE: qservercluster2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: qservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 149139 MB (66% inode=99%):
[1595961000] CURRENT SERVICE STATE: qservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 26998 MB (52% inode=98%):
[1595961000] CURRENT SERVICE STATE: qservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: qservercluster2;Memory;CRITICAL;HARD;3;CRITICAL - 6.5% (3206256 kB) free!
[1595961000] CURRENT SERVICE STATE: qservercluster2;Open-Files;OK;HARD;1;OK: 22528 open files (0% of max 4878254)
[1595961000] CURRENT SERVICE STATE: qservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: qservercluster2;Total Processes;WARNING;HARD;3;PROCS WARNING: 771 processes
[1595961000] CURRENT SERVICE STATE: qservercluster2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595961000] CURRENT SERVICE STATE: redis-1;CPU Load;OK;HARD;1;OK - load average: 0.19, 0.13, 0.22
[1595961000] CURRENT SERVICE STATE: redis-1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.76% system=1.06% iowait=0.01% idle=98.17%
[1595961000] CURRENT SERVICE STATE: redis-1;CPU_Procs;OK;HARD;1;CPU OK: 407 processes
[1595961000] CURRENT SERVICE STATE: redis-1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595961000] CURRENT SERVICE STATE: redis-1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 348653 MB (93% inode=99%):
[1595961000] CURRENT SERVICE STATE: redis-1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44124 MB (86% inode=99%):
[1595961000] CURRENT SERVICE STATE: redis-1;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /vns1 546303 MB (51% inode=99%):
[1595961000] CURRENT SERVICE STATE: redis-1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: redis-1;Memory;OK;HARD;1;OK - 29.7% (39117612 kB) free.
[1595961000] CURRENT SERVICE STATE: redis-1;Open-Files;OK;HARD;1;OK: 25392 open files (0% of max 13066864)
[1595961000] CURRENT SERVICE STATE: redis-1;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: redis-1;Total Processes;OK;HARD;1;PROCS OK: 408 processes
[1595961000] CURRENT SERVICE STATE: redis-2;CPU Load;OK;HARD;1;OK - load average: 0.17, 0.17, 0.23
[1595961000] CURRENT SERVICE STATE: redis-2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.47% system=0.68% iowait=0.01% idle=98.84%
[1595961000] CURRENT SERVICE STATE: redis-2;CPU_Procs;OK;HARD;1;CPU OK: 346 processes
[1595961000] CURRENT SERVICE STATE: redis-2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: redis-2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 234412 MB (62% inode=99%):
[1595961000] CURRENT SERVICE STATE: redis-2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44150 MB (86% inode=99%):
[1595961000] CURRENT SERVICE STATE: redis-2;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /vns1 1069171 MB (99% inode=99%):
[1595961000] CURRENT SERVICE STATE: redis-2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: redis-2;Memory;OK;HARD;1;OK - 55.9% (73723476 kB) free.
[1595961000] CURRENT SERVICE STATE: redis-2;Open-Files;OK;HARD;1;OK: 13152 open files (20% of max 65536)
[1595961000] CURRENT SERVICE STATE: redis-2;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: redis-2;Total Processes;OK;HARD;1;PROCS OK: 343 processes
[1595961000] CURRENT SERVICE STATE: rq-1;CPU Load;OK;HARD;1;OK - load average: 16.90, 15.87, 15.85
[1595961000] CURRENT SERVICE STATE: rq-1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=50.00% system=17.88% iowait=0.00% idle=32.13%
[1595961000] CURRENT SERVICE STATE: rq-1;CPU_Procs;WARNING;HARD;3;CPU WARNING: 1 warn out of 354 processes
[1595961000] CURRENT SERVICE STATE: rq-1;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: rq-1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 400998 MB (99% inode=99%):
[1595961000] CURRENT SERVICE STATE: rq-1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40495 MB (79% inode=99%):
[1595961000] CURRENT SERVICE STATE: rq-1;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /rq1vns1 1068147 MB (99% inode=99%):
[1595961000] CURRENT SERVICE STATE: rq-1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: rq-1;Memory;OK;HARD;1;OK - 77.1% (101691140 kB) free.
[1595961000] CURRENT SERVICE STATE: rq-1;Open-Files;OK;HARD;1;OK: 11184 open files (0% of max 13066902)
[1595961000] CURRENT SERVICE STATE: rq-1;Total Processes;OK;HARD;1;PROCS OK: 353 processes
[1595961000] CURRENT SERVICE STATE: rq-1;rq1-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1595961000] CURRENT SERVICE STATE: rq-2;CPU Load;OK;HARD;1;OK - load average: 12.73, 14.11, 14.92
[1595961000] CURRENT SERVICE STATE: rq-2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=48.31% system=16.90% iowait=0.01% idle=34.78%
[1595961000] CURRENT SERVICE STATE: rq-2;CPU_Procs;OK;HARD;1;CPU OK: 348 processes
[1595961000] CURRENT SERVICE STATE: rq-2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: rq-2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 401126 MB (99% inode=99%):
[1595961000] CURRENT SERVICE STATE: rq-2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 45542 MB (88% inode=99%):
[1595961000] CURRENT SERVICE STATE: rq-2;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /dev 64349 MB (100% inode=99%):
[1595961000] CURRENT SERVICE STATE: rq-2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: rq-2;Memory;OK;HARD;1;OK - 94.4% (124499316 kB) free.
[1595961000] CURRENT SERVICE STATE: rq-2;Open-Files;OK;HARD;1;OK: 10656 open files (0% of max 13066939)
[1595961000] CURRENT SERVICE STATE: rq-2;Total Processes;OK;HARD;1;PROCS OK: 346 processes
[1595961000] CURRENT SERVICE STATE: rq-2;rq2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1595961000] CURRENT SERVICE STATE: secondary-server;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.01, 0.05
[1595961000] CURRENT SERVICE STATE: secondary-server;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.09% system=0.16% iowait=0.00% idle=99.75%
[1595961000] CURRENT SERVICE STATE: secondary-server;CPU_Procs;OK;HARD;1;CPU OK: 304 processes
[1595961000] CURRENT SERVICE STATE: secondary-server;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595961000] CURRENT SERVICE STATE: secondary-server;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 79172 MB (35% inode=99%):
[1595961000] CURRENT SERVICE STATE: secondary-server;HDD_Root status;OK;HARD;1;DISK OK - free space: / 36650 MB (71% inode=99%):
[1595961000] CURRENT SERVICE STATE: secondary-server;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: secondary-server;Memory Status;CRITICAL;HARD;3;CRITICAL - 0.7% (182944 kB) free!
[1595961000] CURRENT SERVICE STATE: secondary-server;Nginx Access Log Status;CRITICAL;HARD;3;(4) < 15.206.135.98 [28/Jul/2020:23:51:05 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1595961000] CURRENT SERVICE STATE: secondary-server;Nginx Error Log Status;CRITICAL;HARD;3;(126) < 2020/07/28 23:53:05 [error] 1823#0: *1504514 recv() failed (104: Connection reset by peer) while proxying connection, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.37:4000", bytes from/to client:45/0, bytes from/to upstream:0/45
[1595961000] CURRENT SERVICE STATE: secondary-server;Nginx Status;OK;HARD;1;NGINX OK -  0.084 sec. response time, Active: 0 (Writing: 0 Reading: 0 Waiting: 0) ReqPerSec: 0.000 ConnPerSec: 0.000 ReqPerConn: 0.000
[1595961000] CURRENT SERVICE STATE: secondary-server;Open-Files;OK;HARD;1;OK: 6304 open files (0% of max 2423397)
[1595961000] CURRENT SERVICE STATE: secondary-server;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: secondary-server;Total Processes;OK;HARD;1;PROCS OK: 313 processes
[1595961000] CURRENT SERVICE STATE: sig1-vm2;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.00, 0.00
[1595961000] CURRENT SERVICE STATE: sig1-vm2;CPU_Procs;OK;HARD;1;CPU OK: 287 processes
[1595961000] CURRENT SERVICE STATE: sig1-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: sig1-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: sig1-vm2;Memory;OK;HARD;1;OK - 58.3% (9520644 kB) free.
[1595961000] CURRENT SERVICE STATE: sig1-vm2;Open-Files;OK;HARD;1;OK: 2688 open files (0% of max 1620608)
[1595961000] CURRENT SERVICE STATE: sig1-vm2;Root status;OK;HARD;1;DISK OK - free space: / 117798 MB (87% inode=96%):
[1595961000] CURRENT SERVICE STATE: sig1-vm2;Total Processes;OK;HARD;1;PROCS OK: 287 processes
[1595961000] CURRENT SERVICE STATE: sig2-vm2;CPU Load;OK;HARD;1;OK - load average: 5.12, 5.29, 4.98
[1595961000] CURRENT SERVICE STATE: sig2-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=3.44% system=14.58% iowait=0.00% idle=80.54%
[1595961000] CURRENT SERVICE STATE: sig2-vm2;CPU_Procs;OK;HARD;1;CPU OK: 383 processes
[1595961000] CURRENT SERVICE STATE: sig2-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: sig2-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 124093 MB (89% inode=99%):
[1595961000] CURRENT SERVICE STATE: sig2-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: sig2-vm2;Memory;OK;HARD;1;OK - 93.3% (32492552 kB) free.
[1595961000] CURRENT SERVICE STATE: sig2-vm2;Open-Files;OK;HARD;1;OK: 11968 open files (0% of max 3443846)
[1595961000] CURRENT SERVICE STATE: sig2-vm2;Total Processes;OK;HARD;1;PROCS OK: 383 processes
[1595961000] CURRENT SERVICE STATE: sig3-vm2;CPU Load;OK;HARD;1;OK - load average: 4.29, 5.84, 5.14
[1595961000] CURRENT SERVICE STATE: sig3-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=3.17% system=14.39% iowait=0.09% idle=82.35%
[1595961000] CURRENT SERVICE STATE: sig3-vm2;CPU_Procs;OK;HARD;1;CPU OK: 467 processes
[1595961000] CURRENT SERVICE STATE: sig3-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: sig3-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 90130 MB (75% inode=96%):
[1595961000] CURRENT SERVICE STATE: sig3-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 2 processes with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: sig3-vm2;Memory;OK;HARD;1;OK - 96.1% (22644068 kB) free.
[1595961000] CURRENT SERVICE STATE: sig3-vm2;Open-Files;OK;HARD;1;OK: 9504 open files (0% of max 2339574)
[1595961000] CURRENT SERVICE STATE: sig3-vm2;Total Processes;OK;HARD;1;PROCS OK: 467 processes
[1595961000] CURRENT SERVICE STATE: sig4-vm2;CPU Load;OK;HARD;1;OK - load average: 0.01, 0.02, 0.05
[1595961000] CURRENT SERVICE STATE: sig4-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.06% system=0.00% iowait=0.00% idle=99.91%
[1595961000] CURRENT SERVICE STATE: sig4-vm2;CPU_Procs;OK;HARD;1;CPU OK: 220 processes
[1595961000] CURRENT SERVICE STATE: sig4-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: sig4-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 87107 MB (67% inode=99%):
[1595961000] CURRENT SERVICE STATE: sig4-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: sig4-vm2;Memory;OK;HARD;1;OK - 96.5% (33619868 kB) free.
[1595961000] CURRENT SERVICE STATE: sig4-vm2;Open-Files;OK;HARD;1;OK: 5728 open files (0% of max 3443901)
[1595961000] CURRENT SERVICE STATE: sig4-vm2;Total Processes;OK;HARD;1;PROCS OK: 225 processes
[1595961000] CURRENT SERVICE STATE: sig5-vm2;CPU Load;OK;HARD;1;OK - load average: 7.93, 5.76, 5.28
[1595961000] CURRENT SERVICE STATE: sig5-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.75% system=6.67% iowait=0.00% idle=90.44%
[1595961000] CURRENT SERVICE STATE: sig5-vm2;CPU_Procs;OK;HARD;1;CPU OK: 383 processes
[1595961000] CURRENT SERVICE STATE: sig5-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: sig5-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 229804 MB (91% inode=99%):
[1595961000] CURRENT SERVICE STATE: sig5-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: sig5-vm2;Memory;OK;HARD;1;OK - 91.1% (31901096 kB) free.
[1595961000] CURRENT SERVICE STATE: sig5-vm2;Open-Files;OK;HARD;1;OK: 11904 open files (0% of max 3462151)
[1595961000] CURRENT SERVICE STATE: sig5-vm2;Total Processes;OK;HARD;1;PROCS OK: 383 processes
[1595961000] CURRENT SERVICE STATE: sig6-vm2;CPU Load;OK;HARD;1;OK - load average: 5.28, 5.19, 5.09
[1595961000] CURRENT SERVICE STATE: sig6-vm2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=3.49% system=14.63% iowait=0.00% idle=80.31%
[1595961000] CURRENT SERVICE STATE: sig6-vm2;CPU_Procs;OK;HARD;1;CPU OK: 386 processes
[1595961000] CURRENT SERVICE STATE: sig6-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: sig6-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 178244 MB (91% inode=99%):
[1595961000] CURRENT SERVICE STATE: sig6-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: sig6-vm2;Memory;OK;HARD;1;OK - 85.4% (19177012 kB) free.
[1595961000] CURRENT SERVICE STATE: sig6-vm2;Open-Files;OK;HARD;1;OK: 12064 open files (0% of max 2220276)
[1595961000] CURRENT SERVICE STATE: sig6-vm2;OutOfMemory-killer--oom-killer;OK;HARD;1;Log check ok - 0 pattern matches found
[1595961000] CURRENT SERVICE STATE: sig6-vm2;Total Processes;OK;HARD;1;PROCS OK: 380 processes
[1595961000] CURRENT SERVICE STATE: sigqscluster1;CPU Load;OK;HARD;1;OK - load average: 0.14, 0.20, 0.35
[1595961000] CURRENT SERVICE STATE: sigqscluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.88% system=0.98% iowait=0.16% idle=97.97%
[1595961000] CURRENT SERVICE STATE: sigqscluster1;CPU_Procs;OK;HARD;1;CPU OK: 1489 processes
[1595961000] CURRENT SERVICE STATE: sigqscluster1;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: sigqscluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 84918 MB (37% inode=99%):
[1595961000] CURRENT SERVICE STATE: sigqscluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39938 MB (78% inode=99%):
[1595961000] CURRENT SERVICE STATE: sigqscluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: sigqscluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.4% (218412 kB) free!
[1595961000] CURRENT SERVICE STATE: sigqscluster1;Open-Files;OK;HARD;1;OK: 68544 open files (1% of max 4878272)
[1595961000] CURRENT SERVICE STATE: sigqscluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: sigqscluster1;Total Processes;OK;HARD;1;PROCS OK: 1492 processes
[1595961000] CURRENT SERVICE STATE: sigqscluster2;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.07, 0.13
[1595961000] CURRENT SERVICE STATE: sigqscluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.33% system=0.38% iowait=0.00% idle=99.30%
[1595961000] CURRENT SERVICE STATE: sigqscluster2;CPU_Procs;OK;HARD;1;CPU OK: 293 processes
[1595961000] CURRENT SERVICE STATE: sigqscluster2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: sigqscluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 208151 MB (99% inode=99%):
[1595961000] CURRENT SERVICE STATE: sigqscluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44716 MB (87% inode=99%):
[1595961000] CURRENT SERVICE STATE: sigqscluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: sigqscluster2;Memory;OK;HARD;1;OK - 97.9% (48227336 kB) free.
[1595961000] CURRENT SERVICE STATE: sigqscluster2;Open-Files;OK;HARD;1;OK: 5696 open files (0% of max 4878254)
[1595961000] CURRENT SERVICE STATE: sigqscluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: sigqscluster2;Total Processes;OK;HARD;1;PROCS OK: 295 processes
[1595961000] CURRENT SERVICE STATE: sigqscluster2;sigqscluster2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1595961000] CURRENT SERVICE STATE: smscapp1;CPU Load;OK;HARD;1;OK - load average: 9.92, 9.60, 9.28
[1595961000] CURRENT SERVICE STATE: smscapp1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=8.30% system=21.86% iowait=0.24% idle=69.47%
[1595961000] CURRENT SERVICE STATE: smscapp1;CPU_Procs;OK;HARD;1;CPU OK: 1022 processes
[1595961000] CURRENT SERVICE STATE: smscapp1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595961000] CURRENT SERVICE STATE: smscapp1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 152547 MB (67% inode=99%):
[1595961000] CURRENT SERVICE STATE: smscapp1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39106 MB (76% inode=98%):
[1595961000] CURRENT SERVICE STATE: smscapp1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: smscapp1;Memory;CRITICAL;HARD;3;CRITICAL - 0.5% (251668 kB) free!
[1595961000] CURRENT SERVICE STATE: smscapp1;Open-Files;OK;HARD;1;OK: 33056 open files (0% of max 4878253)
[1595961000] CURRENT SERVICE STATE: smscapp1;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: smscapp1;Total Processes;CRITICAL;HARD;3;PROCS CRITICAL: 1023 processes
[1595961000] CURRENT SERVICE STATE: smscapp2;CPU Load;OK;HARD;1;OK - load average: 8.06, 9.57, 10.02
[1595961000] CURRENT SERVICE STATE: smscapp2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=10.24% system=32.83% iowait=0.00% idle=56.92%
[1595961000] CURRENT SERVICE STATE: smscapp2;CPU_Procs;OK;HARD;1;CPU OK: 1760 processes
[1595961000] CURRENT SERVICE STATE: smscapp2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: smscapp2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 94668 MB (42% inode=99%):
[1595961000] CURRENT SERVICE STATE: smscapp2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 38775 MB (75% inode=98%):
[1595961000] CURRENT SERVICE STATE: smscapp2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: smscapp2;Memory;OK;HARD;1;OK - 83.6% (41220676 kB) free.
[1595961000] CURRENT SERVICE STATE: smscapp2;Open-Files;OK;HARD;1;OK: 88160 open files (1% of max 4878254)
[1595961000] CURRENT SERVICE STATE: smscapp2;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: smscapp2;Total Processes;OK;HARD;1;PROCS OK: 1762 processes
[1595961000] CURRENT SERVICE STATE: sservercluster1;CPU Load;OK;HARD;1;OK - load average: 1.19, 1.27, 44.42
[1595961000] CURRENT SERVICE STATE: sservercluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.26% system=5.47% iowait=0.00% idle=93.27%
[1595961000] CURRENT SERVICE STATE: sservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 315 processes
[1595961000] CURRENT SERVICE STATE: sservercluster1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595961000] CURRENT SERVICE STATE: sservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 148752 MB (67% inode=99%):
[1595961000] CURRENT SERVICE STATE: sservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40506 MB (79% inode=99%):
[1595961000] CURRENT SERVICE STATE: sservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: sservercluster1;Memory;OK;HARD;1;OK - 90.0% (22066088 kB) free.
[1595961000] CURRENT SERVICE STATE: sservercluster1;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1595961000] CURRENT SERVICE STATE: sservercluster1;Open-Files;OK;HARD;1;OK: 6080 open files (0% of max 2424092)
[1595961000] CURRENT SERVICE STATE: sservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: sservercluster1;Total Processes;OK;HARD;1;PROCS OK: 317 processes
[1595961000] CURRENT SERVICE STATE: sservercluster1;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595961000] CURRENT SERVICE STATE: sservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.49, 0.72, 0.82
[1595961000] CURRENT SERVICE STATE: sservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.86% system=3.71% iowait=0.01% idle=95.42%
[1595961000] CURRENT SERVICE STATE: sservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 326 processes
[1595961000] CURRENT SERVICE STATE: sservercluster2;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595961000] CURRENT SERVICE STATE: sservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 192686 MB (87% inode=99%):
[1595961000] CURRENT SERVICE STATE: sservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 33087 MB (64% inode=98%):
[1595961000] CURRENT SERVICE STATE: sservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: sservercluster2;Memory;OK;HARD;1;OK - 89.1% (21827668 kB) free.
[1595961000] CURRENT SERVICE STATE: sservercluster2;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1595961000] CURRENT SERVICE STATE: sservercluster2;Open-Files;OK;HARD;1;OK: 6432 open files (0% of max 2424092)
[1595961000] CURRENT SERVICE STATE: sservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: sservercluster2;Total Processes;OK;HARD;1;PROCS OK: 325 processes
[1595961000] CURRENT SERVICE STATE: sservercluster2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595961000] CURRENT SERVICE STATE: webserver1;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.01, 0.05
[1595961000] CURRENT SERVICE STATE: webserver1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.05% system=0.01% iowait=0.00% idle=99.94%
[1595961000] CURRENT SERVICE STATE: webserver1;CPU_Procs;OK;HARD;1;CPU OK: 324 processes
[1595961000] CURRENT SERVICE STATE: webserver1;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1595961000] CURRENT SERVICE STATE: webserver1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 224773 MB (99% inode=99%):
[1595961000] CURRENT SERVICE STATE: webserver1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40173 MB (78% inode=99%):
[1595961000] CURRENT SERVICE STATE: webserver1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: webserver1;Memory;OK;HARD;1;OK - 93.7% (22934820 kB) free.
[1595961000] CURRENT SERVICE STATE: webserver1;Nginx_status;OK;HARD;1;NGINX OK -  0.089 sec. response time, Active: 1 (Writing: 1 Reading: 0 Waiting: 0) ReqPerSec: 0.002 ConnPerSec: 0.008 ReqPerConn: 0.995
[1595961000] CURRENT SERVICE STATE: webserver1;Open-Files;OK;HARD;1;OK: 6144 open files (0% of max 2419418)
[1595961000] CURRENT SERVICE STATE: webserver1;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: webserver1;Total Processes;OK;HARD;1;PROCS OK: 326 processes
[1595961000] CURRENT SERVICE STATE: webserver2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.31% system=0.11% iowait=0.01% idle=99.56%
[1595961000] CURRENT SERVICE STATE: webserver2;CPU_Procs;OK;HARD;1;CPU OK: 349 processes
[1595961000] CURRENT SERVICE STATE: webserver2;Current Load;OK;HARD;1;OK - load average: 0.03, 0.03, 0.05
[1595961000] CURRENT SERVICE STATE: webserver2;Current Users;OK;HARD;1;USERS OK - 4 users currently logged in
[1595961000] CURRENT SERVICE STATE: webserver2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 105977 MB (47.15% inode=100%):
[1595961000] CURRENT SERVICE STATE: webserver2;HTTP;OK;HARD;1;HTTP OK: HTTP/1.1 200 OK - 355 bytes in 0.001 second response time
[1595961000] CURRENT SERVICE STATE: webserver2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: webserver2;Memory;OK;HARD;1;OK - 45.7% (11203644 kB) free.
[1595961000] CURRENT SERVICE STATE: webserver2;Open-Files;OK;HARD;1;OK: 6624 open files (0% of max 2423406)
[1595961000] CURRENT SERVICE STATE: webserver2;PING;OK;HARD;1;PING OK - Packet loss = 0%, RTA = 0.08 ms
[1595961000] CURRENT SERVICE STATE: webserver2;Root Partition;OK;HARD;1;DISK OK - free space: / 14836 MB (28.99% inode=99%):
[1595961000] CURRENT SERVICE STATE: webserver2;SSH;OK;HARD;1;SSH OK - OpenSSH_7.4 (protocol 2.0)
[1595961000] CURRENT SERVICE STATE: webserver2;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: webserver2;Total Processes;OK;HARD;1;PROCS OK: 160 processes with STATE = RSZDT
[1595961000] CURRENT SERVICE STATE: webservercluster1;CPU Load;OK;HARD;1;OK - load average: 0.05, 0.06, 0.05
[1595961000] CURRENT SERVICE STATE: webservercluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.00% system=0.01% iowait=0.00% idle=99.99%
[1595961000] CURRENT SERVICE STATE: webservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 317 processes
[1595961000] CURRENT SERVICE STATE: webservercluster1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595961000] CURRENT SERVICE STATE: webservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: / 20082 MB (39% inode=99%):
[1595961000] CURRENT SERVICE STATE: webservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: /home 76964 MB (34% inode=99%):
[1595961000] CURRENT SERVICE STATE: webservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: webservercluster1;Memory;OK;HARD;1;OK - 56.9% (9250600 kB) free.
[1595961000] CURRENT SERVICE STATE: webservercluster1;Open-Files;OK;HARD;1;OK: 4608 open files (0% of max 1607067)
[1595961000] CURRENT SERVICE STATE: webservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: webservercluster1;Total Processes;OK;HARD;1;PROCS OK: 320 processes
[1595961000] CURRENT SERVICE STATE: webservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.19, 0.34, 0.40
[1595961000] CURRENT SERVICE STATE: webservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.38% system=0.75% iowait=0.06% idle=98.81%
[1595961000] CURRENT SERVICE STATE: webservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 288 processes
[1595961000] CURRENT SERVICE STATE: webservercluster2;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595961000] CURRENT SERVICE STATE: webservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 222541 MB (99% inode=99%):
[1595961000] CURRENT SERVICE STATE: webservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39438 MB (77% inode=99%):
[1595961000] CURRENT SERVICE STATE: webservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595961000] CURRENT SERVICE STATE: webservercluster2;Memory;OK;HARD;1;OK - 57.2% (9298180 kB) free.
[1595961000] CURRENT SERVICE STATE: webservercluster2;Open-Files;OK;HARD;1;OK: 7424 open files (0% of max 1607066)
[1595961000] CURRENT SERVICE STATE: webservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1595961000] CURRENT SERVICE STATE: webservercluster2;Total Processes;OK;HARD;1;PROCS OK: 295 processes
[1595961141] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:00:01:05 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1595961189] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(130) < 2020/07/29 00:03:02 [error] 1823#0: *1505457 recv() failed (104: Connection reset by peer) while proxying connection, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.37:4000", bytes from/to client:45/0, bytes from/to upstream:0/45
[1595961579] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.8% (192792 kB) free!
[1595961591] SERVICE ALERT: pservercluster2;Memory;WARNING;SOFT;1;WARNING - 13.7% (3348436 kB) free!
[1595961592] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (238148 kB) free!
[1595961606] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (179068 kB) free!
[1595961699] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (194056 kB) free!
[1595961711] SERVICE ALERT: pservercluster2;Memory;WARNING;SOFT;2;WARNING - 13.6% (3332864 kB) free!
[1595961819] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (197836 kB) free!
[1595961819] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (197836 kB) free!
[1595961831] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 13.5% (3313800 kB) free!
[1595961831] SERVICE ALERT: pservercluster2;Memory;WARNING;HARD;3;WARNING - 13.5% (3313800 kB) free!
[1595961888] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.7% (175012 kB) free!
[1595962008] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 89.8% (22007140 kB) free.
[1595962123] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 350 processes
[1595962209] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 6.2% (3059632 kB) free!
[1595962331] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;WARNING;notify-service-by-email;WARNING - load average: 42.75, 33.43, 36.89
[1595962331] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 42.75, 33.43, 36.89
[1595962342] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2777772 kB) free!
[1595962431] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;OK;notify-service-by-email;OK - 89.7% (21977544 kB) free.
[1595962431] SERVICE ALERT: pservercluster2;Memory;OK;HARD;1;OK - 89.7% (21977544 kB) free.
[1595962825] Auto-save of retention data completed successfully.
[1595962975] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2641) < 2020/07/29 00:32:54 [error] 1786#0: *4633143 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "backend_5002", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595962991] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1022 processes
[1595963019] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;OK;notify-service-by-email;OK - 89.1% (21999104 kB) free.
[1595963019] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 89.1% (21999104 kB) free.
[1595963530] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1072) < 182.18.184.244 [29/Jul/2020:00:42:09 +0530] TCP 502 0 0 0.000 "backend_5003" "0" "0" "0.000"
[1595963801] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (228456 kB) free!
[1595964131] SERVICE FLAPPING ALERT: mrq4;CPU Load;STARTED; Service appears to have started flapping (22.4% change >= 20.0% threshold)
[1595964131] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 37.41, 48.29, 46.70
[1595964277] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1438 processes
[1595964523] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 773 processes
[1595964731] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 43.68, 40.64, 42.94
[1595964784] SERVICE ALERT: webserver2;Memory;CRITICAL;SOFT;1;CRITICAL - 6.1% (1501520 kB) free!
[1595964790] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(125) < 2020/07/29 01:03:02 [error] 1820#0: *1511575 recv() failed (104: Connection reset by peer) while proxying connection, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.37:4000", bytes from/to client:45/0, bytes from/to upstream:0/45
[1595964822] SERVICE ALERT: webserver2;CPU-STATISTICS;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595964844] SERVICE ALERT: webserver2;Memory;CRITICAL;SOFT;2;CRITICAL - 0.7% (172508 kB) free!
[1595964887] SERVICE ALERT: webserver2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.10% system=3.28% iowait=3.34% idle=93.28%
[1595964906] SERVICE ALERT: webserver2;Memory;CRITICAL;SOFT;3;CRITICAL - 0.7% (183152 kB) free!
[1595964966] SERVICE NOTIFICATION: nagiosadmin;webserver2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (171504 kB) free!
[1595964966] SERVICE ALERT: webserver2;Memory;CRITICAL;HARD;4;CRITICAL - 0.7% (171504 kB) free!
[1595965080] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;SOFT;1;PROCS WARNING: 1503 processes
[1595965192] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (248328 kB) free!
[1595965201] SERVICE ALERT: sigqscluster1;Total Processes;OK;HARD;1;PROCS OK: 1500 processes
[1595965206] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (185416 kB) free!
[1595965266] SERVICE NOTIFICATION: nagiosadmin;webserver2;Memory;OK;notify-service-by-email;OK - 75.1% (18406864 kB) free.
[1595965266] SERVICE ALERT: webserver2;Memory;OK;HARD;1;OK - 75.1% (18406864 kB) free.
[1595965331] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 52.72, 48.56, 45.43
[1595965340] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:01:11:05 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1595965419] SERVICE ALERT: pservercluster1;Memory;WARNING;SOFT;1;WARNING - 17.9% (4421756 kB) free!
[1595965539] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 84.2% (20774200 kB) free.
[1595965723] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 349 processes
[1595965809] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2772948 kB) free!
[1595965931] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 40.66, 41.32, 43.41
[1595965943] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2777076 kB) free!
[1595966052] SERVICE ALERT: redis-1;Memory;WARNING;SOFT;1;WARNING - 15.0% (19782720 kB) free!
[1595966172] SERVICE ALERT: redis-1;Memory;WARNING;SOFT;2;WARNING - 10.1% (13317424 kB) free!
[1595966209] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 1.8% (432884 kB) free!
[1595966292] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 4.8% (6327228 kB) free!
[1595966292] SERVICE ALERT: redis-1;Memory;CRITICAL;HARD;3;CRITICAL - 4.8% (6327228 kB) free!
[1595966329] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (185928 kB) free!
[1595966425] Auto-save of retention data completed successfully.
[1595966450] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 83.5% (20457560 kB) free.
[1595966575] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2510) < 2020/07/29 01:32:55 [error] 1786#0: *4676508 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "10.147.212.61:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595966591] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1595966876] SERVICE ALERT: smscapp2;Memory;CRITICAL;SOFT;1;CRITICAL - 0.5% (237760 kB) free!
[1595966996] SERVICE ALERT: smscapp2;Memory;CRITICAL;SOFT;2;CRITICAL - 0.5% (236640 kB) free!
[1595967049] SERVICE ALERT: sservercluster1;Memory;WARNING;SOFT;1;WARNING - 12.5% (3062836 kB) free!
[1595967116] SERVICE NOTIFICATION: nagiosadmin;smscapp2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (244312 kB) free!
[1595967116] SERVICE ALERT: smscapp2;Memory;CRITICAL;HARD;3;CRITICAL - 0.5% (244312 kB) free!
[1595967169] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (193976 kB) free!
[1595967289] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (187004 kB) free!
[1595967289] SERVICE ALERT: sservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (187004 kB) free!
[1595967409] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (237184 kB) free!
[1595967730] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1073) < 182.18.184.244 [29/Jul/2020:01:52:09 +0530] TCP 502 0 0 0.002 "10.147.212.61:5500, 10.147.212.37:5500, 10.147.212.38:5500, 10.147.212.49:5500" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.000, 0.001"
[1595967877] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1435 processes
[1595967889] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;WARNING;notify-service-by-email;WARNING - 15.3% (3756484 kB) free!
[1595967889] SERVICE ALERT: sservercluster1;Memory;WARNING;HARD;3;WARNING - 15.3% (3756484 kB) free!
[1595968124] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 773 processes
[1595968316] SERVICE NOTIFICATION: nagiosadmin;smscapp2;Memory;OK;notify-service-by-email;OK - 42.7% (21051476 kB) free.
[1595968316] SERVICE ALERT: smscapp2;Memory;OK;HARD;1;OK - 42.7% (21051476 kB) free.
[1595968489] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (176508 kB) free!
[1595968489] SERVICE ALERT: sservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.7% (176508 kB) free!
[1595968792] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (230212 kB) free!
[1595968806] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.9% (216860 kB) free!
[1595968940] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:02:11:05 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1595968989] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(123) < 2020/07/29 02:13:06 [error] 1824#0: *1518628 recv() failed (104: Connection reset by peer) while proxying connection, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.37:4000", bytes from/to client:45/0, bytes from/to upstream:0/45
[1595969323] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 348 processes
[1595969409] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.3% (2613432 kB) free!
[1595969543] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2776700 kB) free!
[1595969892] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (638868 kB) free!
[1595970009] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;OK;notify-service-by-email;OK - 75.3% (37109780 kB) free.
[1595970009] SERVICE ALERT: qservercluster2;Memory;OK;HARD;1;OK - 75.3% (37109780 kB) free.
[1595970025] Auto-save of retention data completed successfully.
[1595970175] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2588) < 2020/07/29 02:32:54 [error] 1790#0: *4720429 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "10.147.212.38:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595970192] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1026 processes
[1595970363] SERVICE FLAPPING ALERT: sservercluster1;CPU Load;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1595970592] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;OK;notify-service-by-email;OK - 81.6% (40212524 kB) free.
[1595970592] SERVICE ALERT: smscapp1;Memory;OK;HARD;1;OK - 81.6% (40212524 kB) free.
[1595970889] SERVICE FLAPPING ALERT: sservercluster1;Memory;STARTED; Service appears to have started flapping (23.0% change >= 20.0% threshold)
[1595970889] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 35.8% (8769272 kB) free.
[1595971009] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (219840 kB) free!
[1595971331] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 56.63, 51.08, 46.65
[1595971477] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1437 processes
[1595971930] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1073) < 182.18.184.244 [29/Jul/2020:03:02:09 +0530] TCP 502 0 0 0.002 "10.147.212.61:5501, 10.147.212.49:5501, 10.147.212.37:5501, 10.147.212.38:5501" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.001, 0.000"
[1595972323] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 770 processes
[1595972406] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (194776 kB) free!
[1595972541] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:03:11:05 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1595972589] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(124) < 2020/07/29 03:13:05 [error] 1819#0: *1524692 recv() failed (104: Connection reset by peer) while proxying connection, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.37:4000", bytes from/to client:45/0, bytes from/to upstream:0/45
[1595972689] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 3.0% (740616 kB) free!
[1595972809] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 77.2% (18927316 kB) free.
[1595972923] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 351 processes
[1595973131] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 20.79, 34.83, 43.12
[1595973143] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2775452 kB) free!
[1595973492] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.6% (790852 kB) free!
[1595973625] Auto-save of retention data completed successfully.
[1595974374] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2446) < 2020/07/29 03:42:54 [error] 1786#0: *4770118 access forbidden by rule while initializing session, client: 103.209.99.7, server: 0.0.0.0:13000
[1595974391] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1023 processes
[1595974609] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (217232 kB) free!
[1595974931] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 56.80, 48.51, 44.62
[1595975077] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1436 processes
[1595975763] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;SOFT;1;CRITICAL - load average: 16224.36, 13334.64, 6910.01
[1595975883] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;SOFT;2;CRITICAL - load average: 16227.17, 14291.83, 8039.75
[1595975923] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 770 processes
[1595976003] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 16228.00, 14932.44, 9032.56
[1595976003] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 16228.00, 14932.44, 9032.56
[1595976006] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.9% (221012 kB) free!
[1595976129] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1073) < 182.18.184.244 [29/Jul/2020:04:12:09 +0530] TCP 502 0 0 0.001 "10.147.212.61:5501, 10.147.212.38:5501, 10.147.212.49:5501, 10.147.212.37:5501" "0, 0, 0, 0" "0, 0, 0, 0" "0.000, 0.000, 0.001, 0.000"
[1595976141] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:04:11:05 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1595976189] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(276) < 2020/07/29 04:12:35 [error] 1809#0: *1532554 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595976523] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 349 processes
[1595976731] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 36.66, 42.00, 44.23
[1595976743] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2779988 kB) free!
[1595977092] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.6% (786528 kB) free!
[1595977225] Auto-save of retention data completed successfully.
[1595977974] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2566) < 2020/07/29 04:42:54 [error] 1787#0: *4804695 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "10.147.212.49:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595977992] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1022 processes
[1595978209] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (227696 kB) free!
[1595978531] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 60.08, 51.79, 46.50
[1595978677] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1435 processes
[1595979003] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU Load;OK;notify-service-by-email;OK - load average: 1.41, 2.25, 478.07
[1595979003] SERVICE ALERT: sservercluster1;CPU Load;OK;HARD;1;OK - load average: 1.41, 2.25, 478.07
[1595979523] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 772 processes
[1595979606] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (200412 kB) free!
[1595979730] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1072) < 182.18.184.244 [29/Jul/2020:05:12:09 +0530] TCP 502 0 0 0.000 "backend_5002" "0" "0" "0.000"
[1595979789] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/29 05:12:35 [error] 1822#0: *1546208 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595980009] SERVICE ALERT: sservercluster1;Memory;WARNING;SOFT;1;WARNING - 14.3% (3515364 kB) free!
[1595980123] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 350 processes
[1595980130] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.7% (169132 kB) free!
[1595980250] SERVICE ALERT: sservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.7% (175892 kB) free!
[1595980341] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:05:21:05 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1595980343] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2780920 kB) free!
[1595980692] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.6% (825196 kB) free!
[1595980800] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;SOFT;1;PROCS WARNING: 1502 processes
[1595980825] Auto-save of retention data completed successfully.
[1595980850] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 88.9% (21796652 kB) free.
[1595980921] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;SOFT;2;PROCS WARNING: 1501 processes
[1595981041] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 1501 processes
[1595981041] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;HARD;3;PROCS WARNING: 1501 processes
[1595981574] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2468) < 2020/07/29 05:42:54 [error] 1779#0: *4848427 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "10.147.212.37:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595981641] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Total Processes;OK;notify-service-by-email;PROCS OK: 1499 processes
[1595981641] SERVICE ALERT: sigqscluster1;Total Processes;OK;HARD;1;PROCS OK: 1499 processes
[1595981809] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (214768 kB) free!
[1595982191] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1020 processes
[1595982278] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1437 processes
[1595982731] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 45.68, 42.97, 44.75
[1595982842] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;SOFT;1;PROCS WARNING: 1507 processes
[1595982962] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;SOFT;2;PROCS WARNING: 1503 processes
[1595983082] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 1502 processes
[1595983082] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;HARD;3;PROCS WARNING: 1502 processes
[1595983123] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 773 processes
[1595983206] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (196560 kB) free!
[1595983331] SERVICE ALERT: mrq4;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 48.47, 50.73, 47.78
[1595983390] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/29 06:12:35 [error] 1824#0: *1559832 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595983723] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 350 processes
[1595983929] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1074) < 182.18.184.244 [29/Jul/2020:06:22:09 +0530] TCP 502 0 0 0.002 "10.147.212.61:5501, 10.147.212.49:5501, 10.147.212.37:5501, 10.147.212.38:5501" "0, 0, 0, 0" "0, 0, 0, 0" "0.000, 0.001, 0.001, 0.000"
[1595983941] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:06:21:05 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1595983943] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2780368 kB) free!
[1595984292] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.7% (2290172 kB) free!
[1595984425] Auto-save of retention data completed successfully.
[1595984882] SERVICE FLAPPING ALERT: sigqscluster1;Total Processes;STARTED; Service appears to have started flapping (23.2% change >= 20.0% threshold)
[1595984882] SERVICE ALERT: sigqscluster1;Total Processes;OK;HARD;1;PROCS OK: 1500 processes
[1595985174] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2436) < 2020/07/29 06:42:53 [error] 1785#0: *4891493 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5001, upstream: "10.147.212.37:5500", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595985409] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (224388 kB) free!
[1595985792] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1595986092] SERVICE NOTIFICATION: nagiosadmin;redis-1;Memory;OK;notify-service-by-email;OK - 51.2% (67551108 kB) free.
[1595986092] SERVICE ALERT: redis-1;Memory;OK;HARD;1;OK - 51.2% (67551108 kB) free.
[1595986477] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1638 processes
[1595986724] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 772 processes
[1595986806] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (198788 kB) free!
[1595987323] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 350 processes
[1595987530] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1073) < 182.18.184.244 [29/Jul/2020:07:22:09 +0530] TCP 502 0 0 0.000 "backend_5003" "0" "0" "0.000"
[1595987541] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:07:21:05 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1595987543] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2780444 kB) free!
[1595987589] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/29 07:22:35 [error] 1816#0: *1575755 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595988025] Auto-save of retention data completed successfully.
[1595988775] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2640) < 2020/07/29 07:42:54 [error] 1786#0: *4935701 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "backend_5003", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595989009] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (227356 kB) free!
[1595989991] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1022 processes
[1595990077] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1638 processes
[1595990406] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 1.0% (248944 kB) free!
[1595990923] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 770 processes
[1595990923] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 351 processes
[1595991141] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:08:21:05 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1595991143] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2773236 kB) free!
[1595991189] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/29 08:22:35 [error] 1821#0: *1589393 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595991625] Auto-save of retention data completed successfully.
[1595991729] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1072) < 182.18.184.244 [29/Jul/2020:08:32:09 +0530] TCP 502 0 0 0.000 "backend_5002" "0" "0" "0.000"
[1595992250] SERVICE FLAPPING ALERT: sservercluster1;Memory;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1595992375] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2793) < 2020/07/29 08:42:53 [error] 1789#0: *4982494 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "10.147.212.38:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595992609] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (232604 kB) free!
[1595993591] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1022 processes
[1595993677] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1638 processes
[1595994006] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (191144 kB) free!
[1595994121] SERVICE ALERT: sservercluster2;Current Users;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994166] SERVICE ALERT: sservercluster2;HDD_Home status;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1595994194] SERVICE ALERT: pservercluster2;Messages Log Status;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1595994205] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994214] SERVICE ALERT: sservercluster2;HDD_Root status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994242] SERVICE ALERT: pservercluster2;Memory;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994251] SERVICE ALERT: sservercluster2;Current Users;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994293] SERVICE ALERT: sservercluster2;CPU-STATISTICS;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994296] SERVICE ALERT: sservercluster2;HDD_Home status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994322] SERVICE ALERT: sservercluster2;CPU_Procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994324] SERVICE ALERT: pservercluster2;Messages Log Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994325] SERVICE ALERT: sservercluster2;Memory;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994326] SERVICE ALERT: sservercluster2;zombie_procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994335] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994344] SERVICE ALERT: sservercluster2;HDD_Root status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994371] SERVICE ALERT: sservercluster2;Messages Log Status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994372] SERVICE ALERT: pservercluster2;Memory;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994381] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Current Users;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994381] SERVICE ALERT: sservercluster2;Current Users;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994397] SERVICE ALERT: pservercluster2;zombie_procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994409] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994420] SERVICE ALERT: pservercluster2;Current Users;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994423] SERVICE ALERT: sservercluster2;CPU-STATISTICS;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994426] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;HDD_Home status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994426] SERVICE ALERT: sservercluster2;HDD_Home status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994441] SERVICE ALERT: pservercluster2;HDD_Home status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994452] SERVICE ALERT: sservercluster2;CPU_Procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994454] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Messages Log Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994454] SERVICE ALERT: pservercluster2;Messages Log Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994455] SERVICE ALERT: sservercluster2;Memory;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994456] SERVICE ALERT: sservercluster2;zombie_procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994458] SERVICE ALERT: pservercluster2;Total Processes;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994466] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU Load;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994466] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994474] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;HDD_Root status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994474] SERVICE ALERT: sservercluster2;HDD_Root status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994478] SERVICE ALERT: pservercluster2;HDD_Root status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994501] SERVICE ALERT: sservercluster2;Messages Log Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994502] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994502] SERVICE ALERT: pservercluster2;Memory;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994516] SERVICE ALERT: sservercluster2;Total Processes;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994520] SERVICE ALERT: sservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994523] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 769 processes
[1595994523] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 349 processes
[1595994527] SERVICE ALERT: pservercluster2;zombie_procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994536] SERVICE ALERT: sservercluster2;Open-Files;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994539] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994550] SERVICE ALERT: pservercluster2;Current Users;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994553] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU-STATISTICS;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994553] SERVICE ALERT: sservercluster2;CPU-STATISTICS;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994571] SERVICE ALERT: pservercluster2;HDD_Home status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994582] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994582] SERVICE ALERT: sservercluster2;CPU_Procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994585] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994585] SERVICE ALERT: sservercluster2;Memory;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994586] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;zombie_procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994586] SERVICE ALERT: sservercluster2;zombie_procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994588] SERVICE ALERT: sservercluster2;Sensors Status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994588] SERVICE ALERT: pservercluster2;Total Processes;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994602] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994608] SERVICE ALERT: pservercluster2;HDD_Root status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994631] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Messages Log Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994631] SERVICE ALERT: sservercluster2;Messages Log Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994646] SERVICE ALERT: sservercluster2;Total Processes;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994647] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;zombie_procs;UNKNOWN;notify-service-by-email;NRPE: Call to fork() failed
[1595994647] SERVICE ALERT: pservercluster2;zombie_procs;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595994650] SERVICE ALERT: sservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994659] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;LocalService-NTPD SERVICE;UNKNOWN;notify-service-by-email;Could not open pipe: /usr/bin/ps
[1595994659] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;UNKNOWN;HARD;3;Could not open pipe: /usr/bin/ps
[1595994666] SERVICE ALERT: sservercluster2;Open-Files;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994670] SERVICE ALERT: pservercluster2;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595994697] SERVICE ALERT: pservercluster2;CPU_Procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994701] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;HDD_Home status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994701] SERVICE ALERT: pservercluster2;HDD_Home status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994708] SERVICE ALERT: sservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1595994718] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Total Processes;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994718] SERVICE ALERT: pservercluster2;Total Processes;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994719] SERVICE ALERT: pservercluster2;CPU-STATISTICS;CRITICAL;SOFT;1;NRPE: Call to popen() failed
[1595994721] SERVICE ALERT: pservercluster2;Open-Files;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994722] SERVICE ALERT: pservercluster2;CPU Load;UNKNOWN;SOFT;2;Error opening /usr/bin/uptime
[1595994724] SERVICE ALERT: pservercluster2;Sensors Status;UNKNOWN;SOFT;1;NRPE: Unable to read output
[1595994728] SERVICE ALERT: pservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 38287 MB (74% inode=98%):
[1595994731] SERVICE FLAPPING ALERT: mrq4;CPU Load;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1595994731] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 63.32, 78.43, 83.83
[1595994741] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:09:21:05 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1595994743] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2780148 kB) free!
[1595994766] SERVICE ALERT: sservercluster2;Total Processes;OK;HARD;1;PROCS OK: 321 processes
[1595994771] SERVICE ALERT: sservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595994786] SERVICE ALERT: sservercluster2;Open-Files;OK;HARD;1;OK: 6592 open files (0% of max 2424092)
[1595994789] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/29 09:22:35 [error] 1819#0: *1601461 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595994827] SERVICE ALERT: pservercluster2;CPU_Procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994849] SERVICE ALERT: pservercluster2;CPU-STATISTICS;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994851] SERVICE ALERT: pservercluster2;Open-Files;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994852] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU Load;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994852] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994854] SERVICE ALERT: pservercluster2;Sensors Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994957] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994957] SERVICE ALERT: pservercluster2;CPU_Procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994979] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU-STATISTICS;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994979] SERVICE ALERT: pservercluster2;CPU-STATISTICS;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994981] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Current Users;OK;notify-service-by-email;USERS OK - 1 users currently logged in
[1595994981] SERVICE ALERT: sservercluster2;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595994981] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Open-Files;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994981] SERVICE ALERT: pservercluster2;Open-Files;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994984] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Sensors Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595994984] SERVICE ALERT: pservercluster2;Sensors Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995026] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;HDD_Home status;OK;notify-service-by-email;DISK OK - free space: /home 205489 MB (93% inode=99%):
[1595995026] SERVICE ALERT: sservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 205489 MB (93% inode=99%):
[1595995066] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU Load;OK;notify-service-by-email;OK - load average: 0.93, 1.13, 1.19
[1595995066] SERVICE ALERT: sservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.93, 1.13, 1.19
[1595995075] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;HDD_Root status;OK;notify-service-by-email;DISK OK - free space: / 33086 MB (64% inode=98%):
[1595995075] SERVICE ALERT: sservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 33086 MB (64% inode=98%):
[1595995082] SERVICE FLAPPING ALERT: sigqscluster1;Total Processes;STOPPED; Service appears to have stopped flapping (4.0% change < 5.0% threshold)
[1595995102] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;UNKNOWN;notify-service-by-email;NRPE: Call to fork() failed
[1595995102] SERVICE ALERT: pservercluster2;Memory;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595995158] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU-STATISTICS;OK;notify-service-by-email;CPU STATISTICS OK: user=1.57% system=5.10% iowait=0.00% idle=93.32%
[1595995158] SERVICE ALERT: sservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.57% system=5.10% iowait=0.00% idle=93.32%
[1595995182] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;OK;notify-service-by-email;CPU OK: 325 processes
[1595995182] SERVICE ALERT: sservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 325 processes
[1595995186] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;OK;notify-service-by-email;OK - 71.8% (17595424 kB) free.
[1595995186] SERVICE ALERT: sservercluster2;Memory;OK;HARD;1;OK - 71.8% (17595424 kB) free.
[1595995186] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;zombie_procs;OK;notify-service-by-email;PROCS OK: 0 processes with STATE = Z
[1595995186] SERVICE ALERT: sservercluster2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595995225] Auto-save of retention data completed successfully.
[1595995257] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;zombie_procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995257] SERVICE ALERT: pservercluster2;zombie_procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995269] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;LocalService-NTPD SERVICE;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995269] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995280] SERVICE ALERT: pservercluster2;Current Users;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995329] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1060) < 182.18.184.244 [29/Jul/2020:09:32:07 +0530] TCP 502 0 0 0.000 "backend_5003" "0" "0" "0.000"
[1595995338] SERVICE ALERT: pservercluster2;HDD_Root status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995410] SERVICE ALERT: pservercluster2;Current Users;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995468] SERVICE ALERT: pservercluster2;HDD_Root status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995540] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Current Users;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995540] SERVICE ALERT: pservercluster2;Current Users;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995598] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;HDD_Root status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995598] SERVICE ALERT: pservercluster2;HDD_Root status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995712] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995712] SERVICE ALERT: pservercluster2;Memory;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995768] SERVICE ALERT: sservercluster2;CPU-STATISTICS;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995792] SERVICE ALERT: sservercluster2;CPU_Procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995796] SERVICE ALERT: sservercluster2;Memory;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995796] SERVICE ALERT: sservercluster2;zombie_procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995898] SERVICE ALERT: sservercluster2;CPU-STATISTICS;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995918] SERVICE ALERT: sservercluster2;Sensors Status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995922] SERVICE ALERT: sservercluster2;CPU_Procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995926] SERVICE ALERT: sservercluster2;Memory;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995926] SERVICE ALERT: sservercluster2;zombie_procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995975] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2971) < 2020/07/29 09:42:52 [error] 1786#0: *5017800 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "backend_5003", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595995976] SERVICE ALERT: sservercluster2;Total Processes;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995980] SERVICE ALERT: sservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595995996] SERVICE ALERT: sservercluster2;Open-Files;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996028] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU-STATISTICS;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996028] SERVICE ALERT: sservercluster2;CPU-STATISTICS;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996048] SERVICE ALERT: sservercluster2;Sensors Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996052] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996052] SERVICE ALERT: sservercluster2;CPU_Procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996056] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996056] SERVICE ALERT: sservercluster2;Memory;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996056] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;zombie_procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996056] SERVICE ALERT: sservercluster2;zombie_procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996106] SERVICE ALERT: sservercluster2;Total Processes;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996110] SERVICE ALERT: sservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996126] SERVICE ALERT: sservercluster2;Open-Files;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996178] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Sensors Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996178] SERVICE ALERT: sservercluster2;Sensors Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996191] SERVICE ALERT: sservercluster2;Current Users;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996209] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (239708 kB) free!
[1595996229] SERVICE ALERT: pservercluster1;CPU Load;CRITICAL;SOFT;1;CRITICAL - load average: 16144.67, 10577.48, 4670.77
[1595996236] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Total Processes;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996236] SERVICE ALERT: sservercluster2;Total Processes;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996236] SERVICE ALERT: sservercluster2;HDD_Home status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996240] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;LocalService-NTPD SERVICE;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996240] SERVICE ALERT: sservercluster2;LocalService-NTPD SERVICE;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996256] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Open-Files;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996256] SERVICE ALERT: sservercluster2;Open-Files;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996276] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996285] SERVICE ALERT: sservercluster2;HDD_Root status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996321] SERVICE ALERT: sservercluster2;Current Users;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996349] SERVICE ALERT: pservercluster1;CPU Load;CRITICAL;SOFT;2;CRITICAL - load average: 16217.56, 12447.39, 6072.18
[1595996366] SERVICE ALERT: sservercluster2;HDD_Home status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996406] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996415] SERVICE ALERT: sservercluster2;HDD_Root status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996451] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Current Users;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996451] SERVICE ALERT: sservercluster2;Current Users;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996469] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 16227.50, 13698.65, 7303.70
[1595996469] SERVICE ALERT: pservercluster1;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 16227.50, 13698.65, 7303.70
[1595996496] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;HDD_Home status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996496] SERVICE ALERT: sservercluster2;HDD_Home status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996536] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU Load;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996536] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996545] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;HDD_Root status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595996545] SERVICE ALERT: sservercluster2;HDD_Root status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997050] SERVICE ALERT: sservercluster1;Memory;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1595997180] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997192] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1023 processes
[1595997277] SERVICE ALERT: sservercluster1;LocalService-NTPD SERVICE;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997277] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1637 processes
[1595997278] SERVICE ALERT: sservercluster1;HDD_Root status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997305] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CHECK_NRPE: Error - Could not complete SSL handshake.
[1595997305] SERVICE ALERT: sservercluster1;Memory;CRITICAL;HARD;3;CHECK_NRPE: Error - Could not complete SSL handshake.
[1595997305] SERVICE ALERT: sservercluster1;Current Users;CRITICAL;SOFT;1;NRPE: Call to popen() failed
[1595997306] SERVICE ALERT: sservercluster1;Sensors Status;CRITICAL;SOFT;1;NRPE: Call to popen() failed
[1595997326] SERVICE ALERT: sservercluster1;CPU-STATISTICS;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997361] SERVICE ALERT: sservercluster1;HDD_Home status;CRITICAL;SOFT;1;NRPE: Call to popen() failed
[1595997361] SERVICE ALERT: sservercluster1;zombie_procs;CRITICAL;SOFT;1;NRPE: Call to popen() failed
[1595997361] SERVICE ALERT: sservercluster1;Total Processes;CRITICAL;SOFT;1;NRPE: Call to popen() failed
[1595997363] SERVICE ALERT: sservercluster1;Open-Files;CRITICAL;SOFT;1;NRPE: Call to popen() failed
[1595997392] SERVICE ALERT: sservercluster1;CPU_Procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997397] SERVICE ALERT: sservercluster1;LocalService-NTPD SERVICE;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1595997398] SERVICE ALERT: sservercluster1;HDD_Root status;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1595997430] SERVICE ALERT: sservercluster1;Current Users;CRITICAL;SOFT;2;CHECK_NRPE: Error - Could not complete SSL handshake.
[1595997436] SERVICE ALERT: sservercluster1;Sensors Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997446] SERVICE ALERT: sservercluster1;CPU-STATISTICS;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1595997481] SERVICE ALERT: sservercluster1;Total Processes;CRITICAL;SOFT;2;CHECK_NRPE: Error - Could not complete SSL handshake.
[1595997483] SERVICE ALERT: sservercluster1;Open-Files;CRITICAL;SOFT;2;CHECK_NRPE: Error - Could not complete SSL handshake.
[1595997486] SERVICE ALERT: sservercluster1;HDD_Home status;CRITICAL;SOFT;2;CHECK_NRPE: Error - Could not complete SSL handshake.
[1595997491] SERVICE ALERT: sservercluster1;zombie_procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997522] SERVICE ALERT: sservercluster1;CPU_Procs;CRITICAL;SOFT;2;CHECK_NRPE: Error - Could not complete SSL handshake.
[1595997527] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;LocalService-NTPD SERVICE;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997527] SERVICE ALERT: sservercluster1;LocalService-NTPD SERVICE;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997528] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;HDD_Root status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997528] SERVICE ALERT: sservercluster1;HDD_Root status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997546] SERVICE ALERT: sservercluster1;Messages Log Status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997560] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Current Users;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997560] SERVICE ALERT: sservercluster1;Current Users;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997566] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Sensors Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997566] SERVICE ALERT: sservercluster1;Sensors Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997576] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU-STATISTICS;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997576] SERVICE ALERT: sservercluster1;CPU-STATISTICS;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997606] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (201288 kB) free!
[1595997606] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Total Processes;CRITICAL;notify-service-by-email;CHECK_NRPE: Error - Could not complete SSL handshake.
[1595997606] SERVICE ALERT: sservercluster1;Total Processes;CRITICAL;HARD;3;CHECK_NRPE: Error - Could not complete SSL handshake.
[1595997611] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;SOFT;1;CHECK_NRPE: Error - Could not complete SSL handshake.
[1595997613] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Open-Files;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997613] SERVICE ALERT: sservercluster1;Open-Files;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997616] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;HDD_Home status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997616] SERVICE ALERT: sservercluster1;HDD_Home status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997621] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;zombie_procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997621] SERVICE ALERT: sservercluster1;zombie_procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997652] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU_Procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997652] SERVICE ALERT: sservercluster1;CPU_Procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997676] SERVICE ALERT: sservercluster1;Messages Log Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997741] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997806] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Messages Log Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997806] SERVICE ALERT: sservercluster1;Messages Log Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997871] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU Load;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595997871] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595998065] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Messages Log Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595998123] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 349 processes
[1595998123] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 768 processes
[1595998241] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Messages Log Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595998311] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;HDD_Home status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595998328] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Total Processes;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595998331] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 71.50, 88.91, 89.07
[1595998336] SERVICE FLAPPING ALERT: sservercluster2;CPU Load;STARTED; Service appears to have started flapping (23.2% change >= 20.0% threshold)
[1595998336] SERVICE ALERT: sservercluster2;CPU Load;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595998341] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:10:21:05 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1595998344] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.7% (2784496 kB) free!
[1595998345] SERVICE FLAPPING ALERT: sservercluster2;HDD_Root status;STARTED; Service appears to have started flapping (23.2% change >= 20.0% threshold)
[1595998345] SERVICE ALERT: sservercluster2;HDD_Root status;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595998389] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/29 10:22:35 [error] 1824#0: *1603691 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1595998463] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU Load;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595998567] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595998589] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU-STATISTICS;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595998591] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Open-Files;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595998594] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Sensors Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595998825] Auto-save of retention data completed successfully.
[1595998867] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;zombie_procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595998879] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;LocalService-NTPD SERVICE;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595998930] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1059) < 182.18.184.244 [29/Jul/2020:10:32:07 +0530] TCP 502 0 0 0.001 "10.147.212.37:5501, 10.147.212.38:5501, 10.147.212.61:5501, 10.147.212.49:5501" "0, 0, 0, 0" "0, 0, 0, 0" "0.000, 0.001, 0.000, 0.000"
[1595998946] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595998955] SERVICE ALERT: sservercluster2;HDD_Root status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1595999150] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Current Users;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595999208] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;HDD_Root status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595999322] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595999328] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;LocalService-NTPD SERVICE;OK;notify-service-by-email;PROCS OK: 1 process with command name 'ntpd'
[1595999328] SERVICE ALERT: sservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595999328] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;HDD_Root status;OK;notify-service-by-email;DISK OK - free space: / 40505 MB (79% inode=99%):
[1595999328] SERVICE ALERT: sservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40505 MB (79% inode=99%):
[1595999360] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Current Users;OK;notify-service-by-email;USERS OK - 1 users currently logged in
[1595999360] SERVICE ALERT: sservercluster1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595999366] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Sensors Status;OK;notify-service-by-email;SENSORS OK
[1595999366] SERVICE ALERT: sservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1595999382] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU-STATISTICS;OK;notify-service-by-email;CPU STATISTICS OK: user=1.66% system=5.72% iowait=0.00% idle=92.62%
[1595999382] SERVICE ALERT: sservercluster1;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.66% system=5.72% iowait=0.00% idle=92.62%
[1595999407] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Total Processes;OK;notify-service-by-email;PROCS OK: 315 processes
[1595999407] SERVICE ALERT: sservercluster1;Total Processes;OK;HARD;1;PROCS OK: 315 processes
[1595999414] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Open-Files;OK;notify-service-by-email;OK: 6848 open files (0% of max 2424092)
[1595999414] SERVICE ALERT: sservercluster1;Open-Files;OK;HARD;1;OK: 6848 open files (0% of max 2424092)
[1595999416] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;HDD_Home status;OK;notify-service-by-email;DISK OK - free space: /home 174889 MB (79% inode=99%):
[1595999416] SERVICE ALERT: sservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 174889 MB (79% inode=99%):
[1595999421] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;zombie_procs;OK;notify-service-by-email;PROCS OK: 0 processes with STATE = Z
[1595999421] SERVICE ALERT: sservercluster1;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595999451] SERVICE FLAPPING ALERT: sservercluster2;Current Users;STARTED; Service appears to have started flapping (22.4% change >= 20.0% threshold)
[1595999451] SERVICE ALERT: sservercluster2;Current Users;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595999452] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU_Procs;OK;notify-service-by-email;CPU OK: 315 processes
[1595999452] SERVICE ALERT: sservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 315 processes
[1595999457] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;zombie_procs;OK;notify-service-by-email;PROCS OK: 0 processes with STATE = Z
[1595999457] SERVICE ALERT: pservercluster2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1595999469] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;LocalService-NTPD SERVICE;OK;notify-service-by-email;PROCS OK: 1 process with command name 'ntpd'
[1595999469] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1595999501] SERVICE FLAPPING ALERT: sservercluster2;HDD_Home status;STARTED; Service appears to have started flapping (22.4% change >= 20.0% threshold)
[1595999501] SERVICE ALERT: sservercluster2;HDD_Home status;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595999501] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;HDD_Home status;OK;notify-service-by-email;DISK OK - free space: /home 183099 MB (81% inode=99%):
[1595999501] SERVICE ALERT: pservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 183099 MB (81% inode=99%):
[1595999518] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Total Processes;OK;notify-service-by-email;PROCS OK: 330 processes
[1595999518] SERVICE ALERT: pservercluster2;Total Processes;OK;HARD;1;PROCS OK: 330 processes
[1595999546] SERVICE ALERT: sservercluster2;CPU Load;OK;HARD;1;OK - load average: 3.00, 1.95, 1.40
[1595999555] SERVICE ALERT: sservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 33085 MB (64% inode=98%):
[1595999611] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Messages Log Status;UNKNOWN;notify-service-by-email;NRPE: Unable to read output
[1595999611] SERVICE ALERT: sservercluster1;Messages Log Status;UNKNOWN;HARD;3;NRPE: Unable to read output
[1595999638] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU-STATISTICS;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595999652] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU Load;OK;notify-service-by-email;OK - load average: 0.89, 1.17, 1.27
[1595999652] SERVICE ALERT: pservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.89, 1.17, 1.27
[1595999662] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595999666] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595999666] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;zombie_procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595999671] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU Load;OK;notify-service-by-email;OK - load average: 1.40, 11.64, 10.17
[1595999671] SERVICE ALERT: sservercluster1;CPU Load;OK;HARD;1;OK - load average: 1.40, 11.64, 10.17
[1595999706] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;OK;notify-service-by-email;OK - 83.0% (20355196 kB) free.
[1595999706] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 83.0% (20355196 kB) free.
[1595999741] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Current Users;OK;notify-service-by-email;USERS OK - 1 users currently logged in
[1595999741] SERVICE ALERT: pservercluster2;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1595999758] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU_Procs;OK;notify-service-by-email;CPU OK: 336 processes
[1595999758] SERVICE ALERT: pservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 336 processes
[1595999781] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Open-Files;OK;notify-service-by-email;OK: 10592 open files (0% of max 2424156)
[1595999781] SERVICE ALERT: pservercluster2;Open-Files;OK;HARD;1;OK: 10592 open files (0% of max 2424156)
[1595999784] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU-STATISTICS;OK;notify-service-by-email;CPU STATISTICS OK: user=1.95% system=6.45% iowait=0.12% idle=91.47%
[1595999784] SERVICE ALERT: pservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.95% system=6.45% iowait=0.12% idle=91.47%
[1595999784] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Sensors Status;OK;notify-service-by-email;SENSORS OK
[1595999784] SERVICE ALERT: pservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1595999788] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Sensors Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595999798] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;HDD_Root status;OK;notify-service-by-email;DISK OK - free space: / 38287 MB (74% inode=98%):
[1595999798] SERVICE ALERT: pservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 38287 MB (74% inode=98%):
[1595999809] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (230000 kB) free!
[1595999846] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Total Processes;UNKNOWN;notify-service-by-email;NRPE: Call to fork() failed
[1595999846] SERVICE ALERT: sservercluster2;Total Processes;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1595999850] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;LocalService-NTPD SERVICE;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1595999856] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Open-Files;OK;notify-service-by-email;OK: 8928 open files (0% of max 2424092)
[1595999856] SERVICE ALERT: sservercluster2;Open-Files;OK;HARD;1;OK: 8928 open files (0% of max 2424092)
[1595999912] SERVICE FLAPPING ALERT: pservercluster2;Memory;STARTED; Service appears to have started flapping (21.8% change >= 20.0% threshold)
[1595999912] SERVICE ALERT: pservercluster2;Memory;OK;HARD;1;OK - 81.7% (20017700 kB) free.
[1595999928] SERVICE ALERT: sservercluster1;LocalService-NTPD SERVICE;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1595999928] SERVICE ALERT: sservercluster1;HDD_Root status;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1595999976] SERVICE ALERT: sservercluster1;Sensors Status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000048] SERVICE ALERT: sservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40504 MB (79% inode=99%):
[1596000048] SERVICE ALERT: sservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596000051] SERVICE ALERT: sservercluster2;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1596000069] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU Load;OK;notify-service-by-email;OK - load average: 3.05, 22.06, 285.52
[1596000069] SERVICE ALERT: pservercluster1;CPU Load;OK;HARD;1;OK - load average: 3.05, 22.06, 285.52
[1596000096] SERVICE ALERT: sservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1596000101] SERVICE ALERT: sservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 203552 MB (92% inode=99%):
[1596000174] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3564) < 2020/07/29 10:52:54 [error] 1786#0: *5047567 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5000, upstream: "backend_5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596000212] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Messages Log Status;CRITICAL;notify-service-by-email;(235) < Jul 29 10:49:26 sservercluster1 xinetd[1585]: nrpe: fork failed: Cannot allocate memory (errno = 12)
[1596000212] SERVICE ALERT: sservercluster1;Messages Log Status;CRITICAL;HARD;3;(235) < Jul 29 10:49:26 sservercluster1 xinetd[1585]: nrpe: fork failed: Cannot allocate memory (errno = 12)
[1596000233] SERVICE FLAPPING ALERT: sservercluster2;CPU-STATISTICS;STARTED; Service appears to have started flapping (21.8% change >= 20.0% threshold)
[1596000233] SERVICE ALERT: sservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.59% system=2.56% iowait=0.00% idle=96.85%
[1596000252] SERVICE FLAPPING ALERT: sservercluster2;CPU_Procs;STARTED; Service appears to have started flapping (21.8% change >= 20.0% threshold)
[1596000252] SERVICE ALERT: sservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 322 processes
[1596000256] SERVICE FLAPPING ALERT: sservercluster2;Memory;STARTED; Service appears to have started flapping (21.8% change >= 20.0% threshold)
[1596000256] SERVICE ALERT: sservercluster2;Memory;OK;HARD;1;OK - 78.9% (19342452 kB) free.
[1596000256] SERVICE FLAPPING ALERT: sservercluster2;zombie_procs;STARTED; Service appears to have started flapping (21.8% change >= 20.0% threshold)
[1596000256] SERVICE ALERT: sservercluster2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596000378] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Sensors Status;OK;notify-service-by-email;SENSORS OK
[1596000378] SERVICE ALERT: sservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1596000440] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;LocalService-NTPD SERVICE;OK;notify-service-by-email;PROCS OK: 1 process with command name 'ntpd'
[1596000440] SERVICE ALERT: sservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596000446] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Total Processes;OK;notify-service-by-email;PROCS OK: 322 processes
[1596000446] SERVICE ALERT: sservercluster2;Total Processes;OK;HARD;1;PROCS OK: 322 processes
[1596000454] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Messages Log Status;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1596000454] SERVICE ALERT: pservercluster2;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1596000512] SERVICE ALERT: pservercluster2;Memory;CRITICAL;SOFT;1;NRPE: Call to popen() failed
[1596000632] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Messages Log Status;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1596000632] SERVICE ALERT: sservercluster2;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1596000642] SERVICE ALERT: pservercluster2;Memory;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000667] SERVICE ALERT: pservercluster2;zombie_procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000679] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000711] SERVICE ALERT: pservercluster2;HDD_Home status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000728] SERVICE ALERT: pservercluster2;Total Processes;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000746] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;SOFT;1;CRITICAL - load average: 15678.57, 8078.47, 3263.73
[1596000772] SERVICE ALERT: pservercluster2;Memory;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000787] SERVICE ALERT: pservercluster2;zombie_procs;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1596000809] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000812] SERVICE FLAPPING ALERT: sservercluster1;Messages Log Status;STARTED; Service appears to have started flapping (23.9% change >= 20.0% threshold)
[1596000812] SERVICE ALERT: sservercluster1;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1596000831] SERVICE ALERT: pservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 182981 MB (81% inode=99%):
[1596000858] SERVICE ALERT: pservercluster2;Total Processes;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000862] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000866] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;SOFT;2;CRITICAL - load average: 16135.74, 10768.01, 4833.10
[1596000878] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1635 processes
[1596000917] SERVICE FLAPPING ALERT: pservercluster2;zombie_procs;STARTED; Service appears to have started flapping (22.2% change >= 20.0% threshold)
[1596000917] SERVICE ALERT: pservercluster2;zombie_procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000939] SERVICE FLAPPING ALERT: pservercluster2;LocalService-NTPD SERVICE;STARTED; Service appears to have started flapping (22.2% change >= 20.0% threshold)
[1596000939] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000951] SERVICE ALERT: pservercluster2;Current Users;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000968] SERVICE ALERT: pservercluster2;CPU_Procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000986] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 16197.21, 12567.59, 6212.16
[1596000988] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Total Processes;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000988] SERVICE ALERT: pservercluster2;Total Processes;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000991] SERVICE ALERT: pservercluster2;Open-Files;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000992] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000994] SERVICE ALERT: pservercluster2;CPU-STATISTICS;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596000994] SERVICE ALERT: pservercluster2;Sensors Status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001008] SERVICE ALERT: pservercluster2;HDD_Root status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001064] SERVICE ALERT: pservercluster2;Messages Log Status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001081] SERVICE ALERT: pservercluster2;Current Users;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001098] SERVICE ALERT: pservercluster2;CPU_Procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001121] SERVICE ALERT: pservercluster2;Open-Files;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001122] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU Load;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001122] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001124] SERVICE ALERT: pservercluster2;CPU-STATISTICS;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001124] SERVICE ALERT: pservercluster2;Sensors Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001138] SERVICE ALERT: pservercluster2;HDD_Root status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001194] SERVICE ALERT: pservercluster2;Messages Log Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001206] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (191920 kB) free!
[1596001211] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Current Users;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001211] SERVICE ALERT: pservercluster2;Current Users;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001228] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001228] SERVICE ALERT: pservercluster2;CPU_Procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001251] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Open-Files;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001251] SERVICE ALERT: pservercluster2;Open-Files;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001254] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU-STATISTICS;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001254] SERVICE ALERT: pservercluster2;CPU-STATISTICS;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001254] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Sensors Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001254] SERVICE ALERT: pservercluster2;Sensors Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001268] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;HDD_Root status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001268] SERVICE ALERT: pservercluster2;HDD_Root status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001314] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Messages Log Status;CRITICAL;notify-service-by-email;(192) < Jul 29 11:11:16 pservercluster2 xinetd[1483]: nrpe: fork failed: Cannot allocate memory (errno = 12)
[1596001314] SERVICE ALERT: pservercluster2;Messages Log Status;CRITICAL;HARD;3;(192) < Jul 29 11:11:16 pservercluster2 xinetd[1483]: nrpe: fork failed: Cannot allocate memory (errno = 12)
[1596001372] SERVICE ALERT: pservercluster2;Memory;OK;HARD;1;OK - 77.6% (19025572 kB) free.
[1596001391] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1596001471] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;SOFT;1;CRITICAL - load average: 15998.36, 9425.67, 3986.58
[1596001517] SERVICE ALERT: pservercluster2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596001539] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596001591] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;SOFT;2;CRITICAL - load average: 16182.10, 11670.69, 5468.76
[1596001711] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 16205.83, 13172.43, 6771.05
[1596001711] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 16205.83, 13172.43, 6771.05
[1596001723] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 769 processes
[1596001723] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 350 processes
[1596001811] SERVICE FLAPPING ALERT: pservercluster2;Current Users;STARTED; Service appears to have started flapping (23.2% change >= 20.0% threshold)
[1596001811] SERVICE ALERT: pservercluster2;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1596001851] SERVICE FLAPPING ALERT: pservercluster2;Open-Files;STARTED; Service appears to have started flapping (23.0% change >= 20.0% threshold)
[1596001851] SERVICE ALERT: pservercluster2;Open-Files;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1596001854] SERVICE FLAPPING ALERT: pservercluster2;CPU-STATISTICS;STARTED; Service appears to have started flapping (23.0% change >= 20.0% threshold)
[1596001854] SERVICE ALERT: pservercluster2;CPU-STATISTICS;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1596001854] SERVICE FLAPPING ALERT: pservercluster2;Sensors Status;STARTED; Service appears to have started flapping (23.0% change >= 20.0% threshold)
[1596001854] SERVICE ALERT: pservercluster2;Sensors Status;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1596001931] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 59.52, 77.04, 84.51
[1596001941] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:11:21:05 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1596001982] SERVICE ALERT: pservercluster2;Memory;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596001990] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(284) < 2020/07/29 11:23:09 [error] 1812#0: *1610733 recv() failed (104: Connection reset by peer) while proxying connection, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.38:4000", bytes from/to client:45/0, bytes from/to upstream:0/45
[1596002041] SERVICE ALERT: pservercluster2;HDD_Home status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596002107] SERVICE ALERT: pservercluster2;Memory;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1596002127] SERVICE ALERT: pservercluster2;zombie_procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596002149] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596002161] SERVICE ALERT: pservercluster2;HDD_Home status;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1596002188] SERVICE FLAPPING ALERT: pservercluster2;Total Processes;STARTED; Service appears to have started flapping (22.6% change >= 20.0% threshold)
[1596002188] SERVICE ALERT: pservercluster2;Total Processes;UNKNOWN;HARD;3;NRPE: Call to fork() failed
[1596002237] SERVICE ALERT: pservercluster2;Memory;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596002247] SERVICE ALERT: pservercluster2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596002269] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596002281] SERVICE ALERT: pservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 174147 MB (77% inode=99%):
[1596002425] Auto-save of retention data completed successfully.
[1596002428] SERVICE FLAPPING ALERT: pservercluster2;CPU_Procs;STARTED; Service appears to have started flapping (22.6% change >= 20.0% threshold)
[1596002428] SERVICE ALERT: pservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 336 processes
[1596002452] SERVICE ALERT: pservercluster2;Open-Files;OK;HARD;1;OK: 9216 open files (0% of max 2424156)
[1596002454] SERVICE ALERT: pservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1596002459] SERVICE ALERT: pservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.85% system=5.24% iowait=0.12% idle=92.79%
[1596002468] SERVICE FLAPPING ALERT: pservercluster2;HDD_Root status;STARTED; Service appears to have started flapping (22.8% change >= 20.0% threshold)
[1596002468] SERVICE ALERT: pservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 38287 MB (74% inode=98%):
[1596002543] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.7% (2796668 kB) free!
[1596002789] SERVICE ALERT: pservercluster2;Total Processes;OK;HARD;1;PROCS OK: 333 processes
[1596002837] SERVICE ALERT: pservercluster2;Memory;OK;HARD;1;OK - 86.9% (21310592 kB) free.
[1596003114] SERVICE FLAPPING ALERT: pservercluster2;Messages Log Status;STARTED; Service appears to have started flapping (22.2% change >= 20.0% threshold)
[1596003114] SERVICE ALERT: pservercluster2;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1596003129] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1056) < 182.18.184.244 [29/Jul/2020:11:42:09 +0530] TCP 502 0 0 0.002 "10.147.212.61:5500, 10.147.212.37:5500, 10.147.212.38:5500, 10.147.212.49:5500" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.001, 0.000"
[1596003409] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (232172 kB) free!
[1596003775] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3364) < 2020/07/29 11:52:54 [error] 1786#0: *5079950 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "10.147.212.38:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596003986] SERVICE ALERT: sservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.82, 2.76, 510.41
[1596004478] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1637 processes
[1596004722] SERVICE FLAPPING ALERT: pservercluster2;CPU Load;STARTED; Service appears to have started flapping (21.1% change >= 20.0% threshold)
[1596004722] SERVICE ALERT: pservercluster2;CPU Load;WARNING;HARD;3;WARNING - load average: 1.24, 4.93, 675.51
[1596004806] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (173592 kB) free!
[1596004991] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1020 processes
[1596005312] SERVICE FLAPPING ALERT: sservercluster1;CPU Load;STARTED; Service appears to have started flapping (21.4% change >= 20.0% threshold)
[1596005312] SERVICE ALERT: sservercluster1;CPU Load;OK;HARD;1;OK - load average: 1.87, 2.17, 349.09
[1596005322] SERVICE ALERT: pservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.79, 1.42, 354.40
[1596005323] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 350 processes
[1596005323] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 768 processes
[1596005531] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 69.88, 88.32, 91.10
[1596006025] Auto-save of retention data completed successfully.
[1596006140] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:12:31:05 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596006143] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2746528 kB) free!
[1596006190] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/29 12:32:35 [error] 1822#0: *1631074 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596006729] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1071) < 182.18.184.244 [29/Jul/2020:12:42:09 +0530] TCP 502 0 0 0.000 "backend_5000" "0" "0" "0.000"
[1596007010] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (217760 kB) free!
[1596007974] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3052) < 2020/07/29 13:02:54 [error] 1786#0: *5125842 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5000, upstream: "backend_5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596008038] SERVICE FLAPPING ALERT: sservercluster2;CPU-STATISTICS;STOPPED; Service appears to have stopped flapping (4.5% change < 5.0% threshold)
[1596008052] SERVICE FLAPPING ALERT: sservercluster2;CPU_Procs;STOPPED; Service appears to have stopped flapping (4.5% change < 5.0% threshold)
[1596008056] SERVICE FLAPPING ALERT: sservercluster2;zombie_procs;STOPPED; Service appears to have stopped flapping (4.5% change < 5.0% threshold)
[1596008057] SERVICE FLAPPING ALERT: sservercluster2;Memory;STOPPED; Service appears to have stopped flapping (4.5% change < 5.0% threshold)
[1596008407] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (192660 kB) free!
[1596008592] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1023 processes
[1596008677] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1640 processes
[1596008923] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 768 processes
[1596008923] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 349 processes
[1596009131] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 91.65, 93.88, 92.66
[1596009625] Auto-save of retention data completed successfully.
[1596009740] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(7) < 15.206.135.98 [29/Jul/2020:13:29:36 +0530] TCP 502 0 0 0.000 "10.147.212.61:14001" "0" "0" "0.000"
[1596009743] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2746396 kB) free!
[1596010329] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(995) < 182.18.184.244 [29/Jul/2020:13:42:08 +0530] TCP 502 0 0 0.000 "backend_5003" "0" "0" "0.000"
[1596010389] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/29 13:43:06 [error] 1817#0: *1651146 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596010492] SERVICE ALERT: mrq4;Memory;WARNING;SOFT;1;WARNING - 19.0% (6228324 kB) free!
[1596010612] SERVICE ALERT: mrq4;Memory;WARNING;SOFT;2;WARNING - 18.8% (6160184 kB) free!
[1596010732] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;WARNING;notify-service-by-email;WARNING - 18.6% (6081132 kB) free!
[1596010732] SERVICE ALERT: mrq4;Memory;WARNING;HARD;3;WARNING - 18.6% (6081132 kB) free!
[1596010955] SERVICE FLAPPING ALERT: sservercluster2;HDD_Root status;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1596010955] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;HDD_Root status;OK;notify-service-by-email;DISK OK - free space: / 33084 MB (64% inode=98%):
[1596011209] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (218140 kB) free!
[1596011451] SERVICE FLAPPING ALERT: sservercluster2;Current Users;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1596011451] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Current Users;OK;notify-service-by-email;USERS OK - 1 users currently logged in
[1596011501] SERVICE FLAPPING ALERT: sservercluster2;HDD_Home status;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1596011501] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;HDD_Home status;OK;notify-service-by-email;DISK OK - free space: /home 199847 MB (90% inode=99%):
[1596011574] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2671) < 2020/07/29 14:02:52 [error] 1782#0: *5162124 recv() failed (104: Connection reset by peer) while proxying connection, client: 103.16.101.72, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:43/0, bytes from/to upstream:0/43
[1596012212] SERVICE FLAPPING ALERT: sservercluster1;Messages Log Status;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1596012277] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1636 processes
[1596012523] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 350 processes
[1596012523] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 770 processes
[1596012606] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 1.0% (242616 kB) free!
[1596012731] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 77.51, 81.16, 81.83
[1596012791] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1596012940] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 7.1% (1742436 kB) free!
[1596012986] SERVICE FLAPPING ALERT: sservercluster2;CPU Load;STOPPED; Service appears to have stopped flapping (4.3% change < 5.0% threshold)
[1596012986] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU Load;OK;notify-service-by-email;OK - load average: 1.98, 1.78, 1.44
[1596013047] SERVICE FLAPPING ALERT: pservercluster2;zombie_procs;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1596013047] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;zombie_procs;OK;notify-service-by-email;PROCS OK: 0 processes with STATE = Z
[1596013060] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 5.7% (1404540 kB) free!
[1596013069] SERVICE FLAPPING ALERT: pservercluster2;LocalService-NTPD SERVICE;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1596013069] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;LocalService-NTPD SERVICE;OK;notify-service-by-email;PROCS OK: 1 process with command name 'ntpd'
[1596013180] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.4% (1332152 kB) free!
[1596013180] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 5.4% (1332152 kB) free!
[1596013211] SERVICE FLAPPING ALERT: pservercluster2;Current Users;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1596013225] Auto-save of retention data completed successfully.
[1596013228] SERVICE FLAPPING ALERT: pservercluster2;CPU_Procs;STOPPED; Service appears to have stopped flapping (3.9% change < 5.0% threshold)
[1596013268] SERVICE FLAPPING ALERT: pservercluster2;HDD_Root status;STOPPED; Service appears to have stopped flapping (3.9% change < 5.0% threshold)
[1596013314] SERVICE FLAPPING ALERT: pservercluster2;Messages Log Status;STOPPED; Service appears to have stopped flapping (4.0% change < 5.0% threshold)
[1596013340] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:14:29:36 +0530] TCP 502 0 0 0.000 "10.147.212.61:14001" "0" "0" "0.000"
[1596013343] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2752404 kB) free!
[1596013712] SERVICE FLAPPING ALERT: sservercluster1;CPU Load;STOPPED; Service appears to have stopped flapping (4.4% change < 5.0% threshold)
[1596013780] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;OK;notify-service-by-email;OK - 70.8% (17482668 kB) free.
[1596013780] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 70.8% (17482668 kB) free.
[1596013852] SERVICE FLAPPING ALERT: pservercluster2;Open-Files;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1596013852] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Open-Files;OK;notify-service-by-email;OK: 10240 open files (0% of max 2424156)
[1596013854] SERVICE FLAPPING ALERT: pservercluster2;Sensors Status;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1596013854] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Sensors Status;OK;notify-service-by-email;SENSORS OK
[1596013864] SERVICE FLAPPING ALERT: pservercluster2;CPU-STATISTICS;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1596013864] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU-STATISTICS;OK;notify-service-by-email;CPU STATISTICS OK: user=4.85% system=10.37% iowait=0.00% idle=84.78%
[1596013930] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1015) < 182.18.184.244 [29/Jul/2020:14:42:09 +0530] TCP 502 0 0 0.000 "backend_5002" "0" "0" "0.000"
[1596013990] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(8) < 2020/07/29 14:43:06 [error] 1815#0: *1667916 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14000, upstream: "10.147.212.49:5000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596014190] SERVICE FLAPPING ALERT: pservercluster2;Total Processes;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1596014190] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Total Processes;OK;notify-service-by-email;PROCS OK: 331 processes
[1596014237] SERVICE FLAPPING ALERT: pservercluster2;Memory;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1596014332] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;WARNING;notify-service-by-email;WARNING - 15.7% (5132352 kB) free!
[1596014810] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (219932 kB) free!
[1596015175] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2606) < 2020/07/29 15:02:54 [error] 1786#0: *5197505 recv() failed (104: Connection reset by peer) while proxying connection, client: 103.16.101.72, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:44/0, bytes from/to upstream:0/44
[1596015482] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;SOFT;1;PROCS WARNING: 1508 processes
[1596015592] SERVICE ALERT: smscapp1;Memory;WARNING;SOFT;1;WARNING - 19.9% (9798660 kB) free!
[1596015602] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;SOFT;2;PROCS WARNING: 1504 processes
[1596015712] SERVICE ALERT: smscapp1;Memory;WARNING;SOFT;2;WARNING - 19.7% (9725264 kB) free!
[1596015723] SERVICE ALERT: sigqscluster1;Total Processes;OK;HARD;1;PROCS OK: 1499 processes
[1596015832] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;WARNING;notify-service-by-email;WARNING - 19.6% (9652136 kB) free!
[1596015832] SERVICE ALERT: smscapp1;Memory;WARNING;HARD;3;WARNING - 19.6% (9652136 kB) free!
[1596015877] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1635 processes
[1596016123] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 769 processes
[1596016124] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 350 processes
[1596016206] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.9% (208996 kB) free!
[1596016331] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 94.40, 78.94, 79.51
[1596016391] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1023 processes
[1596016722] SERVICE FLAPPING ALERT: pservercluster2;CPU Load;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1596016722] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU Load;OK;notify-service-by-email;OK - load average: 2.42, 2.07, 1.81
[1596016825] Auto-save of retention data completed successfully.
[1596016922] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;SOFT;1;PROCS WARNING: 1502 processes
[1596016941] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(6) < 15.206.135.98 [29/Jul/2020:15:30:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596016943] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2753428 kB) free!
[1596017043] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;SOFT;2;PROCS WARNING: 1505 processes
[1596017163] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 1504 processes
[1596017163] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;HARD;3;PROCS WARNING: 1504 processes
[1596017530] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(964) < 182.18.184.244 [29/Jul/2020:15:42:09 +0530] TCP 502 0 0 0.002 "10.147.212.37:5500, 10.147.212.61:5500, 10.147.212.49:5500, 10.147.212.38:5500" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.000, 0.001"
[1596017590] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/29 15:42:37 [error] 1819#0: *1685216 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596017763] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Total Processes;OK;notify-service-by-email;PROCS OK: 1500 processes
[1596017763] SERVICE ALERT: sigqscluster1;Total Processes;OK;HARD;1;PROCS OK: 1500 processes
[1596017932] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;WARNING;notify-service-by-email;WARNING - 13.9% (4558592 kB) free!
[1596018363] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;SOFT;1;PROCS WARNING: 1502 processes
[1596018484] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;SOFT;2;PROCS WARNING: 1506 processes
[1596018604] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 1502 processes
[1596018604] SERVICE ALERT: sigqscluster1;Total Processes;WARNING;HARD;3;PROCS WARNING: 1502 processes
[1596018998] SERVICE ALERT: webservercluster1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 321 processes
[1596019009] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (253076 kB) free!
[1596019118] SERVICE ALERT: webservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 319 processes
[1596019375] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2719) < 2020/07/29 16:12:54 [error] 1782#0: *5239437 connect() failed (111: Connection refused) while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "10.147.212.49:5501", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596019432] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;WARNING;notify-service-by-email;WARNING - 13.3% (6535468 kB) free!
[1596019477] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1639 processes
[1596019724] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 769 processes
[1596019806] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (198652 kB) free!
[1596019931] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 77.29, 81.32, 85.04
[1596019992] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1023 processes
[1596020323] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 354 processes
[1596020425] Auto-save of retention data completed successfully.
[1596020543] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2741164 kB) free!
[1596020632] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 10.0% (4935952 kB) free!
[1596020632] SERVICE ALERT: smscapp1;Memory;CRITICAL;HARD;3;CRITICAL - 10.0% (4935952 kB) free!
[1596020932] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;CRITICAL;notify-service-by-email;CRITICAL - 10.0% (3263540 kB) free!
[1596020932] SERVICE ALERT: mrq4;Memory;CRITICAL;HARD;3;CRITICAL - 10.0% (3263540 kB) free!
[1596021130] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1071) < 182.18.184.244 [29/Jul/2020:16:42:07 +0530] TCP 502 0 0 0.001 "10.147.212.61:5501, 10.147.212.38:5501, 10.147.212.37:5501, 10.147.212.49:5501" "0, 0, 0, 0" "0, 0, 0, 0" "0.000, 0.001, 0.000, 0.000"
[1596021140] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:16:40:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596021190] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/29 16:42:37 [error] 1820#0: *1702590 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596022204] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 1503 processes
[1596022610] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (218080 kB) free!
[1596022718] SERVICE ALERT: webservercluster1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 2 warn out of 319 processes
[1596022732] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;WARNING;notify-service-by-email;WARNING - 10.8% (3520604 kB) free!
[1596022732] SERVICE ALERT: mrq4;Memory;WARNING;HARD;3;WARNING - 10.8% (3520604 kB) free!
[1596022838] SERVICE ALERT: webservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 318 processes
[1596022975] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2741) < 2020/07/29 17:12:54 [error] 1786#0: *5275227 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "backend_5003", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596023077] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1637 processes
[1596023324] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 770 processes
[1596023332] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;CRITICAL;notify-service-by-email;CRITICAL - 9.9% (3234036 kB) free!
[1596023332] SERVICE ALERT: mrq4;Memory;CRITICAL;HARD;3;CRITICAL - 9.9% (3234036 kB) free!
[1596023406] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (200032 kB) free!
[1596023531] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 65.59, 77.81, 82.38
[1596023923] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 351 processes
[1596024025] Auto-save of retention data completed successfully.
[1596024143] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.5% (2733328 kB) free!
[1596024191] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1019 processes
[1596024232] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 3.8% (1867424 kB) free!
[1596024604] SERVICE FLAPPING ALERT: sigqscluster1;Total Processes;STARTED; Service appears to have started flapping (20.7% change >= 20.0% threshold)
[1596024604] SERVICE ALERT: sigqscluster1;Total Processes;OK;HARD;1;PROCS OK: 1498 processes
[1596024730] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1072) < 182.18.184.244 [29/Jul/2020:17:42:09 +0530] TCP 502 0 0 0.000 "backend_5000" "0" "0" "0.000"
[1596024741] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:17:40:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596024790] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/29 17:42:37 [error] 1824#0: *1720032 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596026677] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1640 processes
[1596026809] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (228252 kB) free!
[1596026933] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;CRITICAL;notify-service-by-email;CRITICAL - 7.9% (2591552 kB) free!
[1596027006] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (189808 kB) free!
[1596027009] SERVICE ALERT: qservercluster2;Memory;WARNING;SOFT;1;WARNING - 19.4% (9571768 kB) free!
[1596027129] SERVICE ALERT: qservercluster2;Memory;WARNING;SOFT;2;WARNING - 19.3% (9489672 kB) free!
[1596027131] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 81.81, 95.90, 88.55
[1596027175] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3317) < 2020/07/29 18:22:54 [error] 1786#0: *5318608 recv() failed (104: Connection reset by peer) while proxying connection, client: 85.10.207.167, server: 0.0.0.0:13000, upstream: "10.147.212.143:13000", bytes from/to client:41/0, bytes from/to upstream:0/41
[1596027249] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 19.1% (9408376 kB) free!
[1596027249] SERVICE ALERT: qservercluster2;Memory;WARNING;HARD;3;WARNING - 19.1% (9408376 kB) free!
[1596027523] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 771 processes
[1596027523] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 354 processes
[1596027625] Auto-save of retention data completed successfully.
[1596027743] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.5% (2732860 kB) free!
[1596027791] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1596027833] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.6% (300004 kB) free!
[1596028269] SERVICE ALERT: pservercluster1;CPU Load;CRITICAL;SOFT;1;CRITICAL - load average: 14856.21, 6389.11, 2415.56
[1596028330] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1060) < 182.18.184.244 [29/Jul/2020:18:42:08 +0530] TCP 502 0 0 0.002 "10.147.212.61:5501, 10.147.212.37:5501, 10.147.212.49:5501, 10.147.212.38:5501" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.001, 0.000"
[1596028389] SERVICE ALERT: pservercluster1;CPU Load;CRITICAL;SOFT;2;CRITICAL - load average: 15999.21, 9627.85, 4084.19
[1596028391] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(7) < 2020/07/29 18:42:49 [error] 1823#0: *1735028 recv() failed (104: Connection reset by peer) while proxying connection, client: 103.16.101.72, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:45/0, bytes from/to upstream:0/45
[1596028509] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 16153.12, 11794.79, 5550.43
[1596028509] SERVICE ALERT: pservercluster1;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 16153.12, 11794.79, 5550.43
[1596028666] SERVICE ALERT: sservercluster2;Open-Files;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596028712] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;SOFT;1;CRITICAL - load average: 15851.27, 13074.80, 6800.25
[1596028786] SERVICE ALERT: sservercluster2;Open-Files;UNKNOWN;SOFT;2;NRPE: Call to fork() failed
[1596028832] SERVICE ALERT: sservercluster2;Messages Log Status;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1596028832] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;SOFT;2;CRITICAL - load average: 15854.21, 13994.58, 7898.09
[1596028861] SERVICE ALERT: sservercluster2;Current Users;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596028901] SERVICE ALERT: sservercluster2;HDD_Home status;UNKNOWN;SOFT;1;NRPE: Call to fork() failed
[1596028916] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Open-Files;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596028916] SERVICE ALERT: sservercluster2;Open-Files;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596028940] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:18:50:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596028952] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 15854.39, 14610.01, 8862.81
[1596028952] SERVICE ALERT: sservercluster1;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 15854.39, 14610.01, 8862.81
[1596028962] SERVICE ALERT: sservercluster2;Messages Log Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596028965] SERVICE ALERT: sservercluster2;HDD_Root status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596028991] SERVICE ALERT: sservercluster2;Current Users;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029031] SERVICE ALERT: sservercluster2;HDD_Home status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029043] SERVICE ALERT: sservercluster2;CPU-STATISTICS;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029062] SERVICE ALERT: sservercluster2;CPU_Procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029066] SERVICE ALERT: sservercluster2;Memory;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029066] SERVICE ALERT: sservercluster2;zombie_procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029092] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Messages Log Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029092] SERVICE ALERT: sservercluster2;Messages Log Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029095] SERVICE ALERT: sservercluster2;HDD_Root status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029121] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Current Users;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029121] SERVICE ALERT: sservercluster2;Current Users;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029161] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;HDD_Home status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029161] SERVICE ALERT: sservercluster2;HDD_Home status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029173] SERVICE ALERT: sservercluster2;CPU-STATISTICS;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029188] SERVICE ALERT: sservercluster2;Sensors Status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029192] SERVICE ALERT: sservercluster2;CPU_Procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029196] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029196] SERVICE ALERT: sservercluster2;Memory;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029196] SERVICE ALERT: sservercluster2;zombie_procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029225] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;HDD_Root status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029225] SERVICE ALERT: sservercluster2;HDD_Root status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029250] SERVICE ALERT: sservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029256] SERVICE ALERT: sservercluster2;Total Processes;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029303] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU-STATISTICS;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029303] SERVICE ALERT: sservercluster2;CPU-STATISTICS;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029318] SERVICE ALERT: sservercluster2;Sensors Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029322] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029322] SERVICE ALERT: sservercluster2;CPU_Procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029326] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029326] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029326] SERVICE ALERT: sservercluster2;Memory;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029326] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;zombie_procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029326] SERVICE ALERT: sservercluster2;zombie_procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029380] SERVICE ALERT: sservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029386] SERVICE ALERT: sservercluster2;Total Processes;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029448] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Sensors Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029448] SERVICE ALERT: sservercluster2;Sensors Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029456] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU Load;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029456] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029510] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;LocalService-NTPD SERVICE;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029510] SERVICE ALERT: sservercluster2;LocalService-NTPD SERVICE;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029516] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Total Processes;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029516] SERVICE ALERT: sservercluster2;Total Processes;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596029721] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Current Users;OK;notify-service-by-email;USERS OK - 1 users currently logged in
[1596029721] SERVICE ALERT: sservercluster2;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1596029761] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;HDD_Home status;OK;notify-service-by-email;DISK OK - free space: /home 191098 MB (86% inode=99%):
[1596029761] SERVICE ALERT: sservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 191098 MB (86% inode=99%):
[1596029825] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;HDD_Root status;OK;notify-service-by-email;DISK OK - free space: / 33083 MB (64% inode=98%):
[1596029825] SERVICE ALERT: sservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 33083 MB (64% inode=98%):
[1596029908] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU-STATISTICS;OK;notify-service-by-email;CPU STATISTICS OK: user=0.82% system=3.57% iowait=0.00% idle=95.61%
[1596029908] SERVICE ALERT: sservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=0.82% system=3.57% iowait=0.00% idle=95.61%
[1596029922] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU_Procs;OK;notify-service-by-email;CPU OK: 321 processes
[1596029922] SERVICE ALERT: sservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 321 processes
[1596029926] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;OK;notify-service-by-email;OK - 84.8% (20787748 kB) free.
[1596029926] SERVICE ALERT: sservercluster2;Memory;OK;HARD;1;OK - 84.8% (20787748 kB) free.
[1596029926] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;zombie_procs;OK;notify-service-by-email;PROCS OK: 0 processes with STATE = Z
[1596029926] SERVICE ALERT: sservercluster2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596030048] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Sensors Status;OK;notify-service-by-email;SENSORS OK
[1596030048] SERVICE ALERT: sservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1596030056] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU Load;OK;notify-service-by-email;OK - load average: 1.16, 4.77, 4.00
[1596030056] SERVICE ALERT: sservercluster2;CPU Load;OK;HARD;1;OK - load average: 1.16, 4.77, 4.00
[1596030110] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;LocalService-NTPD SERVICE;OK;notify-service-by-email;PROCS OK: 1 process with command name 'ntpd'
[1596030110] SERVICE ALERT: sservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596030116] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Open-Files;OK;notify-service-by-email;OK: 6944 open files (0% of max 2424092)
[1596030116] SERVICE ALERT: sservercluster2;Open-Files;OK;HARD;1;OK: 6944 open files (0% of max 2424092)
[1596030116] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Total Processes;OK;notify-service-by-email;PROCS OK: 320 processes
[1596030116] SERVICE ALERT: sservercluster2;Total Processes;OK;HARD;1;PROCS OK: 320 processes
[1596030277] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1637 processes
[1596030292] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Messages Log Status;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1596030292] SERVICE ALERT: sservercluster2;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1596030399] SERVICE ALERT: pservercluster2;Total Processes;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030410] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (244988 kB) free!
[1596030447] SERVICE ALERT: pservercluster2;Memory;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030452] SERVICE ALERT: pservercluster2;zombie_procs;CRITICAL;SOFT;1;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596030479] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030491] SERVICE ALERT: pservercluster2;HDD_Home status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030529] SERVICE ALERT: pservercluster2;Total Processes;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030532] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030577] SERVICE ALERT: pservercluster2;Memory;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030582] SERVICE ALERT: pservercluster2;zombie_procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030604] SERVICE FLAPPING ALERT: sigqscluster1;Total Processes;STOPPED; Service appears to have stopped flapping (4.9% change < 5.0% threshold)
[1596030606] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (174392 kB) free!
[1596030609] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030621] SERVICE ALERT: pservercluster2;Current Users;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030621] SERVICE ALERT: pservercluster2;HDD_Home status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030638] SERVICE ALERT: pservercluster2;CPU_Procs;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030656] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;SOFT;1;CRITICAL - load average: 16121.47, 10739.52, 4785.03
[1596030659] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Total Processes;CRITICAL;notify-service-by-email;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596030659] SERVICE ALERT: pservercluster2;Total Processes;CRITICAL;HARD;3;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596030659] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;SOFT;2;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596030662] SERVICE ALERT: pservercluster2;Open-Files;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030664] SERVICE ALERT: pservercluster2;Sensors Status;CRITICAL;SOFT;1;CHECK_NRPE: Error - Could not complete SSL handshake.
[1596030669] SERVICE ALERT: pservercluster2;CPU-STATISTICS;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030678] SERVICE ALERT: pservercluster2;HDD_Root status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030707] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030707] SERVICE ALERT: pservercluster2;Memory;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030712] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;zombie_procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030712] SERVICE ALERT: pservercluster2;zombie_procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030724] SERVICE ALERT: pservercluster2;Messages Log Status;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030731] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 69.10, 76.01, 74.70
[1596030739] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;LocalService-NTPD SERVICE;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030739] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030751] SERVICE ALERT: pservercluster2;Current Users;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030751] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;HDD_Home status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030751] SERVICE ALERT: pservercluster2;HDD_Home status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030768] SERVICE ALERT: pservercluster2;CPU_Procs;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030775] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2684) < 2020/07/29 19:22:54 [error] 1786#0: *5345613 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5002, upstream: "backend_5002", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596030776] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;SOFT;2;CRITICAL - load average: 16183.34, 12543.87, 6168.21
[1596030789] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU Load;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030789] SERVICE ALERT: pservercluster2;CPU Load;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030792] SERVICE ALERT: pservercluster2;Open-Files;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030794] SERVICE ALERT: pservercluster2;Sensors Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030799] SERVICE ALERT: pservercluster2;CPU-STATISTICS;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030808] SERVICE ALERT: pservercluster2;HDD_Root status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030850] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 15.5% (7618700 kB) free!
[1596030854] SERVICE ALERT: pservercluster2;Messages Log Status;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030881] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Current Users;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030881] SERVICE ALERT: pservercluster2;Current Users;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030896] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 16191.55, 13751.23, 7383.69
[1596030896] SERVICE ALERT: sservercluster2;CPU Load;CRITICAL;HARD;3;CRITICAL - load average: 16191.55, 13751.23, 7383.69
[1596030898] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030898] SERVICE ALERT: pservercluster2;CPU_Procs;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030922] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Open-Files;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030922] SERVICE ALERT: pservercluster2;Open-Files;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030924] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Sensors Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030924] SERVICE ALERT: pservercluster2;Sensors Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030929] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU-STATISTICS;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030929] SERVICE ALERT: pservercluster2;CPU-STATISTICS;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030938] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;HDD_Root status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030938] SERVICE ALERT: pservercluster2;HDD_Root status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030984] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Messages Log Status;CRITICAL;notify-service-by-email;CHECK_NRPE: Socket timeout after 10 seconds.
[1596030984] SERVICE ALERT: pservercluster2;Messages Log Status;CRITICAL;HARD;3;CHECK_NRPE: Socket timeout after 10 seconds.
[1596031123] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 351 processes
[1596031123] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 772 processes
[1596031132] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.4% (1774896 kB) free!
[1596031225] Auto-save of retention data completed successfully.
[1596031344] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2743820 kB) free!
[1596031392] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1020 processes
[1596031952] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU Load;WARNING;notify-service-by-email;WARNING - load average: 1.37, 3.18, 547.24
[1596031952] SERVICE ALERT: sservercluster1;CPU Load;WARNING;HARD;3;WARNING - load average: 1.37, 3.18, 547.24
[1596032032] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (337032 kB) free!
[1596032081] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Current Users;OK;notify-service-by-email;USERS OK - 2 users currently logged in
[1596032081] SERVICE ALERT: pservercluster2;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1596032098] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU_Procs;OK;notify-service-by-email;CPU OK: 331 processes
[1596032098] SERVICE ALERT: pservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 331 processes
[1596032109] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU Load;WARNING;notify-service-by-email;WARNING - load average: 0.93, 1.74, 363.74
[1596032109] SERVICE ALERT: pservercluster1;CPU Load;WARNING;HARD;3;WARNING - load average: 0.93, 1.74, 363.74
[1596032122] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Open-Files;OK;notify-service-by-email;OK: 10080 open files (0% of max 2424156)
[1596032122] SERVICE ALERT: pservercluster2;Open-Files;OK;HARD;1;OK: 10080 open files (0% of max 2424156)
[1596032124] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Sensors Status;OK;notify-service-by-email;SENSORS OK
[1596032124] SERVICE ALERT: pservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1596032134] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU-STATISTICS;OK;notify-service-by-email;CPU STATISTICS OK: user=1.69% system=5.65% iowait=0.00% idle=92.66%
[1596032134] SERVICE ALERT: pservercluster2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=1.69% system=5.65% iowait=0.00% idle=92.66%
[1596032138] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;HDD_Root status;OK;notify-service-by-email;DISK OK - free space: / 38285 MB (74% inode=98%):
[1596032138] SERVICE ALERT: pservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 38285 MB (74% inode=98%):
[1596032459] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Total Processes;OK;notify-service-by-email;PROCS OK: 334 processes
[1596032459] SERVICE ALERT: pservercluster2;Total Processes;OK;HARD;1;PROCS OK: 334 processes
[1596032507] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;OK;notify-service-by-email;OK - 86.3% (21154876 kB) free.
[1596032507] SERVICE ALERT: pservercluster2;Memory;OK;HARD;1;OK - 86.3% (21154876 kB) free.
[1596032512] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;zombie_procs;OK;notify-service-by-email;PROCS OK: 0 processes with STATE = Z
[1596032512] SERVICE ALERT: pservercluster2;zombie_procs;OK;HARD;1;PROCS OK: 0 processes with STATE = Z
[1596032529] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1026) < 182.18.184.244 [29/Jul/2020:19:52:08 +0530] TCP 502 0 0 0.000 "backend_5000" "0" "0" "0.000"
[1596032539] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;LocalService-NTPD SERVICE;OK;notify-service-by-email;PROCS OK: 1 process with command name 'ntpd'
[1596032539] SERVICE ALERT: pservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1596032541] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:19:50:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596032551] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;HDD_Home status;OK;notify-service-by-email;DISK OK - free space: /home 171900 MB (76% inode=99%):
[1596032551] SERVICE ALERT: pservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 171900 MB (76% inode=99%):
[1596032552] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;CPU Load;OK;notify-service-by-email;OK - load average: 1.62, 2.25, 287.79
[1596032552] SERVICE ALERT: sservercluster1;CPU Load;OK;HARD;1;OK - load average: 1.62, 2.25, 287.79
[1596032589] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;CPU Load;OK;notify-service-by-email;OK - load average: 1.21, 1.31, 1.28
[1596032589] SERVICE ALERT: pservercluster2;CPU Load;OK;HARD;1;OK - load average: 1.21, 1.31, 1.28
[1596032591] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(54) < 2020/07/29 19:52:37 [error] 1818#0: *1743421 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596032709] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;CPU Load;OK;notify-service-by-email;OK - load average: 1.27, 1.36, 191.18
[1596032709] SERVICE ALERT: pservercluster1;CPU Load;OK;HARD;1;OK - load average: 1.27, 1.36, 191.18
[1596032784] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Messages Log Status;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1596032784] SERVICE ALERT: pservercluster2;Messages Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1596033296] SERVICE FLAPPING ALERT: sservercluster2;CPU Load;STARTED; Service appears to have started flapping (23.0% change >= 20.0% threshold)
[1596033296] SERVICE ALERT: sservercluster2;CPU Load;WARNING;HARD;3;WARNING - load average: 0.79, 10.11, 843.78
[1596033878] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1639 processes
[1596033897] SERVICE ALERT: sservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.54, 1.81, 442.39
[1596034206] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (183496 kB) free!
[1596034331] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 64.95, 72.70, 70.79
[1596034375] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2632) < 2020/07/29 20:22:54 [error] 1786#0: *5378622 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "backend_5003", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596034609] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.9% (458284 kB) free!
[1596034723] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 354 processes
[1596034723] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 774 processes
[1596034732] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;CRITICAL;notify-service-by-email;CRITICAL - 4.7% (1546628 kB) free!
[1596034825] Auto-save of retention data completed successfully.
[1596035049] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 13.8% (6778656 kB) free!
[1596035543] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.5% (2730628 kB) free!
[1596035591] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1596035633] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (336668 kB) free!
[1596036129] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(1073) < 182.18.184.244 [29/Jul/2020:20:52:09 +0530] TCP 502 0 0 0.002 "10.147.212.61:5501, 10.147.212.37:5501, 10.147.212.38:5501, 10.147.212.49:5501" "0, 0, 0, 0" "0, 0, 0, 0" "0.001, 0.000, 0.001, 0.000"
[1596036740] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:21:00:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596036791] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/29 21:02:37 [error] 1822#0: *1763042 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596037133] SERVICE NOTIFICATION: nagiosadmin;mrq4;Memory;OK;notify-service-by-email;OK - 44.6% (14598008 kB) free.
[1596037133] SERVICE ALERT: mrq4;Memory;OK;HARD;1;OK - 44.6% (14598008 kB) free.
[1596037806] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (180804 kB) free!
[1596037931] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 53.34, 57.56, 59.56
[1596038077] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1436 processes
[1596038209] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (373400 kB) free!
[1596038323] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 356 processes
[1596038323] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 772 processes
[1596038425] Auto-save of retention data completed successfully.
[1596038575] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(2242) < 2020/07/29 21:32:54 [error] 1786#0: *5418276 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5003, upstream: "backend_5003", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596038649] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 12.7% (6252512 kB) free!
[1596039143] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.5% (2731204 kB) free!
[1596039191] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1021 processes
[1596039730] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(809) < 182.18.184.244 [29/Jul/2020:21:52:10 +0530] TCP 502 0 0 0.002 "10.147.212.61:5501, 10.147.212.38:5501, 10.147.212.37:5501, 10.147.212.49:5501" "0, 0, 0, 0" "0, 0, 0, 0" "0.000, 0.001, 0.000, 0.001"
[1596039832] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (237144 kB) free!
[1596039905] SERVICE ALERT: smscapp2;CPU-STATISTICS;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1596040035] SERVICE ALERT: smscapp2;CPU-STATISTICS;CRITICAL;SOFT;2;CHECK_NRPE: Socket timeout after 10 seconds.
[1596040161] SERVICE ALERT: smscapp2;CPU-STATISTICS;OK;HARD;1;CPU STATISTICS OK: user=10.42% system=32.84% iowait=6.20% idle=50.54%
[1596040341] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:22:00:07 +0530] TCP 502 0 0 0.000 "10.147.212.49:5000" "0" "0" "0.000"
[1596040990] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(415) < 2020/07/29 22:12:37 [error] 1822#0: *1779258 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596041406] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (180508 kB) free!
[1596041531] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;CRITICAL;notify-service-by-email;CRITICAL - load average: 36.32, 45.81, 52.61
[1596041677] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1438 processes
[1596041809] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (371872 kB) free!
[1596041923] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 352 processes
[1596041923] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 773 processes
[1596042025] Auto-save of retention data completed successfully.
[1596042249] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 11.9% (5851080 kB) free!
[1596042743] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.6% (2766708 kB) free!
[1596042775] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(1781) < 2020/07/29 22:42:52 [error] 1786#0: *5463412 no live upstreams while connecting to upstream, client: 182.18.184.244, server: 0.0.0.0:5001, upstream: "backend_5001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596042791] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1019 processes
[1596043432] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (228012 kB) free!
[1596043929] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(700) < 182.18.184.244 [29/Jul/2020:23:02:09 +0530] TCP 502 0 0 0.000 "backend_5002" "0" "0" "0.000"
[1596044540] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Access Log Status;CRITICAL;notify-service-by-email;(4) < 15.206.135.98 [29/Jul/2020:23:10:07 +0530] TCP 502 0 0 0.001 "10.147.212.49:5000" "0" "0" "0.001"
[1596044590] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2020/07/29 23:12:37 [error] 1823#0: *1792616 connect() failed (111: Connection refused) while connecting to upstream, client: 15.206.135.98, server: 0.0.0.0:14001, upstream: "10.147.212.61:14001", bytes from/to client:0/0, bytes from/to upstream:0/0
[1596045006] SERVICE NOTIFICATION: nagiosadmin;secondary-server;Memory Status;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (195604 kB) free!
[1596045131] SERVICE NOTIFICATION: nagiosadmin;mrq4;CPU Load;WARNING;notify-service-by-email;WARNING - load average: 32.82, 39.53, 43.80
[1596045131] SERVICE ALERT: mrq4;CPU Load;WARNING;HARD;3;WARNING - load average: 32.82, 39.53, 43.80
[1596045277] SERVICE NOTIFICATION: nagiosadmin;mrq4;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1440 processes
[1596045297] SERVICE FLAPPING ALERT: sservercluster2;CPU Load;STOPPED; Service appears to have stopped flapping (3.8% change < 5.0% threshold)
[1596045297] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;CPU Load;OK;notify-service-by-email;OK - load average: 0.93, 0.99, 0.98
[1596045410] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.6% (312860 kB) free!
[1596045523] SERVICE NOTIFICATION: nagiosadmin;rq-1;CPU_Procs;WARNING;notify-service-by-email;CPU WARNING: 1 warn out of 352 processes
[1596045524] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 772 processes
[1596045625] Auto-save of retention data completed successfully.
[1596045849] SERVICE NOTIFICATION: nagiosadmin;qservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 11.3% (5578072 kB) free!
[1596046343] SERVICE NOTIFICATION: nagiosadmin;db2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 5.5% (2734876 kB) free!
[1596046391] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1022 processes
[1596046975] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(1869) < 2020/07/29 23:52:54 [error] 1785#0: *5508393 access forbidden by rule while initializing session, client: 103.209.99.7, server: 0.0.0.0:13000
[1596047032] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (227232 kB) free!
