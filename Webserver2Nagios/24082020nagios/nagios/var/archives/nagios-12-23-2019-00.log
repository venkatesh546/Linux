[1576953000] LOG ROTATION: DAILY
[1576953000] LOG VERSION: 2.0
[1576953000] CURRENT HOST STATE: db1-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.41 ms
[1576953000] CURRENT HOST STATE: db2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.39 ms
[1576953000] CURRENT HOST STATE: primary-server;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.38 ms
[1576953000] CURRENT HOST STATE: pservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.38 ms
[1576953000] CURRENT HOST STATE: pservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.34 ms
[1576953000] CURRENT HOST STATE: qservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.35 ms
[1576953000] CURRENT HOST STATE: qservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.31 ms
[1576953000] CURRENT HOST STATE: redis-1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.32 ms
[1576953000] CURRENT HOST STATE: redis-2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.33 ms
[1576953000] CURRENT HOST STATE: rq-1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.28 ms
[1576953000] CURRENT HOST STATE: rq-2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.26 ms
[1576953000] CURRENT HOST STATE: secondary-server;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.38 ms
[1576953000] CURRENT HOST STATE: sig1-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.67 ms
[1576953000] CURRENT HOST STATE: sig2-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.47 ms
[1576953000] CURRENT HOST STATE: sig3-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.37 ms
[1576953000] CURRENT HOST STATE: sig4-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.57 ms
[1576953000] CURRENT HOST STATE: sig5-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.44 ms
[1576953000] CURRENT HOST STATE: sig6-vm2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.46 ms
[1576953000] CURRENT HOST STATE: sigqscluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.43 ms
[1576953000] CURRENT HOST STATE: sigqscluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.31 ms
[1576953000] CURRENT HOST STATE: smscapp1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.29 ms
[1576953000] CURRENT HOST STATE: smscapp2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.26 ms
[1576953000] CURRENT HOST STATE: sservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.32 ms
[1576953000] CURRENT HOST STATE: sservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.36 ms
[1576953000] CURRENT HOST STATE: webserver1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.45 ms
[1576953000] CURRENT HOST STATE: webserver2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.06 ms
[1576953000] CURRENT HOST STATE: webservercluster1;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.46 ms
[1576953000] CURRENT HOST STATE: webservercluster2;UP;HARD;1;PING OK - Packet loss = 0%, RTA = 0.28 ms
[1576953000] CURRENT SERVICE STATE: db1-vm2;CPU Load;OK;HARD;1;OK - load average: 0.66, 0.71, 0.74
[1576953000] CURRENT SERVICE STATE: db1-vm2;CPU_Procs;OK;HARD;1;CPU OK: 461 processes
[1576953000] CURRENT SERVICE STATE: db1-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1576953000] CURRENT SERVICE STATE: db1-vm2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 26915 MB (67% inode=99%):
[1576953000] CURRENT SERVICE STATE: db1-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44594 MB (87% inode=99%):
[1576953000] CURRENT SERVICE STATE: db1-vm2;Memory;OK;HARD;1;OK - 90.8% (22415408 kB) free.
[1576953000] CURRENT SERVICE STATE: db1-vm2;OutOfMemory-killer--oom-killer;OK;HARD;1;Log check ok - 0 pattern matches found
[1576953000] CURRENT SERVICE STATE: db1-vm2;PING;OK;HARD;1;PING OK - Packet loss = 0%, RTA = 0.07 ms
[1576953000] CURRENT SERVICE STATE: db1-vm2;Total Processes;OK;HARD;1;PROCS OK: 461 processes
[1576953000] CURRENT SERVICE STATE: db2;CPU Load;OK;HARD;1;OK - load average: 1.02, 0.91, 0.68
[1576953000] CURRENT SERVICE STATE: db2;CPU_Procs;OK;HARD;1;CPU OK: 331 processes
[1576953000] CURRENT SERVICE STATE: db2;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1576953000] CURRENT SERVICE STATE: db2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 90216 MB (40% inode=99%):
[1576953000] CURRENT SERVICE STATE: db2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44464 MB (86% inode=99%):
[1576953000] CURRENT SERVICE STATE: db2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: db2;Mariadb status;OK;HARD;1;PROCS OK: 1 process with command name 'mysqld'
[1576953000] CURRENT SERVICE STATE: db2;Memory;OK;HARD;1;OK - 56.0% (27607704 kB) free.
[1576953000] CURRENT SERVICE STATE: db2;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: db2;Total Processes;OK;HARD;1;PROCS OK: 331 processes
[1576953000] CURRENT SERVICE STATE: primary-server;CPU Load;OK;HARD;1;OK - load average: 0.04, 0.43, 0.51
[1576953000] CURRENT SERVICE STATE: primary-server;CPU_Procs;OK;HARD;1;CPU OK: 342 processes
[1576953000] CURRENT SERVICE STATE: primary-server;Current Users;OK;HARD;1;USERS OK - 3 users currently logged in
[1576953000] CURRENT SERVICE STATE: primary-server;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 128481 MB (57% inode=99%):
[1576953000] CURRENT SERVICE STATE: primary-server;HDD_Root status;OK;HARD;1;DISK OK - free space: / 30067 MB (58% inode=99%):
[1576953000] CURRENT SERVICE STATE: primary-server;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: primary-server;Memory;OK;HARD;1;OK - 74.9% (18349092 kB) free.
[1576953000] CURRENT SERVICE STATE: primary-server;Nginx Access Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1576953000] CURRENT SERVICE STATE: primary-server;Nginx Error Log Status;CRITICAL;HARD;3;(6) < 2019/12/21 23:50:45 [error] 20756#0: *18909735 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1576953000] CURRENT SERVICE STATE: primary-server;Nginx Status;OK;HARD;1;NGINX OK -  0.102 sec. response time, Active: 0 (Writing: 0 Reading: 0 Waiting: 0) ReqPerSec: 0.000 ConnPerSec: 0.000 ReqPerConn: 0.000
[1576953000] CURRENT SERVICE STATE: primary-server;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: primary-server;Total Processes;OK;HARD;1;PROCS OK: 341 processes
[1576953000] CURRENT SERVICE STATE: pservercluster1;CPU Load;OK;HARD;1;OK - load average: 0.74, 0.55, 0.51
[1576953000] CURRENT SERVICE STATE: pservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 367 processes
[1576953000] CURRENT SERVICE STATE: pservercluster1;Current Users;OK;HARD;1;USERS OK - 7 users currently logged in
[1576953000] CURRENT SERVICE STATE: pservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 174349 MB (78% inode=99%):
[1576953000] CURRENT SERVICE STATE: pservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39511 MB (77% inode=99%):
[1576953000] CURRENT SERVICE STATE: pservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (197516 kB) free!
[1576953000] CURRENT SERVICE STATE: pservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: pservercluster1;Total Processes;OK;HARD;1;PROCS OK: 371 processes
[1576953000] CURRENT SERVICE STATE: pservercluster2;CPU Load;OK;HARD;1;OK - load average: 1.08, 0.99, 0.97
[1576953000] CURRENT SERVICE STATE: pservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 361 processes
[1576953000] CURRENT SERVICE STATE: pservercluster2;Current Users;OK;HARD;1;USERS OK - 6 users currently logged in
[1576953000] CURRENT SERVICE STATE: pservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 145483 MB (64% inode=99%):
[1576953000] CURRENT SERVICE STATE: pservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 37456 MB (73% inode=98%):
[1576953000] CURRENT SERVICE STATE: pservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: pservercluster2;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (185632 kB) free!
[1576953000] CURRENT SERVICE STATE: pservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: pservercluster2;Total Processes;OK;HARD;1;PROCS OK: 364 processes
[1576953000] CURRENT SERVICE STATE: qservercluster1;CPU Load;OK;HARD;1;OK - load average: 6.29, 5.90, 5.69
[1576953000] CURRENT SERVICE STATE: qservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 333 processes
[1576953000] CURRENT SERVICE STATE: qservercluster1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1576953000] CURRENT SERVICE STATE: qservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 224641 MB (99% inode=99%):
[1576953000] CURRENT SERVICE STATE: qservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 44183 MB (86% inode=99%):
[1576953000] CURRENT SERVICE STATE: qservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: qservercluster1;Memory;OK;HARD;1;OK - 88.1% (43395116 kB) free.
[1576953000] CURRENT SERVICE STATE: qservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: qservercluster1;Total Processes;OK;HARD;1;PROCS OK: 330 processes
[1576953000] CURRENT SERVICE STATE: qservercluster2;CPU Load;OK;HARD;1;OK - load average: 3.85, 2.90, 2.46
[1576953000] CURRENT SERVICE STATE: qservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 554 processes
[1576953000] CURRENT SERVICE STATE: qservercluster2;Current Users;OK;HARD;1;USERS OK - 4 users currently logged in
[1576953000] CURRENT SERVICE STATE: qservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 107050 MB (47% inode=99%):
[1576953000] CURRENT SERVICE STATE: qservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 27042 MB (52% inode=98%):
[1576953000] CURRENT SERVICE STATE: qservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: qservercluster2;Memory;OK;HARD;1;OK - 75.9% (37389756 kB) free.
[1576953000] CURRENT SERVICE STATE: qservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: qservercluster2;Total Processes;OK;HARD;1;PROCS OK: 550 processes
[1576953000] CURRENT SERVICE STATE: redis-1;CPU Load;OK;HARD;1;OK - load average: 0.55, 0.58, 0.67
[1576953000] CURRENT SERVICE STATE: redis-1;CPU_Procs;OK;HARD;1;CPU OK: 400 processes
[1576953000] CURRENT SERVICE STATE: redis-1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1576953000] CURRENT SERVICE STATE: redis-1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 363882 MB (97% inode=99%):
[1576953000] CURRENT SERVICE STATE: redis-1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 45133 MB (88% inode=99%):
[1576953000] CURRENT SERVICE STATE: redis-1;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /vns1 372966 MB (34% inode=99%):
[1576953000] CURRENT SERVICE STATE: redis-1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: redis-1;Memory;OK;HARD;1;OK - 71.9% (94717964 kB) free.
[1576953000] CURRENT SERVICE STATE: redis-1;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: redis-1;Total Processes;OK;HARD;1;PROCS OK: 400 processes
[1576953000] CURRENT SERVICE STATE: redis-2;CPU Load;OK;HARD;1;OK - load average: 2.13, 1.91, 1.53
[1576953000] CURRENT SERVICE STATE: redis-2;CPU_Procs;OK;HARD;1;CPU OK: 382 processes
[1576953000] CURRENT SERVICE STATE: redis-2;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1576953000] CURRENT SERVICE STATE: redis-2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 325844 MB (87% inode=99%):
[1576953000] CURRENT SERVICE STATE: redis-2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 45185 MB (88% inode=99%):
[1576953000] CURRENT SERVICE STATE: redis-2;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /vns1 1069171 MB (99% inode=99%):
[1576953000] CURRENT SERVICE STATE: redis-2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: redis-2;Memory;OK;HARD;1;OK - 33.7% (44401340 kB) free.
[1576953000] CURRENT SERVICE STATE: redis-2;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: redis-2;Total Processes;OK;HARD;1;PROCS OK: 385 processes
[1576953000] CURRENT SERVICE STATE: rq-1;CPU Load;OK;HARD;1;OK - load average: 14.09, 15.38, 15.20
[1576953000] CURRENT SERVICE STATE: rq-1;CPU_Procs;OK;HARD;1;CPU OK: 354 processes
[1576953000] CURRENT SERVICE STATE: rq-1;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1576953000] CURRENT SERVICE STATE: rq-1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 400998 MB (99% inode=99%):
[1576953000] CURRENT SERVICE STATE: rq-1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 42063 MB (82% inode=99%):
[1576953000] CURRENT SERVICE STATE: rq-1;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /rq1vns1 1068147 MB (99% inode=99%):
[1576953000] CURRENT SERVICE STATE: rq-1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: rq-1;Memory;OK;HARD;1;OK - 81.1% (106925440 kB) free.
[1576953000] CURRENT SERVICE STATE: rq-1;Total Processes;OK;HARD;1;PROCS OK: 356 processes
[1576953000] CURRENT SERVICE STATE: rq-1;rq1-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1576953000] CURRENT SERVICE STATE: rq-2;CPU Load;OK;HARD;1;OK - load average: 12.76, 15.36, 15.56
[1576953000] CURRENT SERVICE STATE: rq-2;CPU_Procs;OK;HARD;1;CPU OK: 386 processes
[1576953000] CURRENT SERVICE STATE: rq-2;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1576953000] CURRENT SERVICE STATE: rq-2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 401206 MB (99% inode=99%):
[1576953000] CURRENT SERVICE STATE: rq-2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 45492 MB (88% inode=99%):
[1576953000] CURRENT SERVICE STATE: rq-2;HDD_VNS1 status;OK;HARD;1;DISK OK - free space: /dev 64349 MB (100% inode=99%):
[1576953000] CURRENT SERVICE STATE: rq-2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 2 processes with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: rq-2;Memory;OK;HARD;1;OK - 92.5% (121885548 kB) free.
[1576953000] CURRENT SERVICE STATE: rq-2;Total Processes;OK;HARD;1;PROCS OK: 387 processes
[1576953000] CURRENT SERVICE STATE: rq-2;rq2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1576953000] CURRENT SERVICE STATE: secondary-server;CPU Load;OK;HARD;1;OK - load average: 0.01, 0.04, 0.23
[1576953000] CURRENT SERVICE STATE: secondary-server;CPU_Procs;OK;HARD;1;CPU OK: 344 processes
[1576953000] CURRENT SERVICE STATE: secondary-server;Current Users;OK;HARD;1;USERS OK - 3 users currently logged in
[1576953000] CURRENT SERVICE STATE: secondary-server;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 100506 MB (44% inode=99%):
[1576953000] CURRENT SERVICE STATE: secondary-server;HDD_Root status;OK;HARD;1;DISK OK - free space: / 37266 MB (72% inode=99%):
[1576953000] CURRENT SERVICE STATE: secondary-server;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: secondary-server;Memory Status;OK;HARD;1;OK - 81.9% (20073856 kB) free.
[1576953000] CURRENT SERVICE STATE: secondary-server;Nginx Access Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1576953000] CURRENT SERVICE STATE: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1576953000] CURRENT SERVICE STATE: secondary-server;Nginx Status;OK;HARD;1;NGINX OK -  0.088 sec. response time, Active: 0 (Writing: 0 Reading: 0 Waiting: 0) ReqPerSec: 0.000 ConnPerSec: 0.000 ReqPerConn: 0.000
[1576953000] CURRENT SERVICE STATE: secondary-server;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: secondary-server;Total Processes;OK;HARD;1;PROCS OK: 344 processes
[1576953000] CURRENT SERVICE STATE: sig1-vm2;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.03, 0.00
[1576953000] CURRENT SERVICE STATE: sig1-vm2;CPU_Procs;OK;HARD;1;CPU OK: 263 processes
[1576953000] CURRENT SERVICE STATE: sig1-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1576953000] CURRENT SERVICE STATE: sig1-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 2 processes with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: sig1-vm2;Memory;OK;HARD;1;OK - 71.4% (11669408 kB) free.
[1576953000] CURRENT SERVICE STATE: sig1-vm2;Root status;OK;HARD;1;DISK OK - free space: / 125189 MB (93% inode=97%):
[1576953000] CURRENT SERVICE STATE: sig1-vm2;Total Processes;OK;HARD;1;PROCS OK: 266 processes
[1576953000] CURRENT SERVICE STATE: sig2-vm2;CPU Load;OK;HARD;1;OK - load average: 0.65, 0.83, 0.85
[1576953000] CURRENT SERVICE STATE: sig2-vm2;CPU_Procs;OK;HARD;1;CPU OK: 456 processes
[1576953000] CURRENT SERVICE STATE: sig2-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1576953000] CURRENT SERVICE STATE: sig2-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 124129 MB (89% inode=99%):
[1576953000] CURRENT SERVICE STATE: sig2-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: sig2-vm2;Memory;OK;HARD;1;OK - 90.2% (31420192 kB) free.
[1576953000] CURRENT SERVICE STATE: sig2-vm2;Total Processes;OK;HARD;1;PROCS OK: 457 processes
[1576953000] CURRENT SERVICE STATE: sig3-vm2;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.00, 0.00
[1576953000] CURRENT SERVICE STATE: sig3-vm2;CPU_Procs;OK;HARD;1;CPU OK: 549 processes
[1576953000] CURRENT SERVICE STATE: sig3-vm2;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1576953000] CURRENT SERVICE STATE: sig3-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 90257 MB (75% inode=96%):
[1576953000] CURRENT SERVICE STATE: sig3-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 2 processes with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: sig3-vm2;Memory;OK;HARD;1;OK - 96.0% (22619068 kB) free.
[1576953000] CURRENT SERVICE STATE: sig3-vm2;Total Processes;OK;HARD;1;PROCS OK: 550 processes
[1576953000] CURRENT SERVICE STATE: sig4-vm2;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.01, 0.05
[1576953000] CURRENT SERVICE STATE: sig4-vm2;CPU_Procs;OK;HARD;1;CPU OK: 222 processes
[1576953000] CURRENT SERVICE STATE: sig4-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1576953000] CURRENT SERVICE STATE: sig4-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 99598 MB (77% inode=99%):
[1576953000] CURRENT SERVICE STATE: sig4-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: sig4-vm2;Memory;OK;HARD;1;OK - 89.0% (31018272 kB) free.
[1576953000] CURRENT SERVICE STATE: sig4-vm2;Total Processes;OK;HARD;1;PROCS OK: 222 processes
[1576953000] CURRENT SERVICE STATE: sig5-vm2;CPU Load;OK;HARD;1;OK - load average: 0.72, 0.99, 0.98
[1576953000] CURRENT SERVICE STATE: sig5-vm2;CPU_Procs;OK;HARD;1;CPU OK: 461 processes
[1576953000] CURRENT SERVICE STATE: sig5-vm2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1576953000] CURRENT SERVICE STATE: sig5-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 231773 MB (92% inode=99%):
[1576953000] CURRENT SERVICE STATE: sig5-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: sig5-vm2;Memory;OK;HARD;1;OK - 88.8% (31085700 kB) free.
[1576953000] CURRENT SERVICE STATE: sig5-vm2;Total Processes;OK;HARD;1;PROCS OK: 461 processes
[1576953000] CURRENT SERVICE STATE: sig6-vm2;CPU Load;OK;HARD;1;OK - load average: 0.70, 0.81, 0.85
[1576953000] CURRENT SERVICE STATE: sig6-vm2;CPU_Procs;OK;HARD;1;CPU OK: 498 processes
[1576953000] CURRENT SERVICE STATE: sig6-vm2;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1576953000] CURRENT SERVICE STATE: sig6-vm2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 179745 MB (91% inode=99%):
[1576953000] CURRENT SERVICE STATE: sig6-vm2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: sig6-vm2;Memory;OK;HARD;1;OK - 74.0% (16609168 kB) free.
[1576953000] CURRENT SERVICE STATE: sig6-vm2;OutOfMemory-killer--oom-killer;OK;HARD;1;Log check ok - 0 pattern matches found
[1576953000] CURRENT SERVICE STATE: sig6-vm2;Total Processes;OK;HARD;1;PROCS OK: 498 processes
[1576953000] CURRENT SERVICE STATE: sigqscluster1;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.02, 0.15
[1576953000] CURRENT SERVICE STATE: sigqscluster1;CPU_Procs;OK;HARD;1;CPU OK: 349 processes
[1576953000] CURRENT SERVICE STATE: sigqscluster1;Current Users;OK;HARD;1;USERS OK - 5 users currently logged in
[1576953000] CURRENT SERVICE STATE: sigqscluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 224102 MB (99% inode=99%):
[1576953000] CURRENT SERVICE STATE: sigqscluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40021 MB (78% inode=99%):
[1576953000] CURRENT SERVICE STATE: sigqscluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: sigqscluster1;Memory;WARNING;HARD;3;WARNING - 16.1% (7952960 kB) free!
[1576953000] CURRENT SERVICE STATE: sigqscluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: sigqscluster1;Total Processes;OK;HARD;1;PROCS OK: 350 processes
[1576953000] CURRENT SERVICE STATE: sigqscluster2;CPU Load;OK;HARD;1;OK - load average: 12.22, 12.11, 12.00
[1576953000] CURRENT SERVICE STATE: sigqscluster2;CPU_Procs;OK;HARD;1;CPU OK: 303 processes
[1576953000] CURRENT SERVICE STATE: sigqscluster2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1576953000] CURRENT SERVICE STATE: sigqscluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 208589 MB (99% inode=99%):
[1576953000] CURRENT SERVICE STATE: sigqscluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 45489 MB (88% inode=99%):
[1576953000] CURRENT SERVICE STATE: sigqscluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: sigqscluster2;Memory;OK;HARD;1;OK - 80.8% (39814668 kB) free.
[1576953000] CURRENT SERVICE STATE: sigqscluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: sigqscluster2;Total Processes;OK;HARD;1;PROCS OK: 298 processes
[1576953000] CURRENT SERVICE STATE: sigqscluster2;sigqscluster2-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1576953000] CURRENT SERVICE STATE: smscapp1;CPU Load;OK;HARD;1;OK - load average: 2.31, 2.25, 2.25
[1576953000] CURRENT SERVICE STATE: smscapp1;CPU_Procs;OK;HARD;1;CPU OK: 636 processes
[1576953000] CURRENT SERVICE STATE: smscapp1;Current Users;OK;HARD;1;USERS OK - 3 users currently logged in
[1576953000] CURRENT SERVICE STATE: smscapp1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 89942 MB (40% inode=99%):
[1576953000] CURRENT SERVICE STATE: smscapp1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 39074 MB (76% inode=98%):
[1576953000] CURRENT SERVICE STATE: smscapp1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: smscapp1;Memory;OK;HARD;1;OK - 63.8% (31463988 kB) free.
[1576953000] CURRENT SERVICE STATE: smscapp1;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: smscapp1;Total Processes;OK;HARD;1;PROCS OK: 636 processes
[1576953000] CURRENT SERVICE STATE: smscapp2;CPU Load;OK;HARD;1;OK - load average: 3.90, 3.97, 3.95
[1576953000] CURRENT SERVICE STATE: smscapp2;CPU_Procs;OK;HARD;1;CPU OK: 2128 processes
[1576953000] CURRENT SERVICE STATE: smscapp2;Current Users;OK;HARD;1;USERS OK - 0 users currently logged in
[1576953000] CURRENT SERVICE STATE: smscapp2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 98693 MB (43% inode=99%):
[1576953000] CURRENT SERVICE STATE: smscapp2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 38757 MB (75% inode=98%):
[1576953000] CURRENT SERVICE STATE: smscapp2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: smscapp2;Memory;OK;HARD;1;OK - 52.9% (26068856 kB) free.
[1576953000] CURRENT SERVICE STATE: smscapp2;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: smscapp2;Total Processes;OK;HARD;1;PROCS OK: 2128 processes
[1576953000] CURRENT SERVICE STATE: sservercluster1;CPU Load;OK;HARD;1;OK - load average: 1.29, 1.21, 1.18
[1576953000] CURRENT SERVICE STATE: sservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 327 processes
[1576953000] CURRENT SERVICE STATE: sservercluster1;Current Users;OK;HARD;1;USERS OK - 3 users currently logged in
[1576953000] CURRENT SERVICE STATE: sservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 160988 MB (72% inode=99%):
[1576953000] CURRENT SERVICE STATE: sservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40520 MB (79% inode=99%):
[1576953000] CURRENT SERVICE STATE: sservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: sservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (197240 kB) free!
[1576953000] CURRENT SERVICE STATE: sservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: sservercluster1;Total Processes;OK;HARD;1;PROCS OK: 327 processes
[1576953000] CURRENT SERVICE STATE: sservercluster2;CPU Load;OK;HARD;1;OK - load average: 0.52, 0.41, 0.40
[1576953000] CURRENT SERVICE STATE: sservercluster2;CPU_Procs;OK;HARD;1;CPU OK: 349 processes
[1576953000] CURRENT SERVICE STATE: sservercluster2;Current Users;OK;HARD;1;USERS OK - 5 users currently logged in
[1576953000] CURRENT SERVICE STATE: sservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 180133 MB (81% inode=99%):
[1576953000] CURRENT SERVICE STATE: sservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 33243 MB (64% inode=98%):
[1576953000] CURRENT SERVICE STATE: sservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: sservercluster2;Memory;CRITICAL;HARD;3;CRITICAL - 0.9% (224464 kB) free!
[1576953000] CURRENT SERVICE STATE: sservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: sservercluster2;Total Processes;OK;HARD;1;PROCS OK: 349 processes
[1576953000] CURRENT SERVICE STATE: webserver1;CPU Load;OK;HARD;1;OK - load average: 0.03, 0.11, 0.32
[1576953000] CURRENT SERVICE STATE: webserver1;CPU_Procs;OK;HARD;1;CPU OK: 364 processes
[1576953000] CURRENT SERVICE STATE: webserver1;Current Users;OK;HARD;1;USERS OK - 1 users currently logged in
[1576953000] CURRENT SERVICE STATE: webserver1;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 224832 MB (99% inode=99%):
[1576953000] CURRENT SERVICE STATE: webserver1;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40214 MB (78% inode=99%):
[1576953000] CURRENT SERVICE STATE: webserver1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: webserver1;Memory;OK;HARD;1;OK - 84.6% (20701804 kB) free.
[1576953000] CURRENT SERVICE STATE: webserver1;Nginx_status;OK;HARD;1;NGINX OK -  0.088 sec. response time, Active: 1 (Writing: 1 Reading: 0 Waiting: 0) ReqPerSec: 0.003 ConnPerSec: 0.010 ReqPerConn: 0.970
[1576953000] CURRENT SERVICE STATE: webserver1;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: webserver1;Total Processes;OK;HARD;1;PROCS OK: 366 processes
[1576953000] CURRENT SERVICE STATE: webserver2;CPU_Procs;OK;HARD;1;CPU OK: 496 processes
[1576953000] CURRENT SERVICE STATE: webserver2;Current Load;OK;HARD;1;OK - load average: 0.00, 0.02, 0.05
[1576953000] CURRENT SERVICE STATE: webserver2;Current Users;OK;HARD;1;USERS OK - 37 users currently logged in
[1576953000] CURRENT SERVICE STATE: webserver2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 95634 MB (42.55% inode=100%):
[1576953000] CURRENT SERVICE STATE: webserver2;HTTP;OK;HARD;1;HTTP OK: HTTP/1.1 200 OK - 355 bytes in 0.001 second response time
[1576953000] CURRENT SERVICE STATE: webserver2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: webserver2;Memory;OK;HARD;1;OK - 62.9% (15418032 kB) free.
[1576953000] CURRENT SERVICE STATE: webserver2;PING;OK;HARD;1;PING OK - Packet loss = 0%, RTA = 0.07 ms
[1576953000] CURRENT SERVICE STATE: webserver2;Root Partition;OK;HARD;1;DISK OK - free space: / 13333 MB (26.05% inode=99%):
[1576953000] CURRENT SERVICE STATE: webserver2;SSH;OK;HARD;1;SSH OK - OpenSSH_7.4 (protocol 2.0)
[1576953000] CURRENT SERVICE STATE: webserver2;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: webserver2;Total Processes;OK;HARD;1;PROCS OK: 164 processes with STATE = RSZDT
[1576953000] CURRENT SERVICE STATE: webservercluster1;CPU Load;OK;HARD;1;OK - load average: 0.00, 0.01, 0.05
[1576953000] CURRENT SERVICE STATE: webservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 1708 processes
[1576953000] CURRENT SERVICE STATE: webservercluster1;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1576953000] CURRENT SERVICE STATE: webservercluster1;HDD_Home status;OK;HARD;1;DISK OK - free space: / 20337 MB (39% inode=99%):
[1576953000] CURRENT SERVICE STATE: webservercluster1;HDD_Root status;OK;HARD;1;DISK OK - free space: /home 75638 MB (33% inode=99%):
[1576953000] CURRENT SERVICE STATE: webservercluster1;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: webservercluster1;Memory;OK;HARD;1;OK - 63.8% (10367308 kB) free.
[1576953000] CURRENT SERVICE STATE: webservercluster1;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: webservercluster1;Total Processes;CRITICAL;HARD;3;PROCS CRITICAL: 1717 processes
[1576953000] CURRENT SERVICE STATE: webservercluster2;CPU Load;OK;HARD;1;OK - load average: 1.95, 1.90, 1.94
[1576953000] CURRENT SERVICE STATE: webservercluster2;CPU_Procs;CRITICAL;HARD;3;CPU CRITICAL: 1 crit, 0 warn out of 306 processes
[1576953000] CURRENT SERVICE STATE: webservercluster2;Current Users;OK;HARD;1;USERS OK - 2 users currently logged in
[1576953000] CURRENT SERVICE STATE: webservercluster2;HDD_Home status;OK;HARD;1;DISK OK - free space: /home 223247 MB (99% inode=99%):
[1576953000] CURRENT SERVICE STATE: webservercluster2;HDD_Root status;OK;HARD;1;DISK OK - free space: / 40123 MB (78% inode=99%):
[1576953000] CURRENT SERVICE STATE: webservercluster2;LocalService-NTPD SERVICE;OK;HARD;1;PROCS OK: 1 process with command name 'ntpd'
[1576953000] CURRENT SERVICE STATE: webservercluster2;Memory;OK;HARD;1;OK - 52.7% (8560900 kB) free.
[1576953000] CURRENT SERVICE STATE: webservercluster2;Sensors Status;OK;HARD;1;SENSORS OK
[1576953000] CURRENT SERVICE STATE: webservercluster2;Total Processes;OK;HARD;1;PROCS OK: 303 processes
[1576953098] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 2.2% (536496 kB) free!
[1576953487] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (196904 kB) free!
[1576953636] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (197548 kB) free!
[1576953667] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.9% (232432 kB) free!
[1576954168] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;WARNING;notify-service-by-email;WARNING - 16.0% (7899080 kB) free!
[1576954201] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 305 processes
[1576954694] Auto-save of retention data completed successfully.
[1576954959] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1850 processes
[1576955514] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(6) < 2019/12/22 00:41:13 [error] 20751#0: *18918806 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1576956098] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;OK;notify-service-by-email;OK - 40.9% (10101348 kB) free.
[1576956098] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 40.9% (10101348 kB) free.
[1576957087] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (181000 kB) free!
[1576957267] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.0% (251004 kB) free!
[1576957298] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.9% (222032 kB) free!
[1576957418] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (205124 kB) free!
[1576957538] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (171144 kB) free!
[1576957538] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.7% (171144 kB) free!
[1576957768] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (228356 kB) free!
[1576957768] SERVICE ALERT: sigqscluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.5% (228356 kB) free!
[1576957801] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 304 processes
[1576957835] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (198312 kB) free!
[1576958294] Auto-save of retention data completed successfully.
[1576958560] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 2050 processes
[1576959114] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3) < 2019/12/22 01:41:14 [error] 20756#0: *18929443 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1576960235] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;OK;notify-service-by-email;OK - 42.8% (10496292 kB) free.
[1576960235] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 42.8% (10496292 kB) free.
[1576960687] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (182700 kB) free!
[1576960867] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.9% (217080 kB) free!
[1576961139] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (207224 kB) free!
[1576961368] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (236600 kB) free!
[1576961401] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 305 processes
[1576961768] SERVICE ALERT: smscapp1;Memory;CRITICAL;SOFT;1;CRITICAL - 5.5% (2708428 kB) free!
[1576961888] SERVICE ALERT: smscapp1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.4% (214172 kB) free!
[1576961894] Auto-save of retention data completed successfully.
[1576962008] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (232964 kB) free!
[1576962008] SERVICE ALERT: smscapp1;Memory;CRITICAL;HARD;3;CRITICAL - 0.5% (232964 kB) free!
[1576962609] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;OK;notify-service-by-email;OK - 87.4% (43077944 kB) free.
[1576962609] SERVICE ALERT: smscapp1;Memory;OK;HARD;1;OK - 87.4% (43077944 kB) free.
[1576962714] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(9) < 2019/12/22 02:41:13 [error] 20756#0: *18940042 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1576962760] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 2199 processes
[1576964287] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (187428 kB) free!
[1576964467] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.9% (210804 kB) free!
[1576964968] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (250624 kB) free!
[1576965001] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 308 processes
[1576965338] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 3.9% (965372 kB) free!
[1576965494] Auto-save of retention data completed successfully.
[1576966314] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(6) < 2019/12/22 03:40:45 [error] 20756#0: *18950581 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1576966360] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 2211 processes
[1576966708] SERVICE ALERT: rq-1;rq1-rabbitmqerror;CRITICAL;SOFT;1;CHECK_NRPE: Socket timeout after 10 seconds.
[1576966829] SERVICE ALERT: rq-1;rq1-rabbitmqerror;OK;HARD;1;Log check ok - 0 pattern matches found
[1576967887] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.9% (212248 kB) free!
[1576968067] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.9% (223360 kB) free!
[1576968569] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.5% (231872 kB) free!
[1576968601] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 306 processes
[1576968938] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 2.2% (542736 kB) free!
[1576969094] Auto-save of retention data completed successfully.
[1576969914] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(6) < 2019/12/22 04:41:37 [error] 20756#0: *18961426 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1576970560] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 2201 processes
[1576971487] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (194280 kB) free!
[1576971667] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.9% (229168 kB) free!
[1576972201] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 305 processes
[1576972538] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 1.3% (331272 kB) free!
[1576972694] Auto-save of retention data completed successfully.
[1576972768] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.4% (214956 kB) free!
[1576973514] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(6) < 2019/12/22 05:41:13 [error] 20757#0: *18971986 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1576974636] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.7% (179844 kB) free!
[1576974756] SERVICE ALERT: sservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.8% (194760 kB) free!
[1576974760] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 2186 processes
[1576974876] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (178544 kB) free!
[1576974876] SERVICE ALERT: sservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.7% (178544 kB) free!
[1576975087] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (175460 kB) free!
[1576975267] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;OK;notify-service-by-email;OK - 86.6% (21220076 kB) free.
[1576975267] SERVICE ALERT: sservercluster2;Memory;OK;HARD;1;OK - 86.6% (21220076 kB) free.
[1576975430] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1576975429
[1576975431] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;OK;notify-service-by-email;OK - 86.5% (21347176 kB) free.
[1576975431] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 86.5% (21347176 kB) free.
[1576975435] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1576975434
[1576975466] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Memory;1576975465
[1576975467] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;OK;notify-service-by-email;OK - 89.0% (21822448 kB) free.
[1576975467] SERVICE ALERT: pservercluster2;Memory;OK;HARD;1;OK - 89.0% (21822448 kB) free.
[1576975471] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Memory;1576975470
[1576975475] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Memory;1576975474
[1576975478] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Memory;1576975478
[1576975519] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sigqscluster1;Memory;1576975518
[1576975520] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;OK;notify-service-by-email;OK - 78.5% (38672856 kB) free.
[1576975520] SERVICE ALERT: sigqscluster1;Memory;OK;HARD;1;OK - 78.5% (38672856 kB) free.
[1576975523] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sigqscluster1;Memory;1576975522
[1576975526] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sigqscluster1;Memory;1576975525
[1576975556] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster1;Memory;1576975555
[1576975556] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;OK;notify-service-by-email;OK - 91.0% (22310652 kB) free.
[1576975556] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 91.0% (22310652 kB) free.
[1576975560] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster1;Memory;1576975559
[1576975564] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster1;Memory;1576975563
[1576975568] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster1;Memory;1576975567
[1576975801] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 302 processes
[1576976294] Auto-save of retention data completed successfully.
[1576977114] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(6) < 2019/12/22 06:41:14 [error] 20756#0: *18982525 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1576978360] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 2160 processes
[1576979401] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 306 processes
[1576979894] Auto-save of retention data completed successfully.
[1576980714] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(6) < 2019/12/22 07:41:13 [error] 20756#0: *18993223 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1576981960] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 2122 processes
[1576983001] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 308 processes
[1576983494] Auto-save of retention data completed successfully.
[1576983892] SERVICE ALERT: redis-1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 401 processes
[1576984012] SERVICE ALERT: redis-1;CPU_Procs;OK;HARD;1;CPU OK: 400 processes
[1576984314] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3) < 2019/12/22 08:36:14 [error] 20756#0: *18999940 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1576985432] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/12/22 08:58:56 [error] 28870#0: *24798367 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.37:4000", bytes from/to client:232/17, bytes from/to upstream:17/232
[1576985552] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1576985560] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 2104 processes
[1576986601] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 305 processes
[1576987013] SERVICE ALERT: redis-1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 402 processes
[1576987094] Auto-save of retention data completed successfully.
[1576987133] SERVICE ALERT: redis-1;CPU_Procs;OK;HARD;1;CPU OK: 403 processes
[1576987353] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(2) < 2019/12/22 09:32:08 [error] 28874#0: *24812074 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:236/17, bytes from/to upstream:17/236
[1576987435] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.7% (171676 kB) free!
[1576987473] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1576987555] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.7% (180424 kB) free!
[1576987675] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (194472 kB) free!
[1576987675] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (194472 kB) free!
[1576987914] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(6) < 2019/12/22 09:40:46 [error] 20756#0: *19011219 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1576988673] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/12/22 09:45:55 [error] 28874#0: *24817519 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.37:4000", bytes from/to client:217/17, bytes from/to upstream:17/217
[1576988793] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(1) < 2019/12/22 09:54:41 [error] 28863#0: *24821065 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.38:4000", bytes from/to client:392/17, bytes from/to upstream:17/392
[1576988913] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1576989161] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 2087 processes
[1576989250] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1576989249
[1576989250] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;OK;notify-service-by-email;OK - 90.4% (22314348 kB) free.
[1576989250] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 90.4% (22314348 kB) free.
[1576989253] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1576989252
[1576989257] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1576989256
[1576989513] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/12/22 09:59:42 [error] 28869#0: *24823061 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:248/17, bytes from/to upstream:17/248
[1576989634] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1576990201] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 306 processes
[1576990233] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/12/22 10:18:31 [error] 28874#0: *24830720 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:220/17, bytes from/to upstream:17/220
[1576990353] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1576990694] Auto-save of retention data completed successfully.
[1576991514] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(3) < 2019/12/22 10:41:14 [error] 20756#0: *19021709 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1576991553] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(2) < 2019/12/22 10:36:04 [error] 28867#0: *24837850 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:241/17, bytes from/to upstream:17/241
[1576991673] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1576993360] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1963 processes
[1576993801] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 309 processes
[1576994073] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/12/22 11:20:15 [error] 28871#0: *24855843 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.38:4000", bytes from/to client:215/17, bytes from/to upstream:17/215
[1576994193] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1576994294] Auto-save of retention data completed successfully.
[1576995115] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(9) < 2019/12/22 11:41:37 [error] 20760#0: *19032191 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1576995809] SERVICE ALERT: secondary-server;CPU_Procs;CRITICAL;SOFT;1;CPU CRITICAL: 1 crit, 0 warn out of 344 processes
[1576995929] SERVICE ALERT: secondary-server;CPU_Procs;OK;HARD;1;CPU OK: 344 processes
[1576996960] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1900 processes
[1576997057] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;1;CRITICAL - 0.7% (176372 kB) free!
[1576997177] SERVICE ALERT: pservercluster1;Memory;CRITICAL;SOFT;2;CRITICAL - 0.7% (172184 kB) free!
[1576997194] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/12/22 12:07:43 [error] 28862#0: *24876119 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:212/17, bytes from/to upstream:17/212
[1576997297] SERVICE NOTIFICATION: nagiosadmin;pservercluster1;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (188364 kB) free!
[1576997297] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 0.8% (188364 kB) free!
[1576997314] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1576997319] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1576997318
[1576997320] SERVICE FLAPPING ALERT: pservercluster1;Memory;STARTED; Service appears to have started flapping (20.3% change >= 20.0% threshold)
[1576997320] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 88.7% (21891544 kB) free.
[1576997323] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1576997322
[1576997327] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1576997325
[1576997401] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 303 processes
[1576997894] Auto-save of retention data completed successfully.
[1576998514] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/12/22 12:30:08 [error] 28866#0: *24886039 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.38:4000", bytes from/to client:218/17, bytes from/to upstream:17/218
[1576998634] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1576999234] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/12/22 12:44:41 [error] 28868#0: *24892414 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:251/17, bytes from/to upstream:17/251
[1576999314] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(9) < 2019/12/22 12:51:14 [error] 20757#0: *19044307 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1576999354] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577000555] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(2) < 2019/12/22 13:11:21 [error] 28874#0: *24904127 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:253/17, bytes from/to upstream:17/253
[1577000560] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1876 processes
[1577000675] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577000678] SERVICE ALERT: pservercluster2;Memory;WARNING;SOFT;1;WARNING - 16.9% (4136928 kB) free!
[1577000798] SERVICE ALERT: pservercluster2;Memory;WARNING;SOFT;2;WARNING - 16.2% (3970280 kB) free!
[1577000918] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 15.5% (3792168 kB) free!
[1577000918] SERVICE ALERT: pservercluster2;Memory;WARNING;HARD;3;WARNING - 15.5% (3792168 kB) free!
[1577001001] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 310 processes
[1577001275] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/12/22 13:20:07 [error] 28874#0: *24907953 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.38:4000", bytes from/to client:245/17, bytes from/to upstream:17/245
[1577001395] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577001494] Auto-save of retention data completed successfully.
[1577002118] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 9.1% (2218560 kB) free!
[1577002118] SERVICE ALERT: pservercluster2;Memory;CRITICAL;HARD;3;CRITICAL - 9.1% (2218560 kB) free!
[1577002595] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/12/22 13:46:01 [error] 28874#0: *24918508 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.37:4000", bytes from/to client:245/17, bytes from/to upstream:17/245
[1577002715] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577002914] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(15) < 2019/12/22 13:51:13 [error] 20757#0: *19054920 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577003316] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/12/22 13:58:33 [error] 28867#0: *24924055 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.37:4000", bytes from/to client:245/17, bytes from/to upstream:17/245
[1577003436] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577004160] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1742 processes
[1577004601] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 312 processes
[1577004636] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/12/22 14:16:06 [error] 28865#0: *24931680 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.38:4000", bytes from/to client:245/17, bytes from/to upstream:17/245
[1577004756] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577005094] Auto-save of retention data completed successfully.
[1577005356] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(2) < 2019/12/22 14:28:24 [error] 28872#0: *24937293 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.49:4000", bytes from/to client:451/17, bytes from/to upstream:17/451
[1577005476] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577005526] SERVICE ALERT: sigqscluster1;Memory;WARNING;SOFT;1;WARNING - 17.4% (8567260 kB) free!
[1577005646] SERVICE ALERT: sigqscluster1;Memory;WARNING;SOFT;2;WARNING - 17.4% (8566528 kB) free!
[1577005718] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.8% (203512 kB) free!
[1577005766] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;WARNING;notify-service-by-email;WARNING - 17.4% (8568388 kB) free!
[1577005766] SERVICE ALERT: sigqscluster1;Memory;WARNING;HARD;3;WARNING - 17.4% (8568388 kB) free!
[1577006076] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(2) < 2019/12/22 14:42:11 [error] 28871#0: *24943662 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.38:4000", bytes from/to client:448/17, bytes from/to upstream:17/448
[1577006197] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577006327] SERVICE ALERT: pservercluster1;Memory;WARNING;SOFT;1;WARNING - 19.7% (4866088 kB) free!
[1577006447] SERVICE ALERT: pservercluster1;Memory;WARNING;SOFT;2;WARNING - 19.6% (4842072 kB) free!
[1577006514] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(12) < 2019/12/22 14:45:45 [error] 20760#0: *19064386 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.143:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577006567] SERVICE ALERT: pservercluster1;Memory;WARNING;HARD;3;WARNING - 19.5% (4819924 kB) free!
[1577006796] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/12/22 14:55:59 [error] 28864#0: *24949938 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.38:4000", bytes from/to client:245/17, bytes from/to upstream:17/245
[1577006916] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577007516] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(2) < 2019/12/22 15:08:31 [error] 28871#0: *24955345 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:245/17, bytes from/to upstream:17/245
[1577007636] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577007714] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1577007714] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577007760] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1575 processes
[1577008201] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 316 processes
[1577008236] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/12/22 15:16:02 [error] 28862#0: *24958626 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:421/17, bytes from/to upstream:17/421
[1577008315] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(15) < 2019/12/22 15:20:45 [error] 20756#0: *19070532 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577008356] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577008435] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577008694] Auto-save of retention data completed successfully.
[1577008974] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 7.2% (1776256 kB) free!
[1577009035] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1334) < 2019/12/22 15:33:18 [error] 20757#0: *19074063 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577009079] SERVICE ALERT: primary-server;Nginx Access Log Status;CRITICAL;SOFT;1;(1253) < 103.255.146.164 [22/Dec/2019:15:33:17 +0530] TCP 502 0 0 0.000 "backend_3000" "0" "0" "0.000"
[1577009155] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(3) < 2019/12/22 15:35:45 [error] 20756#0: *19074491 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577009200] SERVICE ALERT: primary-server;Nginx Access Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577009275] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577009318] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (171844 kB) free!
[1577009366] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;WARNING;notify-service-by-email;WARNING - 14.3% (7035360 kB) free!
[1577009574] SERVICE ALERT: pservercluster1;Memory;WARNING;HARD;3;WARNING - 14.4% (3565556 kB) free!
[1577009875] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(12) < 2019/12/22 15:46:36 [error] 20760#0: *19076424 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.143:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577009995] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577010596] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(6) < 2019/12/22 15:56:36 [error] 20757#0: *19078133 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577010716] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(12) < 2019/12/22 16:00:41 [error] 20757#0: *19078872 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577010836] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577011360] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 1236 processes
[1577011436] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(7) < 2019/12/22 16:11:36 [error] 20756#0: *19080788 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577011556] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(9) < 2019/12/22 16:15:40 [error] 20757#0: *19081507 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577011569] SERVICE ALERT: sservercluster1;Memory;WARNING;SOFT;1;WARNING - 19.9% (4874344 kB) free!
[1577011676] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577011689] SERVICE ALERT: sservercluster1;Memory;WARNING;SOFT;2;WARNING - 19.6% (4816112 kB) free!
[1577011801] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 312 processes
[1577011809] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;WARNING;notify-service-by-email;WARNING - 19.4% (4758192 kB) free!
[1577011809] SERVICE ALERT: sservercluster1;Memory;WARNING;HARD;3;WARNING - 19.4% (4758192 kB) free!
[1577012276] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(8) < 2019/12/22 16:25:45 [error] 20758#0: *19083247 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577012294] Auto-save of retention data completed successfully.
[1577012396] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577012574] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 7.8% (1921964 kB) free!
[1577012918] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;CRITICAL;notify-service-by-email;CRITICAL - 0.7% (176220 kB) free!
[1577012966] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;WARNING;notify-service-by-email;WARNING - 11.9% (5846696 kB) free!
[1577012997] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(12) < 2019/12/22 16:36:37 [error] 20756#0: *19085119 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577013117] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(3) < 2019/12/22 16:40:45 [error] 20758#0: *19085833 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577013237] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577013837] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(9) < 2019/12/22 16:51:37 [error] 20758#0: *19087736 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577013957] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(3) < 2019/12/22 16:54:14 [error] 20756#0: *19088183 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577014077] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(4) < 2019/12/22 16:56:37 [error] 20758#0: *19088594 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577014077] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;HARD;3;(4) < 2019/12/22 16:56:37 [error] 20758#0: *19088594 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577014332] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1577014331
[1577014332] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 89.9% (22187560 kB) free.
[1577014335] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1577014334
[1577014358] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Memory;1577014357
[1577014359] SERVICE NOTIFICATION: nagiosadmin;pservercluster2;Memory;OK;notify-service-by-email;OK - 79.4% (19455584 kB) free.
[1577014359] SERVICE ALERT: pservercluster2;Memory;OK;HARD;1;OK - 79.4% (19455584 kB) free.
[1577014362] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Memory;1577014361
[1577014365] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster2;Memory;1577014364
[1577014384] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sigqscluster1;Memory;1577014383
[1577014385] SERVICE NOTIFICATION: nagiosadmin;sigqscluster1;Memory;OK;notify-service-by-email;OK - 78.4% (38637144 kB) free.
[1577014385] SERVICE ALERT: sigqscluster1;Memory;OK;HARD;1;OK - 78.4% (38637144 kB) free.
[1577014388] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sigqscluster1;Memory;1577014386
[1577014425] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster1;Memory;1577014424
[1577014425] SERVICE NOTIFICATION: nagiosadmin;sservercluster1;Memory;OK;notify-service-by-email;OK - 91.3% (22379968 kB) free.
[1577014425] SERVICE ALERT: sservercluster1;Memory;OK;HARD;1;OK - 91.3% (22379968 kB) free.
[1577014960] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;CRITICAL;notify-service-by-email;PROCS CRITICAL: 729 processes
[1577015401] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 307 processes
[1577015894] Auto-save of retention data completed successfully.
[1577016161] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;WARNING;notify-service-by-email;PROCS WARNING: 557 processes
[1577016161] SERVICE ALERT: webservercluster1;Total Processes;WARNING;HARD;3;PROCS WARNING: 557 processes
[1577016761] SERVICE NOTIFICATION: nagiosadmin;webservercluster1;Total Processes;OK;notify-service-by-email;PROCS OK: 472 processes
[1577016761] SERVICE ALERT: webservercluster1;Total Processes;OK;HARD;1;PROCS OK: 472 processes
[1577017677] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(5) < 2019/12/22 17:56:13 [error] 20761#0: *19098923 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577017867] SERVICE ALERT: sservercluster2;Memory;WARNING;SOFT;1;WARNING - 19.7% (4836352 kB) free!
[1577017987] SERVICE ALERT: sservercluster2;Memory;WARNING;SOFT;2;WARNING - 19.6% (4800884 kB) free!
[1577018107] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;WARNING;notify-service-by-email;WARNING - 19.5% (4780952 kB) free!
[1577018107] SERVICE ALERT: sservercluster2;Memory;WARNING;HARD;3;WARNING - 19.5% (4780952 kB) free!
[1577018535] SERVICE ALERT: pservercluster1;Memory;WARNING;SOFT;1;WARNING - 16.2% (3991364 kB) free!
[1577018655] SERVICE ALERT: pservercluster1;Memory;WARNING;SOFT;2;WARNING - 16.6% (4092912 kB) free!
[1577018775] SERVICE ALERT: pservercluster1;Memory;WARNING;HARD;3;WARNING - 16.5% (4070208 kB) free!
[1577019001] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 310 processes
[1577019025] SERVICE ALERT: webservercluster1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 332 processes
[1577019145] SERVICE ALERT: webservercluster1;CPU_Procs;OK;HARD;1;CPU OK: 333 processes
[1577019478] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;OK;notify-service-by-email;Log check ok - 0 pattern matches found
[1577019478] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577019494] Auto-save of retention data completed successfully.
[1577019533] SERVICE ALERT: redis-1;CPU_Procs;WARNING;SOFT;1;CPU WARNING: 1 warn out of 402 processes
[1577019653] SERVICE ALERT: redis-1;CPU_Procs;OK;HARD;1;CPU OK: 401 processes
[1577019756] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/12/22 18:24:23 [error] 28873#0: *25041918 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.61:4000", bytes from/to client:241/17, bytes from/to upstream:17/241
[1577019876] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577019975] SERVICE ALERT: pservercluster1;Memory;CRITICAL;HARD;3;CRITICAL - 9.3% (2296124 kB) free!
[1577020078] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(12) < 2019/12/22 18:36:36 [error] 20756#0: *19106038 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577020198] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577020476] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(1) < 2019/12/22 18:36:27 [error] 28872#0: *25047155 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.37:4000", bytes from/to client:241/17, bytes from/to upstream:17/241
[1577020596] SERVICE ALERT: secondary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(1) < 2019/12/22 18:45:47 [error] 28874#0: *25051104 recv() failed (104: Connection reset by peer) while proxying connection, client: 49.50.86.152, server: 0.0.0.0:4000, upstream: "10.147.212.37:4000", bytes from/to client:215/17, bytes from/to upstream:17/215
[1577020603] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster2;Memory;1577020602
[1577020603] SERVICE NOTIFICATION: nagiosadmin;sservercluster2;Memory;OK;notify-service-by-email;OK - 91.1% (22336096 kB) free.
[1577020603] SERVICE ALERT: sservercluster2;Memory;OK;HARD;1;OK - 91.1% (22336096 kB) free.
[1577020606] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;sservercluster2;Memory;1577020605
[1577020640] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1577020639
[1577020641] SERVICE ALERT: pservercluster1;Memory;OK;HARD;1;OK - 89.4% (22063972 kB) free.
[1577020644] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1577020642
[1577020648] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;pservercluster1;Memory;1577020647
[1577020716] SERVICE ALERT: secondary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577020798] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(9) < 2019/12/22 18:45:39 [error] 20759#0: *19107654 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.143:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577020918] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(3) < 2019/12/22 18:51:14 [error] 20756#0: *19108618 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577021038] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577021638] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(12) < 2019/12/22 19:00:41 [error] 20756#0: *19110411 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577021759] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577022358] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(9) < 2019/12/22 19:15:34 [error] 20756#0: *19113012 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577022478] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(2) < 2019/12/22 19:16:37 [error] 20760#0: *19113212 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.143:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577022598] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577022601] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 312 processes
[1577022609] SERVICE ALERT: smscapp1;Memory;WARNING;SOFT;1;WARNING - 20.0% (9861016 kB) free!
[1577022729] SERVICE ALERT: smscapp1;Memory;WARNING;SOFT;2;WARNING - 19.9% (9830144 kB) free!
[1577022849] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;WARNING;notify-service-by-email;WARNING - 19.9% (9803792 kB) free!
[1577022849] SERVICE ALERT: smscapp1;Memory;WARNING;HARD;3;WARNING - 19.9% (9803792 kB) free!
[1577023094] Auto-save of retention data completed successfully.
[1577023198] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(6) < 2019/12/22 19:26:14 [error] 20756#0: *19114898 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577023318] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(7) < 2019/12/22 19:31:37 [error] 20760#0: *19115836 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577023438] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577024038] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(10) < 2019/12/22 19:41:37 [error] 20749#0: *19117567 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.143:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577024159] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(3) < 2019/12/22 19:45:33 [error] 20756#0: *19118275 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577024279] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577024596] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;smscapp1;Memory;1577024594
[1577024596] SERVICE NOTIFICATION: nagiosadmin;smscapp1;Memory;OK;notify-service-by-email;OK - 89.2% (43983316 kB) free.
[1577024596] SERVICE ALERT: smscapp1;Memory;OK;HARD;1;OK - 89.2% (43983316 kB) free.
[1577024600] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;smscapp1;Memory;1577024598
[1577024604] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;smscapp1;Memory;1577024602
[1577024608] EXTERNAL COMMAND: SCHEDULE_FORCED_SVC_CHECK;smscapp1;Memory;1577024607
[1577024879] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(9) < 2019/12/22 19:56:36 [error] 20756#0: *19120250 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577024999] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577025599] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(12) < 2019/12/22 20:06:13 [error] 20758#0: *19122019 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577025719] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(5) < 2019/12/22 20:11:36 [error] 20756#0: *19122997 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577025839] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577026201] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 307 processes
[1577026440] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(12) < 2019/12/22 20:20:45 [error] 20756#0: *19124616 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577026560] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577026694] Auto-save of retention data completed successfully.
[1577027160] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(13) < 2019/12/22 20:31:37 [error] 20760#0: *19126558 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.143:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577027280] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(3) < 2019/12/22 20:36:14 [error] 20756#0: *19127359 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577027400] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577028000] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(12) < 2019/12/22 20:46:14 [error] 20747#0: *19129146 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577028120] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(3) < 2019/12/22 20:51:14 [error] 20756#0: *19130032 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577028241] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577028840] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(12) < 2019/12/22 21:00:40 [error] 20756#0: *19131693 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577028960] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577029560] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(9) < 2019/12/22 21:15:35 [error] 20756#0: *19134392 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577029680] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577029801] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 310 processes
[1577030248] SERVICE FLAPPING ALERT: pservercluster1;Memory;STOPPED; Service appears to have stopped flapping (3.9% change < 5.0% threshold)
[1577030280] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(9) < 2019/12/22 21:26:14 [error] 20756#0: *19136267 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577030294] Auto-save of retention data completed successfully.
[1577030400] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577031000] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(9) < 2019/12/22 21:35:45 [error] 20756#0: *19137931 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577031121] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(3) < 2019/12/22 21:40:45 [error] 20756#0: *19138809 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577031241] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577031841] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(12) < 2019/12/22 21:51:37 [error] 20756#0: *19140726 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577031961] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(2) < 2019/12/22 21:55:45 [error] 20760#0: *19141445 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577032081] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577032681] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(9) < 2019/12/22 22:06:13 [error] 20756#0: *19143344 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577032801] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577033401] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 312 processes
[1577033402] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(6) < 2019/12/22 22:15:37 [error] 20756#0: *19145042 connect() failed (111: Connection refused) while connecting to upstream, client: 103.255.146.164, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577033522] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(3) < 2019/12/22 22:20:45 [error] 20756#0: *19145823 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.155:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577033642] SERVICE ALERT: primary-server;Nginx Error Log Status;OK;HARD;1;Log check ok - 0 pattern matches found
[1577033894] Auto-save of retention data completed successfully.
[1577034242] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;1;(9) < 2019/12/22 22:31:36 [error] 20759#0: *19146827 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.143:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577034362] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;SOFT;2;(7) < 2019/12/22 22:35:25 [error] 20756#0: *19146947 recv() failed (104: Connection reset by peer) while proxying connection, client: 103.209.99.7, server: 0.0.0.0:13000, upstream: "10.147.212.155:13000", bytes from/to client:43/0, bytes from/to upstream:0/43
[1577034482] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(6) < 2019/12/22 22:36:36 [error] 20758#0: *19147079 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577034482] SERVICE ALERT: primary-server;Nginx Error Log Status;CRITICAL;HARD;3;(6) < 2019/12/22 22:36:36 [error] 20758#0: *19147079 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
[1577034701] SERVICE ALERT: pservercluster2;CPU Load;WARNING;SOFT;1;WARNING - load average: 1316.42, 918.09, 420.11
[1577034821] SERVICE ALERT: pservercluster2;CPU Load;WARNING;SOFT;2;WARNING - load average: 1319.58, 1051.10, 529.23
[1577034941] SERVICE ALERT: pservercluster2;CPU Load;OK;HARD;1;OK - load average: 573.07, 936.59, 555.89
[1577035698] SERVICE ALERT: pservercluster1;CPU Load;CRITICAL;SOFT;1;CRITICAL - load average: 123.32, 602.13, 399.21
[1577035818] SERVICE ALERT: pservercluster1;CPU Load;WARNING;SOFT;2;WARNING - load average: 17.29, 403.19, 350.91
[1577035938] SERVICE ALERT: pservercluster1;CPU Load;OK;HARD;1;OK - load average: 3.07, 270.06, 308.46
[1577037001] SERVICE NOTIFICATION: nagiosadmin;webservercluster2;CPU_Procs;CRITICAL;notify-service-by-email;CPU CRITICAL: 1 crit, 0 warn out of 313 processes
[1577037494] Auto-save of retention data completed successfully.
[1577038082] SERVICE NOTIFICATION: nagiosadmin;primary-server;Nginx Error Log Status;CRITICAL;notify-service-by-email;(6) < 2019/12/22 23:35:45 [error] 20756#0: *19154486 connect() failed (111: Connection refused) while connecting to upstream, client: 183.82.105.122, server: 0.0.0.0:3000, upstream: "10.147.212.154:3000", bytes from/to client:0/0, bytes from/to upstream:0/0
